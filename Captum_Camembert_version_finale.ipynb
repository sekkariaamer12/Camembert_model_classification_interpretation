{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPXxUhOF9mdq"
      },
      "source": [
        "Les bibliothèques à installer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uem0T3VX9M9j",
        "outputId": "6c6e9751-2a78-4f5e-b51d-f01ae70e40f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.33.2-py3-none-any.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.17.1-py3-none-any.whl (294 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.8/294.8 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m94.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.17.1 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.33.2\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.6-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.9/235.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.6\n",
            "Collecting emoji\n",
            "  Downloading emoji-2.8.0-py2.py3-none-any.whl (358 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m358.9/358.9 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: emoji\n",
            "Successfully installed emoji-2.8.0\n",
            "Collecting SentencePiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: SentencePiece\n",
            "Successfully installed SentencePiece-0.1.99\n",
            "Collecting captum\n",
            "  Downloading captum-0.6.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from captum) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from captum) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.10/dist-packages (from captum) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6->captum) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6->captum) (16.0.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->captum) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6->captum) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6->captum) (1.3.0)\n",
            "Installing collected packages: captum\n",
            "Successfully installed captum-0.6.0\n",
            "Collecting scikit-plot\n",
            "  Downloading scikit_plot-0.3.7-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from scikit-plot) (3.7.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.10/dist-packages (from scikit-plot) (1.2.2)\n",
            "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.10/dist-packages (from scikit-plot) (1.11.2)\n",
            "Requirement already satisfied: joblib>=0.10 in /usr/local/lib/python3.10/dist-packages (from scikit-plot) (1.3.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.8.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->scikit-plot) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=1.4.0->scikit-plot) (1.16.0)\n",
            "Installing collected packages: scikit-plot\n",
            "Successfully installed scikit-plot-0.3.7\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install unidecode\n",
        "!pip install emoji\n",
        "!pip install SentencePiece\n",
        "!pip install captum\n",
        "!pip install scikit-plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqIJNllV96m6"
      },
      "source": [
        "Import Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eC_I6k8s-CRM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn\n",
        "from tqdm import tqdm, trange\n",
        "import numpy as np\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import CamembertTokenizer, CamembertForSequenceClassification\n",
        "from transformers import AdamW\n",
        "import json\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "import unidecode\n",
        "import emoji\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.optim import Adam\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from captum.attr import LayerIntegratedGradients\n",
        "from captum.attr import visualization as viz\n",
        "from collections import defaultdict\n",
        "import scikitplot as skplt\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import CamembertModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-lvnd5zBUe_",
        "outputId": "a3c048a5-ebbb-4f28-91cb-801cf7b614e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: emoji in /usr/local/lib/python3.10/dist-packages (2.8.0)\n"
          ]
        }
      ],
      "source": [
        "pip install --upgrade emoji"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFdYUjZZ-9rP"
      },
      "source": [
        "Partie 1 : Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "MKV57YA5_B00",
        "outputId": "9144d7cd-2415-46da-ebcd-d8319735f96f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f403dd0e-1d4c-429a-8ad1-5a0672bd3ac3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>🇸🇬 Un ancien Airbus A380 de Singapore Airlines...</td>\n",
              "      <td>avion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Deux Dassault Falcon 900LX pour la Royal Air F...</td>\n",
              "      <td>avion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>🔴 Israël vient d'annoncer l'interdiction des v...</td>\n",
              "      <td>avion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Mais ce volet là est particulièrement importan...</td>\n",
              "      <td>décroissance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ce n’est pas le cas de #Malte, qui a peu de pl...</td>\n",
              "      <td>nucléaire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>492</th>\n",
              "      <td>On a été dans un des seuls resto un peu gastro...</td>\n",
              "      <td>viande</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>494</th>\n",
              "      <td>@BShirizadeh @rogerseban @BridonneauV @Reclaim...</td>\n",
              "      <td>nucléaire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>La baisse des émissions carbone, c'est l'élect...</td>\n",
              "      <td>nucléaire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>Dans une nouvelle enquête #L214 montre des cas...</td>\n",
              "      <td>viande</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>Entre les transactivistes myopes qui s'abonnen...</td>\n",
              "      <td>viande</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>194 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f403dd0e-1d4c-429a-8ad1-5a0672bd3ac3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f403dd0e-1d4c-429a-8ad1-5a0672bd3ac3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f403dd0e-1d4c-429a-8ad1-5a0672bd3ac3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e41d503e-6770-4563-a83d-495421038355\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e41d503e-6770-4563-a83d-495421038355')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e41d503e-6770-4563-a83d-495421038355 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                  Text         Topic\n",
              "0    🇸🇬 Un ancien Airbus A380 de Singapore Airlines...         avion\n",
              "1    Deux Dassault Falcon 900LX pour la Royal Air F...         avion\n",
              "2    🔴 Israël vient d'annoncer l'interdiction des v...         avion\n",
              "3    Mais ce volet là est particulièrement importan...  décroissance\n",
              "4    Ce n’est pas le cas de #Malte, qui a peu de pl...     nucléaire\n",
              "..                                                 ...           ...\n",
              "492  On a été dans un des seuls resto un peu gastro...        viande\n",
              "494  @BShirizadeh @rogerseban @BridonneauV @Reclaim...     nucléaire\n",
              "495  La baisse des émissions carbone, c'est l'élect...     nucléaire\n",
              "497  Dans une nouvelle enquête #L214 montre des cas...        viande\n",
              "498  Entre les transactivistes myopes qui s'abonnen...        viande\n",
              "\n",
              "[194 rows x 2 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def process_json_file(filename):\n",
        "    # Open and read the JSON file\n",
        "    with open(filename, 'r', encoding='utf-8') as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    # Create an empty list to store the rows\n",
        "    rows = []\n",
        "\n",
        "    # Iterate over each key-value pair in the JSON data\n",
        "    for key, value in data.items():\n",
        "        # Extract the required fields from the value\n",
        "        topic = value.get('topic')\n",
        "        stance = value.get('stance')\n",
        "        text = value.get('text')\n",
        "        author = value.get('author')\n",
        "\n",
        "        # Create a row as a list with the extracted fields\n",
        "        row = [topic, stance, text, author]\n",
        "\n",
        "        # Add the row to the list of rows\n",
        "        rows.append(row)\n",
        "\n",
        "    # Create the DataFrame using the list of rows\n",
        "    df = pd.DataFrame(rows, columns=['Topic', 'Stance', 'Text', 'Author'])\n",
        "    # Remove \"Stance\" and \"Author\" columns\n",
        "    df = df.drop(['Stance', 'Author'], axis=1)\n",
        "\n",
        "    # Rearrange the columns\n",
        "    df = df[['Text', 'Topic']]\n",
        "    df = df[df['Topic'] != 'other']\n",
        "    df['Topic'] = df['Topic'].replace('nucleaire', 'nucléaire')\n",
        "\n",
        "    return df\n",
        "\n",
        "# Call the function with the filename and print the result\n",
        "df = process_json_file('results.json')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "W4vxYayu_wgn",
        "outputId": "288ecf43-d1b1-4224-c467-bd7ba8b28575"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-4-4745668d0312>:9: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  text = BeautifulSoup(text, 'html.parser').get_text()\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-51e6f110-3882-4d01-926c-3c952cd6a3cb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Singapore Un ancien Airbus A Singapore Airline...</td>\n",
              "      <td>avion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Deux Dassault Falcon LX pour Royal Air Force</td>\n",
              "      <td>avion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>red_circle Israel vient d'annoncer l'interdict...</td>\n",
              "      <td>avion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Mais ce volet est particulierement important P...</td>\n",
              "      <td>décroissance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ce nest pas cas Malte qui a peu place peu moye...</td>\n",
              "      <td>nucléaire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>492</th>\n",
              "      <td>On a ete dans un seuls resto un peu gastro veg...</td>\n",
              "      <td>viande</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>494</th>\n",
              "      <td>BShirizadeh rogerseban BridonneauV ReclaimFina...</td>\n",
              "      <td>nucléaire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>baisse emissions carbone c'est l'electrificati...</td>\n",
              "      <td>nucléaire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>Dans une nouvelle enquete L montre cas maltrai...</td>\n",
              "      <td>viande</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>Entre transactivistes myopes qui s'abonnent pu...</td>\n",
              "      <td>viande</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>194 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-51e6f110-3882-4d01-926c-3c952cd6a3cb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-51e6f110-3882-4d01-926c-3c952cd6a3cb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-51e6f110-3882-4d01-926c-3c952cd6a3cb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f556734f-38df-4b8e-a394-88f6410b86a3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f556734f-38df-4b8e-a394-88f6410b86a3')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f556734f-38df-4b8e-a394-88f6410b86a3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                  Text         Topic\n",
              "0    Singapore Un ancien Airbus A Singapore Airline...         avion\n",
              "1         Deux Dassault Falcon LX pour Royal Air Force         avion\n",
              "2    red_circle Israel vient d'annoncer l'interdict...         avion\n",
              "3    Mais ce volet est particulierement important P...  décroissance\n",
              "4    Ce nest pas cas Malte qui a peu place peu moye...     nucléaire\n",
              "..                                                 ...           ...\n",
              "492  On a ete dans un seuls resto un peu gastro veg...        viande\n",
              "494  BShirizadeh rogerseban BridonneauV ReclaimFina...     nucléaire\n",
              "495  baisse emissions carbone c'est l'electrificati...     nucléaire\n",
              "497  Dans une nouvelle enquete L montre cas maltrai...        viande\n",
              "498  Entre transactivistes myopes qui s'abonnent pu...        viande\n",
              "\n",
              "[194 rows x 2 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "\n",
        "def convert_emoji_to_text(input_text):\n",
        "    french_stopwords = ['le', 'la', 'les', 'de', 'du', 'des', 'je', 'tu', 'il', 'elle', 'nous', 'vous', 'ils', 'elles']\n",
        "\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', input_text)\n",
        "    text = emoji.demojize(text)\n",
        "\n",
        "    # Remove HTML tags\n",
        "    text = BeautifulSoup(text, 'html.parser').get_text()\n",
        "\n",
        "    # Remove non-alphanumeric characters except for certain characters that may form complete words\n",
        "    text = re.sub(r\"[^\\wÀ-ÿ\\s'-]\", '', text)\n",
        "\n",
        "    # Remove numbers\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "\n",
        "    # Remove multiple spaces\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "\n",
        "    # Convert accented characters to their ASCII equivalent\n",
        "    converted_text = unidecode.unidecode(text)\n",
        "\n",
        "    # Convert emojis to text representation\n",
        "\n",
        "\n",
        "    # Remove words that don't have any sense in French\n",
        "    converted_text = ' '.join([word for word in converted_text.split() if word.lower() not in french_stopwords])\n",
        "\n",
        "    return converted_text\n",
        "df['Text'] = df['Text'].apply(convert_emoji_to_text)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "ba26d44f04b94b87b5fcb91aa26b885b",
            "0c08707df1dc4a3e9f453dd77f892cb9",
            "55e07f86caa446bc92f59079e1fd3e1a",
            "f9fbea7ba1054fd9a95f11a3f9d32cfc",
            "627a6e86df9143229e0473528dd0189e",
            "3904831de1cf4812abe4e4e68f8041d1",
            "f3e2cfe95656420f858341b041e8c8c4",
            "251c0d15e8934c81a8bcc81db922aa3c",
            "fb013b809bd649a5a446c629668224b5",
            "ef4e012b7384490c9d92ac2caaf0de42",
            "50a8b3a628e7446e85c743a2ef0147c5",
            "d711aae23db840a8b1b9345278746fc1",
            "54808a869491405883544a70e3b39634",
            "becf1165f932483ead634174f352cd38",
            "7ff8534ab40846efa8136cd50144b7e5",
            "ddbb65d3f2904ccfbde80b8621e4002b",
            "53fd5cc5fdb942b7922da6f6beae9c1d",
            "2f1169c946fa49f58df1148e59e0673a",
            "9203bab8523b4baea7c2128ff5cf6cc8",
            "b9bd4edfccd340d5aad58f3746fcb75f",
            "fdb2990ef9a14c749e6093afe5f17b81",
            "13ac6963e60b4ba0a11287a4a04b30b1"
          ]
        },
        "id": "DK4BskxGAfEZ",
        "outputId": "0c430ce8-16ea-4d73-b0ff-57d1d2fbb2dc"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ba26d44f04b94b87b5fcb91aa26b885b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)tencepiece.bpe.model:   0%|          | 0.00/811k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d711aae23db840a8b1b9345278746fc1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/508 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "tokenizer = CamembertTokenizer.from_pretrained('camembert-base')\n",
        "\n",
        "labels = {'avion':0,\n",
        "          'décroissance':1,\n",
        "          'nucléaire':2,\n",
        "          'viande':3,\n",
        "          #'other':4\n",
        "          }\n",
        "\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, df):\n",
        "\n",
        "        self.labels = [labels[label] for label in df['Topic']]\n",
        "        self.texts = [tokenizer(text, padding='max_length', max_length=250, truncation=True, return_tensors=\"pt\") for text in df['Text']]\n",
        "\n",
        "    def classes(self):\n",
        "        return self.labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def get_batch_labels(self, idx):\n",
        "        # Fetch a batch of labels\n",
        "        return np.array(self.labels[idx])\n",
        "\n",
        "    def get_batch_texts(self, idx):\n",
        "        # Fetch a batch of inputs\n",
        "        return self.texts[idx]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        batch_texts = self.get_batch_texts(idx)\n",
        "        batch_y = self.get_batch_labels(idx)\n",
        "\n",
        "        return batch_texts, batch_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUCjjt7GBH4A",
        "outputId": "9cc9dfc5-ac36-40f3-fd49-f2b5d5314c3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "155 19 20\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def process_and_split_data(data_filename):\n",
        "    np.random.seed(112)\n",
        "\n",
        "    # Read the JSON data and process it\n",
        "    df = process_json_file(data_filename)\n",
        "\n",
        "    # Split the data into train, validation, and test sets\n",
        "    df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=42),\n",
        "                                         [int(.8*len(df)), int(.9*len(df))])\n",
        "\n",
        "    return df_train, df_val, df_test\n",
        "\n",
        "# Call the function to process and split the data\n",
        "df_train, df_val, df_test = process_and_split_data('results.json')\n",
        "\n",
        "print(len(df_train), len(df_val), len(df_test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlegvNYpBWG1"
      },
      "source": [
        "Partie 2 : Model classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pfN1LXUmBP1b"
      },
      "outputs": [],
      "source": [
        "class CamembertClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, dropout=0.5):\n",
        "\n",
        "        super(CamembertClassifier, self).__init__()\n",
        "\n",
        "        self.bert = CamembertModel.from_pretrained('camembert-base')\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear = nn.Linear(768, 4)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, input_id, mask = None):\n",
        "\n",
        "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
        "        dropout_output = self.dropout(pooled_output)\n",
        "        linear_output = self.linear(dropout_output)\n",
        "        final_layer = self.relu(linear_output)\n",
        "\n",
        "        return final_layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312,
          "referenced_widgets": [
            "e0f21bea6d7a4af49c24428fcf0327ae",
            "5be2e706625b476bb92b8773b08d6f93",
            "6316e29a817e4f3aa5ebba496bb07b53",
            "4eaed1dbc18e4c3c9ffcd332e9cc1398",
            "7591052b83184646b6ce6ed75693d7a7",
            "41e650a7f166453aad7a59a59133607c",
            "e69f1da37d394ae9ba54dedc16b09764",
            "c8f1fd79c4184ec39ad21f9369d0c475",
            "9fc2d14b00a741b6a74a08b4cc557b39",
            "b98016ec6e21448c94f190eda67bf9ca",
            "efe7647200d740969a99cb244c303290"
          ]
        },
        "id": "VBxrk-J_BQAR",
        "outputId": "2c9814ef-e29f-4832-c31b-9499ad255e35"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e0f21bea6d7a4af49c24428fcf0327ae",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/445M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 78/78 [00:12<00:00,  6.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 1 | Train Loss:  0.596                 | Train Accuracy:  0.561                 | Val Loss:  0.514                 | Val Accuracy:  0.684\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 78/78 [00:08<00:00,  8.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 2 | Train Loss:  0.367                 | Train Accuracy:  0.897                 | Val Loss:  0.316                 | Val Accuracy:  0.947\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 78/78 [00:08<00:00,  8.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 3 | Train Loss:  0.191                 | Train Accuracy:  0.974                 | Val Loss:  0.173                 | Val Accuracy:  1.000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 78/78 [00:09<00:00,  8.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 4 | Train Loss:  0.101                 | Train Accuracy:  1.000                 | Val Loss:  0.311                 | Val Accuracy:  0.789\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 78/78 [00:09<00:00,  8.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 5 | Train Loss:  0.061                 | Train Accuracy:  1.000                 | Val Loss:  0.073                 | Val Accuracy:  1.000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 78/78 [00:09<00:00,  8.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 6 | Train Loss:  0.038                 | Train Accuracy:  1.000                 | Val Loss:  0.049                 | Val Accuracy:  1.000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 78/78 [00:09<00:00,  8.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 7 | Train Loss:  0.028                 | Train Accuracy:  1.000                 | Val Loss:  0.034                 | Val Accuracy:  1.000\n"
          ]
        }
      ],
      "source": [
        "def train(model, train_data, val_data, learning_rate, epochs):\n",
        "\n",
        "    train, val = Dataset(train_data), Dataset(val_data)\n",
        "\n",
        "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=2, shuffle=True)\n",
        "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=2)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = Adam(model.parameters(), lr= learning_rate)\n",
        "\n",
        "    if use_cuda:\n",
        "\n",
        "            model = model.cuda()\n",
        "            criterion = criterion.cuda()\n",
        "\n",
        "    for epoch_num in range(epochs):\n",
        "\n",
        "            total_acc_train = 0\n",
        "            total_loss_train = 0\n",
        "\n",
        "            for train_input, train_label in tqdm(train_dataloader):\n",
        "\n",
        "                train_label = train_label.to(device)\n",
        "                mask = train_input['attention_mask'].to(device)\n",
        "                input_id = train_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "                output = model(input_id, mask)\n",
        "\n",
        "                batch_loss = criterion(output, train_label.long())\n",
        "                total_loss_train += batch_loss.item()\n",
        "\n",
        "                acc = (output.argmax(dim=1) == train_label).sum().item()\n",
        "                total_acc_train += acc\n",
        "\n",
        "                model.zero_grad()\n",
        "                batch_loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            total_acc_val = 0\n",
        "            total_loss_val = 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "\n",
        "                for val_input, val_label in val_dataloader:\n",
        "\n",
        "                    val_label = val_label.to(device)\n",
        "                    mask = val_input['attention_mask'].to(device)\n",
        "                    input_id = val_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "                    output = model(input_id, mask)\n",
        "\n",
        "                    batch_loss = criterion(output, val_label.long())\n",
        "                    total_loss_val += batch_loss.item()\n",
        "\n",
        "                    acc = (output.argmax(dim=1) == val_label).sum().item()\n",
        "                    total_acc_val += acc\n",
        "\n",
        "            print(\n",
        "                f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} \\\n",
        "                | Train Accuracy: {total_acc_train / len(train_data): .3f} \\\n",
        "                | Val Loss: {total_loss_val / len(val_data): .3f} \\\n",
        "                | Val Accuracy: {total_acc_val / len(val_data): .3f}')\n",
        "\n",
        "EPOCHS = 7\n",
        "model = CamembertClassifier()\n",
        "LR = 3e-5\n",
        "train(model, df_train, df_val, LR, EPOCHS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WASBvnCHCRR7"
      },
      "source": [
        "Partie 3 : Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 741
        },
        "id": "KZsw-JZEiC33",
        "outputId": "b2909c79-074f-4ec9-8bb4-a9c0dbe16920"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy:  1.000\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       avion       1.00      1.00      1.00         3\n",
            "décroissance       1.00      1.00      1.00         4\n",
            "   nucléaire       1.00      1.00      1.00         8\n",
            "      viande       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           1.00        20\n",
            "   macro avg       1.00      1.00      1.00        20\n",
            "weighted avg       1.00      1.00      1.00        20\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkwAAAHyCAYAAAAZTJFbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB3TUlEQVR4nO3dd1gU1xoG8HeXDrJgoykKKgIqKqIxxK5YQkSNLRo0dmNsQaPG3hU1scfeNRpj7zF2I3ZQ1AgaO6gINljBSNtz/+AyuoqyhIXdlfd3n3ludubM7DcDst9+58wZmRBCgIiIiIjeS67rAIiIiIj0HRMmIiIiomwwYSIiIiLKBhMmIiIiomwwYSIiIiLKBhMmIiIiomwwYSIiIiLKBhMmIiIiomwwYSIiIiLKBhMmIiIiomwwYSIiIiK99ddffyEgIABOTk6QyWTYsWOH2nYhBMaOHQtHR0dYWFjAz88PN27cUGvz7NkzBAYGQqFQwNbWFj169EBiYmKO4mDCRERERHorKSkJVapUwYIFC7LcPmPGDMybNw+LFy/G2bNnYWVlhaZNm+LVq1dSm8DAQFy9ehUHDx7Enj178Ndff6F37945ikPGh+8SERGRIZDJZNi+fTtatWoFIKO65OTkhB9++AFDhgwBACQkJMDe3h6rV69Ghw4dEBkZiQoVKuD8+fOoXr06AGD//v3w9/fH/fv34eTkpNF7G+fJGZFBUalUePjwIaytrSGTyXQdDhER5ZAQAi9evICTkxPk8rzpPHr16hVSUlK0ciwhxDufN2ZmZjAzM8vRce7cuYNHjx7Bz89PWmdjY4OaNWvi9OnT6NChA06fPg1bW1spWQIAPz8/yOVynD17Fl9++aVG78WEifDw4UM4OzvrOgwiIsql6OholCxZUuvHffXqFYpaWOIltNMpVahQoXfGEI0bNw7jx4/P0XEePXoEALC3t1dbb29vL2179OgR7Ozs1LYbGxujSJEiUhtNMGEiWFtbAwACYQlTsMKUH+bEROo6BCL6iChfvIBz+YrS33NtS0lJwUsIBMIq158TKRBYn5iI6OhoKBQKaX1Oq0v5jQkTSWVRU8iYMOWTN/9IEBFpS14PqzDXwudEZoehQqHI9d9CBwcHAEBsbCwcHR2l9bGxsahatarUJi4uTm2/tLQ0PHv2TNo/J3ETERERfZAcMshluVy0+MXc1dUVDg4OOHz4sLROqVTi7Nmz8PX1BQD4+voiPj4eYWFhUpsjR45ApVKhZs2aGr8XK0xERESkETlyX2nJ6f6JiYm4efOm9PrOnTsIDw9HkSJFUKpUKQQFBWHy5Mlwc3ODq6srxowZAycnJ+lOOk9PTzRr1gy9evXC4sWLkZqaiv79+6NDhw4a3yEHMGEiIiIiPRYaGooGDRpIrwcPHgwA6NKlC1avXo1hw4YhKSkJvXv3Rnx8PGrXro39+/fD3Nxc2mf9+vXo378/GjVqBLlcjjZt2mDevHk5ioPzMBGUSiVsbGzQTQuD+Ugzi5Pu6zoEIvqIKJVK2DiWQkJCQp6Mkcz8nOgjs4ZZLsdJJQuBxeJFnsWaV1hhIiIiIo3ooktOXxhq3ERERET5hhUmIiIi0kjmnW65OgYALc1/ma+YMBEREZFG2CVHRERERO/FChMRERFpRC7LWHJ1DO2Eku+YMBEREZFG2CVHRERERO/FChMRERFpRCaT5foBv4Y6PTITJiIiItJIQe6SY8JEREREGinIg74NNW4iIiKifMMKExEREWlEhtxXWjiGiYiIiD5qWns0igEy1LiJiIiI8g0rTERERKQR3iVHRERElA3eJUdERERE78UKExEREWmEXXJERERE2ZBDBnkuJwYw1ITJUOMmIiIiyjesMBEREZFGCvKgbyZMREREpBGOYSIiIiLKRkGuMBlq3ERERET5hhUmIiIi0kjGw3dzV2KSQWgnmHzGhImIiIg0wi45IiIiInovVpiIiIhII7xLjoiIiCgb7JIjIiIiovdihYmIiIg0op1nyeWyRKUjTJiIiIhII+ySIyIiIqL3YsKkZ1xcXDBnzhxdh6F15WrVRN/NqzDtZigWJ91HleZN32kTMHoIpt8Kw7wnN/H9nt9gV9ZVbbtlYVt0Xzkfs2MiMevBVXRe+DPMrCw/+L7GZmboMGsyfo66gjmx19F7/VJY2xVTa1O4pBP6bV2DeY9vYMbdcLSeMhpyI6Pcn7QBOLZkNUZ6+qJ/kXKYVi8Ad0IvfrB92LY9GOddH/2LlMPEGn64sv+I2nYhBHZN+hnDyvhgQNFymPNFR8TevJOHZ2BYeL3zH6+5dsm0tBgiJkx65vz58+jdu7euw9A6MytL3L8SgY2DRme5vcngvmjwXTdsGDgC0+sHICXpJQbs/BXGZmZSm+4r58PRszzmBnyNBW27wq1WTQT+MuOD79tu+jhU9m+MZZ2/xaymbWHraI8+G5ZJ22VyOfpvWwtjUxPMaNQSa3oPgm9gOwSMGaKdE9djoVt2YcvwSWg+IggjT+5DSa8KmN+yM5RxT7Jsf+tMKFZ07Y9a33TAqFN/oGpAUyzu0BMPrl6T2hyYtQhHF63C1/Om4sdju2FqZYH5LTsh9dWr/DotvcXrnf94zbUvs0sut4shYsKkZ4oXLw5Lyw9XTQzR1QNHsWviTwjfvT/L7Y369cAfM+bh0t4DePB3JFb1CoKtoz2qBmRUohzcy6FSkwZY13co7oZexK3T57FxyBhUb9sCNg72WR7TXGGNWl06YMvwibh+/BSiwq9gTZ/BKOtbA641qgEAKvjVg6OHG1b2GIj7lyMy4pz0E+r37gIjE5O8uRh64tD8ZajVrSM+++YrOHmWx9fzgmFiYY5Ta3/Psv2RhStQsXF9NBnUB44ebmgxdihKVa2EY0vWAMj45n14wQp8PmwAqjZvipJenui2bA7iY2IRvvvP/Dw1vcTrnf94zbUvc9B3bhdDxIRJy/bv34/atWvD1tYWRYsWRfPmzXHr1i0AwGeffYYff/xRrf3jx49hYmKCv/76C8C7XXJRUVFo2bIlChUqBIVCgfbt2yM2NlbaPn78eFStWhXr1q2Di4sLbGxs0KFDB7x48SLvT1ZLirmUgo2DPSKPnpDWvVK+wJ3z4ShT0wcAUKamD5KexyPq4mWpzbUjJyBUKrjW8M7yuKW9vWBsaqp23Nh/buFp1H2UqZmRMJX5xAcPrl7Dize+cUYcOg4LGwWcKpTX6nnqk7SUFERdvALPBrWldXK5HJ4N6uD2ubAs97l99gI83mgPZCSct89mtH9yNwrK2Dh4NqgjbbewUcC1RlXcPnshD87CcPB65z9ec9I2JkxalpSUhMGDByM0NBSHDx+GXC7Hl19+CZVKhcDAQGzcuBFCvH7w4O+//w4nJyfUqVPnnWOpVCq0bNkSz549w/Hjx3Hw4EHcvn0bX331lVq7W7duYceOHdizZw/27NmD48ePY9q0ae+NMTk5GUqlUm3RJYV9cQB4p0z+Iu4xFHYZ2xR2xfHi8VO17ar0dCQ9j5f2f/e4dkhNTsa/Cern9yLuCRT2dtJ7K+Meq23PfJ3Z5mOU+PQZVOnp0vXNZG1XDMrYx1nuo4x9DMVb47/ebJ/5/++2KQ5lXJy2QjdIvN75j9c8bxTkLjlOK6Blbdq0UXu9cuVKFC9eHBEREWjfvj2CgoIQEhIiJUgbNmxAx44dIZO9+xt0+PBhXLlyBXfu3IGzszMAYO3atahYsSLOnz+PGjVqAMhIrFavXg1ra2sAQOfOnXH48GFMmTIlyxiDg4MxYcIErZ0zEREVDDLkvtJioPkSK0zaduPGDXTs2BFlypSBQqGAi4sLgIyuteLFi6NJkyZYv349AODOnTs4ffo0AgMDszxWZGQknJ2dpWQJACpUqABbW1tERkZK61xcXKRkCQAcHR0R94FvOyNGjEBCQoK0REdH5+aUc+3D39r+/80u7jGsixdV2y43MoJVYdsPfFuMg4mZGSxsFG8dtxiUsXHSe7/9DTTzdWabj1GhokUgNzJ6p7qWUX17X8WueBZVwNftP1wp/HirdZrg9c5/vOakbUyYtCwgIADPnj3DsmXLcPbsWZw9exYAkJKSAgAIDAzEli1bkJqaig0bNsDLywteXl65ek+TtwYny2QyqFSq97Y3MzODQqFQW3Tpyd0oJDyKhUf912MHzK0L/X9cQMbYgdtnw2BV2Balqr6+Vu71a0Eml+PO+axvE7538QrSUlLUjmvvVgZFS5WUxhvcPheGEhU91JIxz4Z18W+CEjGRN7R6nvrE2NQUpby9cO3YSWmdSqXCtWMhKPOJT5b7lKlZTa09AEQeOSGNMyvmUgoKeztcOxYibf9XGotWLQ/OwnDweuc/XvO8wWkFSCuePn2K69evY/To0WjUqBE8PT3x/PlztTYtW7bEq1evsH//fmzYsOG91SUA8PT0RHR0tFoFKCIiAvHx8ahQoUKenUdeMLOyRMnKFVCyckbcxVycUbJyBRQu6QQA/7/zZCAq+zeGU0UPdH3rzpNH12/i7wNH0WnBDLj4VEXZT6ujw8zJCN2yCwmPMgbB2zo6YPyFY3DxqQogY+D4yTUb0XbaWJSv+xlKVfXCN4tn4daZUNw5n5EwRRw6jphrN9B1+VyU8PJEBb96aDFuKI4tXYO0/ye5Hyu/Ab0Qsuo3nP51M2Ku3cBv349Eyst/8Vnn9gCAVT2DsH3s67FwDfv2wNWDx3Bw7hI8un4Tu6fMwr0Ll1H/2y4AMhL1jLsd50t3O65+627HgozXO//xmmufXCbTymKIOIZJiwoXLoyiRYti6dKlcHR0RFRUFIYPH67WxsrKCq1atcKYMWMQGRmJjh07vvd4fn5+8PLyQmBgIObMmYO0tDT07dsX9erVQ/Xq1fP6dLSqdLUqGLx/s/S63fTxAIDTv27Cmm8H48CshTCztETgL9NhaaPAzdPnMb9VJ6QlJ0v7rOw+AB1mTUbQ3o0QKhUu7NyHTUPGStuNTIzh4F4OppYW0rrNP06AUKnw7fqlMDYzRcSh4/ht0Ehpu1CpsKBNF3w9Nxg/HtmF5KSXOLNhM3ZP+jkPr4Z+qN62BV48eYbdk2dCGfsYJStXwIAd66Ruh2f3H0D2xujMsp9WR49V87Fr4k/YOX4G7Mq6oM/G5ShR0UNq02Twd0h++RLr+w/HywQlyvnWwIAd62Bibp7v56dveL3zH685aZNMvHnLFuXaoUOHMHDgQNy+fRvu7u6YN28e6tevj+3bt6NVq1YAgD/++AP+/v6oW7cujh8/rra/i4sLgoKCEBQUBCBj7NOAAQOkO+6aNWuG+fPnw94+Y+6h8ePHY8eOHQgPD5eOMWfOHMyZMwd3797VKGalUgkbGxt0gxVMDbZYalgWJ93XdQhE9BFRKpWwcSyFhISEPBlmkfk5scqmGCxlueuceilU6JbwJM9izStMmIgJkw4wYSIibcqvhGm1lhKmrgaYMHEMExEREVE2OIaJiIiINKKNu9wMtR+DCRMRERFpRCaTZTnRco6OYaApExMmIiIi0khBrjBxDBMRERFRNlhhIiIiIo3IkftKi6FWapgwERERkUZksowlV8fQTij5zlATPSIiIqJ8wwoTERERaUT2///l9hiGiAkTERERaYR3yRERERHRe7HCRERERBopyBUmJkxERESkETkAeS4zHrnQSij5jl1yRERERNlghYmIiIg0wrvkiIiIiDRgmOlO7jFhIiIiIo1oZaZvA824OIaJiIiI9FZ6ejrGjBkDV1dXWFhYoGzZspg0aRKEeD16XAiBsWPHwtHRERYWFvDz88ONGze0GgcTJiIiItKITEtLTkyfPh2LFi3CL7/8gsjISEyfPh0zZszA/PnzpTYzZszAvHnzsHjxYpw9exZWVlZo2rQpXr16lavzfRO75IiIiEgjcsggz+Uoppzuf+rUKbRs2RJffPEFAMDFxQW//fYbzp07ByCjujRnzhyMHj0aLVu2BACsXbsW9vb22LFjBzp06JCreF/HTURERJTPlEql2pKcnJxlu88++wyHDx/GP//8AwC4dOkSQkJC8PnnnwMA7ty5g0ePHsHPz0/ax8bGBjVr1sTp06e1Fi8rTERERKQRbc707ezsrLZ+3LhxGD9+/Dvthw8fDqVSCQ8PDxgZGSE9PR1TpkxBYGAgAODRo0cAAHt7e7X97O3tpW3awISJiIiINKLNu+Sio6OhUCik9WZmZlm237RpE9avX48NGzagYsWKCA8PR1BQEJycnNClS5fcBZMDTJiIiIgo3ykUCrWE6X2GDh2K4cOHS2ORvLy8cO/ePQQHB6NLly5wcHAAAMTGxsLR0VHaLzY2FlWrVtVavBzDRERERBrRxV1yL1++hFyunq4YGRlBpVIBAFxdXeHg4IDDhw9L25VKJc6ePQtfX98cvtv7scJEREREGtHFo1ECAgIwZcoUlCpVChUrVsTFixcxa9YsdO/ePeN4MhmCgoIwefJkuLm5wdXVFWPGjIGTkxNatWqVq1jfxISJiIiI9Nb8+fMxZswY9O3bF3FxcXBycsK3336LsWPHSm2GDRuGpKQk9O7dG/Hx8ahduzb2798Pc3NzrcUhE29OlUkFklKphI2NDbrBCqYF9ilB+Wtx0n1dh0BEHxGlUgkbx1JISEjQaFzQfzq+jQ32FXOElTx3o3mSVCr4P4nJs1jzCitMREREpBFtTitgaJgwERERkUYKcsLEu+SIiIiIssEKExEREWlEF3fJ6QsmTERERKQRbc70bWjYJUdERESUDVaYiIiISCNy5L7SYqiVGiZMREREpBHeJUdERERE78UKExEREWlGJoOsgI76ZsJEREREGinIXXJMmEgyJybSoJ7rY8j6WJXUdQgFDp/fR0S5wYSJiIiINMIKExEREVE2ZFoYw5TrMVA6woSJiIiINCKXZSy5PYYh4rQCRERERNlghYmIiIg0IpPLIMtliYgP3yUiIqKPGh++S0RERETvxQoTERERaaQgV5iYMBEREZFGCvK0AuySIyIiIsoGK0xERESkEXbJEREREWWDXXJERERE9F6sMBEREZFG2CVHRERElA25TAZ5LjOe3O6vK0yYiIiISCMFucLEMUxERERE2WCFiYiIiDQigxbukuPDd4mIiOhjJpNnLLk6htBOLPmNXXJERERE2WCFiYiIiDSjhYkrDXXUNxMmIiIi0gjvkiMiIiKi92KFiYiIiDSSUWHK7bPktBRMPmPCRERERBphlxwRERERvRcrTERERKQRPkuOiIiIKBsFuUuOCRMRERFpRKaFeZhyPY+TjnAMExEREVE2WGEiIiIijbBLjoiIiCgbBTlhYpccERERUTZYYSIiIiKNyOQyyOS5HPQtDLPExISJiIiINMIuOSIiIiJ6L1aYiIiISCOc6ZuIiIgoG+ySIyIiIqL3YoWJiIiINMJHoxiAlJQUTJ06FZGRkboOhfLQsSWrMdLTF/2LlMO0egG4E3rxg+3Dtu3BOO/66F+kHCbW8MOV/UfUtgshsGvSzxhWxgcDipbDnC86IvbmnTw8A/1QrlZN9N28CtNuhmJx0n1Uad70nTYBo4dg+q0wzHtyE9/v+Q12ZV3VtlsWtkX3lfMxOyYSsx5cReeFP8PMyvKD72tsZoYOsybj56grmBN7Hb3XL4W1XTG1NoVLOqHf1jWY9/gGZtwNR+spoyE3Msr9SRsA/n7nP15z7ZLhdbfcf150fRL/kd4lTPXr10dQUNA763/44QdcuXIFHh4eOouB8lboll3YMnwSmo8IwsiT+1DSqwLmt+wMZdyTLNvfOhOKFV37o9Y3HTDq1B+oGtAUizv0xIOr16Q2B2YtwtFFq/D1vKn48dhumFpZYH7LTkh99Sq/TksnzKwscf9KBDYOGp3l9iaD+6LBd92wYeAITK8fgJSklxiw81cYm5lJbbqvnA9Hz/KYG/A1FrTtCrdaNRH4y4wPvm+76eNQ2b8xlnX+FrOatoWtoz36bFgmbZfJ5ei/bS2MTU0wo1FLrOk9CL6B7RAwZoh2TlyP8fc7//Gaa19mhSm3iyHSu4QpK5s2bcLVq1exZs2afLnQ27Ztw6RJk/L8fUjdofnLUKtbR3z2zVdw8iyPr+cFw8TCHKfW/p5l+yMLV6Bi4/poMqgPHD3c0GLsUJSqWgnHlqwBkPFN8PCCFfh82ABUbd4UJb080W3ZHMTHxCJ895/5eWr57uqBo9g18SeE796f5fZG/XrgjxnzcGnvATz4OxKregXB1tEeVQMyKlEO7uVQqUkDrOs7FHdDL+LW6fPYOGQMqrdtARsH+yyPaa6wRq0uHbBl+ERcP34KUeFXsKbPYJT1rQHXGtUAABX86sHRww0rewzE/csRGXFO+gn1e3eBkYlJ3lwMPcHf7/zHa07aZBAJU/v27XHkyBGYmprm6jgpKSkatStSpAisra1z9V6UM2kpKYi6eAWeDWpL6+RyOTwb1MHtc2FZ7nP77AV4vNEeyPhAvn02o/2Tu1FQxsbBs0EdabuFjQKuNari9tkLeXAWhqGYSynYONgj8ugJad0r5QvcOR+OMjV9AABlavog6Xk8oi5eltpcO3ICQqWCaw3vLI9b2tsLxqamaseN/ecWnkbdR5maGQlTmU988ODqNbx44xt+xKHjsLBRwKlCea2epz7h73f+4zXPI7ntjpPBYPvkdJowJSUl4ZtvvkGhQoXg6OiImTNnqm1PTk7GkCFDUKJECVhZWaFmzZo4duyYWpuTJ0+ifv36sLS0ROHChdG0aVM8f/4cQEbXWv/+/REUFIRixYqhadOMb8/Hjx/HJ598AjMzMzg6OmL48OFIS0uTjvl2l9zChQvh5uYGc3Nz2Nvbo23bttK2LVu2wMvLCxYWFihatCj8/PyQlJQEADh//jwaN26MYsWKwcbGBvXq1cOFC+r/qGQyGZYvX44vv/wSlpaWcHNzw65du9TaXL16Fc2bN4dCoYC1tTXq1KmDW7duSduXL18OT09PmJubw8PDAwsXLszhT0L3Ep8+gyo9HQq74mrrre2KQRn7OMt9lLGPoXhrfMyb7TP//902xaGMi9NW6AZHYZ9xjd/ulngR91i6/gq74njx+KnadlV6OpKex0v7v3tcO6QmJ+PfBOVbx30Chb2d9N7KOPWfZ+brzDYfI/5+5z9e87zBLjkdGTp0KI4fP46dO3fiwIEDOHbsmFpC0b9/f5w+fRobN27E5cuX0a5dOzRr1gw3btwAAISHh6NRo0aoUKECTp8+jZCQEAQEBCA9PV06xpo1a2BqaoqTJ09i8eLFePDgAfz9/VGjRg1cunQJixYtwooVKzB58uQsYwwNDcXAgQMxceJEXL9+Hfv370fdunUBADExMejYsSO6d++OyMhIHDt2DK1bt4YQAgDw4sULdOnSBSEhIThz5gzc3Nzg7++PFy9eqL3HhAkT0L59e1y+fBn+/v4IDAzEs2fPAAAPHjxA3bp1YWZmhiNHjiAsLAzdu3eXErz169dj7NixmDJlCiIjIzF16lSMGTMGa9asee91T05OhlKpVFuIiIjo/XQ2rUBiYiJWrFiBX3/9FY0aNQKQkdyULFkSABAVFYVVq1YhKioKTk5OAIAhQ4Zg//79WLVqFaZOnYoZM2agevXqahWVihUrqr2Pm5sbZsx4PVB11KhRcHZ2xi+//AKZTAYPDw88fPgQP/74I8aOHQu5XD2HjIqKgpWVFZo3bw5ra2uULl0a3t4ZXRIxMTFIS0tD69atUbp0aQCAl5eXtG/Dhg3VjrV06VLY2tri+PHjaN68ubS+a9eu6NixIwBg6tSpmDdvHs6dO4dmzZphwYIFsLGxwcaNG2Hy/zEe5cu/7roYN24cZs6cidatWwMAXF1dERERgSVLlqBLly5ZXvvg4GBMmDAhy226UqhoEciNjN6pPmRUJ95X0SieRZXkdfs3Kyk2jvZvtHmMkl7qvycFyZvfkpWPXn8rtrYrjvtXrma0iXsM6+JF1faTGxnBqrDtB76dx8HEzAwWNgq1KlPGN/Q46b1dqldV2y+zApDZ5mPE3+/8x2ueN2TyjCW3xzBEOgv71q1bSElJQc2aNaV1RYoUgbu7OwDgypUrSE9PR/ny5VGoUCFpOX78uNQdlVlh+hAfHx+115GRkfD19VUrCdaqVQuJiYm4f//+O/s3btwYpUuXRpkyZdC5c2esX78eL1++BABUqVIFjRo1gpeXF9q1a4dly5ZJ3YEAEBsbi169esHNzQ02NjZQKBRITExEVFSU2ntUrlxZ+m8rKysoFArE/b+8Gx4ejjp16kjJ0puSkpJw69Yt9OjRQ+0aTZ48Wa3L7m0jRoxAQkKCtERHR3/oEuYLY1NTlPL2wrVjJ6V1KpUK146FoMwnPlnuU6ZmNbX2ABB55IQ0DqeYSyko7O1w7ViItP1faaxOtTw4C8Pw5G4UEh7FwqP+67Ea5taF/j8OI2Osxu2zYbAqbItSVV9/AXCvXwsyuRx3zmd9W/a9i1eQlpKidlx7tzIoWqqkNL7j9rkwlKjooZaMeTasi38TlIiJvKHV89Qn/P3Of7zmeaMgd8np7cSViYmJMDIyQlhYGIzemqOlUKFCAAALC4tsj2NlZZWrOKytrXHhwgUcO3YMBw4cwNixYzF+/HicP38etra2OHjwIE6dOoUDBw5g/vz5GDVqFM6ePQtXV1d06dIFT58+xdy5c1G6dGmYmZnB19f3ncHnbydDMpkMKpUq23NMTEwEACxbtkwt8QTwzjV7k5mZGczeuH1cX/gN6IXVvQejtHdluFSviiMLViDl5b/4rHN7AMCqnkGwdXLAlxOHAwAa9u2BmU3b4eDcJfBq1gjnt+zCvQuXETh/GoCM65hxN9h82JVzRbHSztg16We1u8E+VmZWlihe1kV6XczFGSUrV0DSs3g8v//w/3f6DETczTt4ci8aLcYMUbvT59H1m/j7wFF0WjADGwaOgJGJMTrMnIzQLbuQ8CgWAGDr6ICgvRuxulcQ7oaF45XyBU6u2Yi208Yi6Xk8Xilf4KuZk3DrTCjunM9ImCIOHUfMtRvounwuto2eAht7O7QYNxTHlq5BmoY3ZRgq/n7nP15z0iadJUxly5aFiYkJzp49i1KlSgEAnj9/jn/++Qf16tWDt7c30tPTERcXhzp16mR5jMqVK+Pw4cM56l7y9PTE1q1bIYSQstyTJ0/C2tpa6g58m7GxMfz8/ODn54dx48bB1tYWR44cQevWrSGTyVCrVi3UqlULY8eORenSpbF9+3YMHjwYJ0+exMKFC+Hv7w8AiI6OxpMnWc//8T6VK1fGmjVrkJqa+k5iZW9vDycnJ9y+fRuBgYE5Oq4+qt62BV48eYbdk2dCGfsYJStXwIAd66Qy+LP7DyCTv/5mUvbT6uixaj52TfwJO8fPgF1ZF/TZuBwlKr6eq6vJ4O+Q/PIl1vcfjpcJSpTzrYEBO9bBxNw8388vP5WuVgWD92+WXrebPh4AcPrXTVjz7WAcmLUQZpaWCPxlOixtFLh5+jzmt+qEtORkaZ+V3Qegw6zJCNq7EUKlwoWd+7BpyFhpu5GJMRzcy8HU8nVSv/nHCRAqFb5dvxTGZqaIOHQcvw0aKW0XKhUWtOmCr+cG48cju5Cc9BJnNmzG7kk/5+HV0A/8/c5/vOZ5QC7LWHJ7DAMkE5kjlHXgu+++wx9//IGVK1fCzs4Oo0aNwpEjR9CjRw/MmTMHnTp1wsmTJzFz5kx4e3vj8ePHOHz4MCpXrowvvvgC//zzD7y8vNCjRw/06dMHpqamOHr0KNq1a4dixYqhfv36qFq1KubMmSO954MHD1C+fHl069YN/fv3x/Xr19GzZ0/069cP48ePBwC1/fbs2YPbt2+jbt26KFy4MPbt24f+/fvj8uXLSExMxOHDh9GkSRPY2dnh7Nmz6NSpE3bs2IHPP/8c1apVQ7FixTB37lwolUoMHToUoaGhmDp1qnQXnkwmw/bt29GqVSspRltbW8yZMwddu3bF06dP4e7ujnr16mHEiBGwsbHBmTNn8Mknn8Dd3R3Lly/HwIEDMW3aNDRr1gzJyckIDQ3F8+fPMXjwYI1+DkqlEjY2NkiIiYJCodDST5c+pI9V1sk55Z3FSe92uRN9LJRKJWwcSyEhISFP/o5nfk5E1a4EhXHuZuZXpqWjVMjfeRZrXtHp0KuffvoJderUQUBAAPz8/FC7dm21MUerVq3CN998gx9++AHu7u5o1aoVzp8/L1WkypcvjwMHDuDSpUv45JNP4Ovri507d8LY+P2FsxIlSmDfvn04d+4cqlSpgj59+qBHjx4YPTrrGZFtbW2xbds2NGzYEJ6enli8eDF+++03VKxYEQqFAn/99Rf8/f1Rvnx5jB49GjNnzsTnn38OAFixYgWeP3+OatWqoXPnzhg4cCDs7HJ263TRokVx5MgRJCYmol69evDx8cGyZcukalPPnj2xfPlyrFq1Cl5eXqhXrx5Wr14NV1fXbI5MRERkGB48eIBOnTqhaNGisLCwgJeXF0JDQ6XtQgiMHTsWjo6OsLCwgJ+fn3RHvbbotMJE+oEVpvzHClP+Y4WJPmb5VWGKruOllQqT84krGsf6/PlzeHt7o0GDBvjuu+9QvHhx3LhxA2XLlkXZsmUBANOnT0dwcDDWrFkDV1dXjBkzBleuXEFERATMtdRdqreDvomIiEjP6GAM0/Tp0+Hs7IxVq1ZJ697sRRFCYM6cORg9ejRatmwJAFi7di3s7e2xY8cOdOjQIXfxZoatlaMQERHRxy+3z0WRno+CdyZQTn7jppM37dq1C9WrV0e7du1gZ2cHb29vLFv2+qHed+7cwaNHj+Dn5yets7GxQc2aNXH69GmtnToTJiIiIsp3zs7OsLGxkZbg4OAs292+fRuLFi2Cm5sb/vzzT3z33XcYOHCg9ESLR48eAci4c/xN9vb20jZtYJccERERaUQml6lNxfBfjwFkTLXz5him980PqFKpUL16dUydOhUA4O3tjb///huLFy9+7xMt8gIrTERERKQZLXbJKRQKteV9CZOjoyMqVKigts7T01N6aoaDgwOAjKdrvCk2Nlbapg1MmIiIiEhv1apVC9evX1db988//0jPcHV1dYWDgwMOHz4sbVcqlTh79ix8fX21Fge75IiIiEgjMpkWuuRy+Cy5QYMG4bPPPsPUqVPRvn17nDt3DkuXLsXSpUul4wUFBWHy5Mlwc3OTphVwcnJSmxQ6tzRKmHbt2qXxAVu0aPGfgyEiIiI99kaXWq6OkQM1atTA9u3bMWLECEycOBGurq6YM2eO2iPBhg0bhqSkJPTu3Rvx8fGoXbs29u/fr7U5mAANJ66UyzXruZPJZEhPT891UJS/OHFl/uPElfmPE1fSxyy/Jq580NgHCpNcTlyZmo4SB8MM7tEoGlWYVCpVXsdBRERE+k4OLUxcqZVI8l2uxjC9evVKq+UuIiIi0l8ymSzHY5CyOoYhynGel56ejkmTJqFEiRIoVKgQbt++DQAYM2YMVqxYofUAiYiIiHQtxwnTlClTsHr1asyYMQOmpqbS+kqVKmH58uVaDY6IiIj0SOaz5HK7GKAcJ0xr167F0qVLERgYCCOj1wO/qlSpgmvXrmk1OCIiItIjWpy40tDkeAzTgwcPUK5cuXfWq1QqpKamaiUoIiIi0j8yecaS22MYohyHXaFCBZw4ceKd9Vu2bIG3t7dWgiIiIiLSJzmuMI0dOxZdunTBgwcPoFKpsG3bNly/fh1r167Fnj178iJGIiIi0gc6mLhSX+S4wtSyZUvs3r0bhw4dgpWVFcaOHYvIyEjs3r0bjRs3zosYiYiISA/I5DKtLIboP83DVKdOHRw8eFDbsRARERHppf88cWVoaCgiIyMBZIxr8vHx0VpQREREpIcKcJdcjhOm+/fvo2PHjjh58iRsbW0BAPHx8fjss8+wceNGlCzJZ2QRERF9lLQxj5KBdsnleAxTz549kZqaisjISDx79gzPnj1DZGQkVCoVevbsmRcxEhEREelUjitMx48fx6lTp+Du7i6tc3d3x/z581GnTh2tBkdERET6oyA/Sy7HCZOzs3OWE1Smp6fDyclJK0ERERGRHmKXnOZ++uknDBgwAKGhodK60NBQfP/99/j555+1GhwRERGRPtCowlS4cGG1ElpSUhJq1qwJY+OM3dPS0mBsbIzu3bujVatWeRIoERER6Zo2ngVnmBUmjRKmOXPm5HEYREREpO84hikbXbp0yes4iIiISN8V4DFM/3niSgB49eoVUlJS1NYpFIpcBURERESkb3I86DspKQn9+/eHnZ0drKysULhwYbWFiIiIPk6ZXXK5XQxRjhOmYcOG4ciRI1i0aBHMzMywfPlyTJgwAU5OTli7dm1exEhERET6ILNLLreLAcpxl9zu3buxdu1a1K9fH926dUOdOnVQrlw5lC5dGuvXr0dgYGBexElERESkMzmuMD179gxlypQBkDFe6dmzZwCA2rVr46+//tJudERERKQ/Mh++m9vFAOU4YSpTpgzu3LkDAPDw8MCmTZsAZFSeMh/GS0RERB8fmVymlcUQ5Thh6tatGy5dugQAGD58OBYsWABzc3MMGjQIQ4cO1XqARERERLqW4zFMgwYNkv7bz88P165dQ1hYGMqVK4fKlStrNTgiIiLSI9roUjPQLrlczcMEAKVLl0bp0qW1EQsRERHpMzm0MHGlViLJdxolTPPmzdP4gAMHDvzPwRAREZH+4qNRsjF79myNDiaTyZgwERER0UdHo4Qp8644ItKOxUn3dR1CgdPHqqSuQyhQ+Dv+keKz5IiIiIiyUYAHfRvo0CsiIiKi/MMKExEREWmmAFeYmDARERGRhrTxaBPDTJjYJUdERESUjf+UMJ04cQKdOnWCr68vHjx4AABYt24dQkJCtBocERER6RG5XDuLAcpx1Fu3bkXTpk1hYWGBixcvIjk5GQCQkJCAqVOnaj1AIiIi0hOZY5hyuxigHCdMkydPxuLFi7Fs2TKYmJhI62vVqoULFy5oNTgiIiIifZDjQd/Xr19H3bp131lvY2OD+Ph4bcRERERE+qgA3yWX4wqTg4MDbt68+c76kJAQlClTRitBERERkR5il5zmevXqhe+//x5nz56FTCbDw4cPsX79egwZMgTfffddXsRIRERE+qAAD/rOcZfc8OHDoVKp0KhRI7x8+RJ169aFmZkZhgwZggEDBuRFjEREREQ6leOESSaTYdSoURg6dChu3ryJxMREVKhQAYUKFcqL+IiIiEhfFOAxTP95pm9TU1NUqFBBm7EQERGRPmPCpLkGDRpA9oGTPXLkSK4CIiIiItI3OU6YqlatqvY6NTUV4eHh+Pvvv9GlSxdtxUVERET6hhUmzc2ePTvL9ePHj0diYmKuAyIiIiI9pY273Az0LjmtRd2pUyesXLlSW4cjIiIi0hv/edD3206fPg1zc3NtHY6IiIj0DbvkNNe6dWu110IIxMTEIDQ0FGPGjNFaYERERKRnZNBCwqSVSPJdjhMmGxsbtddyuRzu7u6YOHEimjRporXAiIiIiPRFjhKm9PR0dOvWDV5eXihcuHBexURERET6qAB3yeVo0LeRkRGaNGmC+Pj4PAqHiIiI9JVMLtfKYohyHHWlSpVw+/btvIiFiIiI9JrsdZXpvy4GOogpxwnT5MmTMWTIEOzZswcxMTFQKpVqCxEREdHHRuMxTBMnTsQPP/wAf39/AECLFi3UHpEihIBMJkN6err2oyQiIiLdK8BjmDROmCZMmIA+ffrg6NGjeRkPERER6SsmTNkTQgAA6tWrl2fBEBEREemjHE0rIDPQrJCIiIi0oAA/Sy5HCVP58uWzTZqePXuWq4CIiIhIT7FLTjMTJkx4Z6ZvIiIioo9djhKmDh06wM7OLq9iISIiIn1WgCtMGnckcvwSERFRAZfbSStzmXBNmzYNMpkMQUFB0rpXr16hX79+KFq0KAoVKoQ2bdogNjZWCyerTuOEKfMuOSIiIqL8dv78eSxZsgSVK1dWWz9o0CDs3r0bmzdvxvHjx/Hw4UO0bt1a6++vccKkUqnYHUdERFSQZd4ll9slhxITExEYGIhly5ahcOHC0vqEhASsWLECs2bNQsOGDeHj44NVq1bh1KlTOHPmjDbPPOePRiEiIqICSotdcm8/Wi05Ofm9b9uvXz988cUX8PPzU1sfFhaG1NRUtfUeHh4oVaoUTp8+rdVTZ8JEREREmtFiwuTs7AwbGxtpCQ4OzvItN27ciAsXLmS5/dGjRzA1NYWtra3aent7ezx69Eirp56ju+SIiIiItCE6OhoKhUJ6bWZmlmWb77//HgcPHoS5uXl+hvcOJkxERESkGS3O9K1QKNQSpqyEhYUhLi4O1apVk9alp6fjr7/+wi+//II///wTKSkpiI+PV6syxcbGwsHBIXdxvh22Vo9GWZo7d67W+1I/VseWrMZIT1/0L1IO0+oF4E7oxQ+2D9u2B+O866N/kXKYWMMPV/YfUdsuhMCuST9jWBkfDChaDnO+6IjYm3fy8AwMC6+3dpSrVRN9N6/CtJuhWJx0H1WaN32nTcDoIZh+KwzzntzE93t+g11ZV7XtloVt0X3lfMyOicSsB1fReeHPMLOy/OD7GpuZocOsyfg56grmxF5H7/VLYW1XTK1N4ZJO6Ld1DeY9voEZd8PRespoyI2Mcn/SBoK/41omgxa65DR/u0aNGuHKlSsIDw+XlurVqyMwMFD6bxMTExw+fFja5/r164iKioKvr69WT50JkxZ07doVrVq1ynLbzJkzsW3bNrXsOLfH/FiFbtmFLcMnofmIIIw8uQ8lvSpgfsvOUMY9ybL9rTOhWNG1P2p90wGjTv2BqgFNsbhDTzy4ek1qc2DWIhxdtApfz5uKH4/thqmVBea37ITUV6/y67T0Fq+39phZWeL+lQhsHDQ6y+1NBvdFg++6YcPAEZhePwApSS8xYOevMH6jC6L7yvlw9CyPuQFfY0HbrnCrVROBv8z44Pu2mz4Olf0bY1nnbzGraVvYOtqjz4Zl0naZXI7+29bC2NQEMxq1xJreg+Ab2A4BY4Zo58T1HH/HDZ+1tTUqVaqktlhZWaFo0aKoVKkSbGxs0KNHDwwePBhHjx5FWFgYunXrBl9fX3z66adajYUJUx46efIk1q1bh507d2bZN/shc+fOxerVq/MmMD11aP4y1OrWEZ998xWcPMvj63nBMLEwx6m1v2fZ/sjCFajYuD6aDOoDRw83tBg7FKWqVsKxJWsAZHwTPLxgBT4fNgBVmzdFSS9PdFs2B/ExsQjf/Wd+nppe4vXWnqsHjmLXxJ8Qvnt/ltsb9euBP2bMw6W9B/Dg70is6hUEW0d7VA3IqEQ5uJdDpSYNsK7vUNwNvYhbp89j45AxqN62BWwc7LM8prnCGrW6dMCW4RNx/fgpRIVfwZo+g1HWtwZca2R8QavgVw+OHm5Y2WMg7l+OyIhz0k+o37sLjExM8uZi6BH+jucBHU9cmZXZs2ejefPmaNOmDerWrQsHBwds27ZNq+8BMGHKU7Vq1UJ4ePg7o/c1YWNj88H9UlJS/ntgeigtJQVRF6/As0FtaZ1cLodngzq4fS4sy31un70AjzfaAxkfELfPZrR/cjcKytg4eDaoI223sFHAtUZV3D57IQ/OwnDweuefYi6lYONgj8ijJ6R1r5QvcOd8OMrU9AEAlKnpg6Tn8Yi6eFlqc+3ICQiVCq41vLM8bmlvLxibmqodN/afW3gadR9lamYkTGU+8cGDq9fw4o2KSsSh47CwUcCpQnmtnqe+4e94HtGDhOnYsWOYM2eO9Nrc3BwLFizAs2fPkJSUhG3btml9/BJQQBKm+vXrY+DAgRg2bBiKFCkCBwcHjB8/HgBw9+5dyGQyhIeHS+3j4+Mhk8lw7Ngxad3Vq1fRvHlzKBQKWFtbo06dOrh161aW76dSqRAcHAxXV1dYWFigSpUq2LJli7Q9PT0dPXr0kLa7u7tj7ty5asd4u0uufv366N+/P4KCglCsWDE0bZrxzfTvv//G559/jkKFCsHe3h6dO3fGkydZl5v1WeLTZ1Clp0NhV1xtvbVdMShjH2e5jzL2MRRvjdd4s33m/7/bpjiUcXHaCt0g8XrnH4V9xjV+uxvoRdxj6for7IrjxeOnattV6elIeh4v7f/uce2QmpyMfxOUbx33CRT2dtJ7K+PUf56ZrzPbfKz4O07aViASJgBYs2YNrKyscPbsWcyYMQMTJ07EwYMHNdr3wYMHqFu3LszMzHDkyBGEhYWhe/fuSEtLy7J9cHAw1q5di8WLF+Pq1asYNGgQOnXqhOPHjwPISKhKliyJzZs3IyIiAmPHjsXIkSOxadOmbM/B1NQUJ0+exOLFixEfH4+GDRvC29sboaGh2L9/P2JjY9G+ffsPHic5OfmdCcOIiIiyJdPCLN8yw0w9Csy0ApUrV8a4ceMAAG5ubvjll19w+PBhuLm5ZbvvggULYGNjg40bN8Lk//3+5ctnXc5OTk7G1KlTcejQIWmEfpkyZRASEoIlS5agXr16MDExwYQJE6R9XF1dcfr0aWzatOmDyY6bmxtmzHg9CHTy5Mnw9vbG1KlTpXUrV66Es7Mz/vnnn/fGGBwcrPb++qBQ0SKQGxm9820449vy+75hF8/iW/vr9m9+s7dxtH+jzWOU9KqozfANDq93/nmzKqF89LoKYW1XHPevXM1oE/cY1sWLqu0nNzKCVWHbD1RD4mBiZgYLG4ValSmjIhInvbdL9apq+2VWXDLbfKz4O55HtDEGSctjmPKLYaZ5/8HbD+tzdHREnIYl1PDwcNSpU0dKlj7k5s2bePnyJRo3boxChQpJy9q1a9W68BYsWAAfHx8UL14chQoVwtKlSxEVFfXBY/v4+Ki9vnTpEo4ePar2Ph4eHgDw3u5CABgxYgQSEhKkJTo6OtvzymvGpqYo5e2Fa8dOSutUKhWuHQtBmU98stynTM1qau0BIPLICWlcSDGXUlDY2+HasRBp+7/S2JGc3bX4seH1zj9P7kYh4VEsPOq/Hhtjbl3o/+NeMsbG3D4bBqvCtihV1Utq416/FmRyOe6cz/o2+HsXryAtJUXtuPZuZVC0VElpPM3tc2EoUdFDLRnzbFgX/yYoERN5Q6vnqW/4O07aVmAqTG8nOzKZDCqVCvL/T6AlhJC2paamqrW1sLDQ+H0SExMBAHv37kWJEiXUtmXeKbdx40YMGTIEM2fOhK+vL6ytrfHTTz/h7NmzHzy2lZXVO+8VEBCA6dOnv9PW0dHxvccxMzPL8V17+cFvQC+s7j0Ypb0rw6V6VRxZsAIpL//FZ50zqm6regbB1skBX04cDgBo2LcHZjZth4Nzl8CrWSOc37IL9y5cRuD8aQAyfsYZdyfNh105VxQr7Yxdk35WuzupIOP11h4zK0sUL+sivS7m4oySlSsg6Vk8nt9/+P87qwYi7uYdPLkXjRZjhqjdWfXo+k38feAoOi2YgQ0DR8DIxBgdZk5G6JZdSHgUCwCwdXRA0N6NWN0rCHfDwvFK+QIn12xE22ljkfQ8Hq+UL/DVzEm4dSYUd85nJEwRh44j5toNdF0+F9tGT4GNvR1ajBuKY0vXIO0ju3EkK/wdzwMFuMJUYBKm9ylePKPEGhMTA2/vjLtR3hwADmRUp9asWYPU1NRsq0wVKlSAmZkZoqKiUK9evSzbnDx5Ep999hn69u0rrftQReh9qlWrhq1bt8LFxQXGxob/o6zetgVePHmG3ZNnQhn7GCUrV8CAHeukMviz+w8gk7/+h1b20+rosWo+dk38CTvHz4BdWRf02bgcJSp6SG2aDP4OyS9fYn3/4XiZoEQ53xoYsGMdTHQ8xb4+4PXWntLVqmDw/s3S63bTxwMATv+6CWu+HYwDsxbCzNISgb9Mh6WNAjdPn8f8Vp2Q9sbDRld2H4AOsyYjaO9GCJUKF3buw6YhY6XtRibGcHAvB1PL11/gNv84AUKlwrfrl8LYzBQRh47jt0Ejpe1CpcKCNl3w9dxg/HhkF5KTXuLMhs3YPennPLwa+oO/43lApoUxSAY6hkkm3iytfKTq16+PqlWrqt2G2KpVK9ja2mL16tXw9fWFiYkJlixZgri4OAwbNgznzp3D0aNHUb9+fTx9+hTu7u6oV68eRowYARsbG5w5cwaffPIJ3N3d0bVrV8THx2PHjh0AgNGjR2Px4sWYOXMmateujYSEBJw8eRIKhQJdunTBvHnzMGbMGGzatAmurq5Yt24d5s2bB1dXVylZe/uYWZ3Dw4cPUbVqVdSrV0+6A/DmzZvYuHEjli9fDiMNZ/NVKpWwsbFBQkxUttPUExmqPlYldR1CgbI46b6uQyhQlEolbBxLISEhIU/+jmd+TjybFQSFRe56KJT/JqPI4Dl5FmteMcw0T8tWrlyJtLQ0+Pj4ICgoCJMnT1bbXrRoURw5cgSJiYmoV68efHx8sGzZsvdWmyZNmoQxY8YgODgYnp6eaNasGfbu3QtX14xHIXz77bdo3bo1vvrqK9SsWRNPnz5VqzZpysnJCSdPnkR6ejqaNGkCLy8vBAUFwdbWVupqJCIiotwrEBUm+jBWmKggYIUpf7HClL/yrcI0e7B2KkyDZhlchcnwB74QERFR/ijAg77Zb0NERESUDVaYiIiISDOZs3Xn9hgGiAkTERERaYZdckRERET0PqwwERERkWYK8MSVTJiIiIhIMzJooUtOK5HkO8NM84iIiIjyEStMREREpBneJUdERESUjQJ8lxwTJiIiItJMAR70bZhRExEREeUjVpiIiIhIMzIZIGeXHBEREdH7sUuOiIiIiN6HFSYiIiLSDO+SIyIiIsoGu+SIiIiI6H1YYSIiIiLNyLVwl1xu99cRJkxERESkmQI8holdckRERETZYIWJiIiINFOAB30zYSIiIiLNcAwTERERUTZkMi1UmAwzYTLMuhgRERFRPmKFiYiIiDRTgO+SY8JEREREminAg74NM2oiIiKifMQKExEREWmGd8kRERERZYNdckRERET0PqwwERERkWZ4lxwRERFRNuTyjCW3xzBAhhk1ERERUT5ihYmIiIg0pIUuObBLjoiIiD5mBfguOSZMREREpJkCPOjbMNM8IiIionzEChMRERFppgDfJceEiYgKhMVJ93UdQoHSx6qkrkMoUFIg8ueN2CVHRERERO/DChMRERFpRibTwl1yhllhYsJEREREmmGXHBERERG9DytMREREpBlOXElERESUDbksY8ntMQyQYaZ5RERERPmIFSYiIiLSDLvkiIiIiLJRgO+SY8JEREREminAFSbDjJqIiIgoH7HCRERERBqRyWSQ5bJLLbf76woTJiIiItIMu+SIiIiI6H2YMBEREZFmMitMuV1yIDg4GDVq1IC1tTXs7OzQqlUrXL9+Xa3Nq1ev0K9fPxQtWhSFChVCmzZtEBsbq80zZ8JEREREGpLJXs/2/V+XHI5hOn78OPr164czZ87g4MGDSE1NRZMmTZCUlCS1GTRoEHbv3o3Nmzfj+PHjePjwIVq3bq3VU+cYJiIiItJb+/fvV3u9evVq2NnZISwsDHXr1kVCQgJWrFiBDRs2oGHDhgCAVatWwdPTE2fOnMGnn36qlThYYSIiIiLNaLFLTqlUqi3JyckahZCQkAAAKFKkCAAgLCwMqamp8PPzk9p4eHigVKlSOH36tNZOnQkTERERaSZzpu/cLgCcnZ1hY2MjLcHBwdm+vUqlQlBQEGrVqoVKlSoBAB49egRTU1PY2tqqtbW3t8ejR4+0durskiMiIqJ8Fx0dDYVCIb02MzPLdp9+/frh77//RkhISF6GliUmTERERKQZmUwL8zBlVJgUCoVawpSd/v37Y8+ePfjrr79QsmRJab2DgwNSUlIQHx+vVmWKjY2Fg4ND7mJ9A7vkiIiISDNa7JLTlBAC/fv3x/bt23HkyBG4urqqbffx8YGJiQkOHz4srbt+/TqioqLg6+urldMGWGEiIiIiTelgpu9+/fphw4YN2LlzJ6ytraVxSTY2NrCwsICNjQ169OiBwYMHo0iRIlAoFBgwYAB8fX21doccwISJiIiI9NiiRYsAAPXr11dbv2rVKnTt2hUAMHv2bMjlcrRp0wbJyclo2rQpFi5cqNU4mDARERGRZjInn8ztMXJACJFtG3NzcyxYsAALFiz4r1FliwkTERERaYYP3yUiIiKi92GFiYiIiDTzH+5yy/IYBogJExEREWmGXXJERERE9D6sMBEREZFm2CVHRERElA12yRERERHR+7DCRERERJqRyzOW3B7DADFhIiIiIo3IZDLIcjkGKbf76woTJiIiItKMTKaFMUyGmTAZZl2MiIiIKB+xwkRERESa4bQCRERERNnRwrQCBtq5ZZhRExEREeUjJkxaMn78eFStWjXP3+fYsWOQyWSIj4/P8/fShWNLVmOkpy/6FymHafUCcCf04gfbh23bg3He9dG/SDlMrOGHK/uPqG0XQmDXpJ8xrIwPBhQthzlfdETszTt5eAaGhdc7f/F6a0+5WjXRd/MqTLsZisVJ91GledN32gSMHoLpt8Iw78lNfL/nN9iVdVXbblnYFt1XzsfsmEjMenAVnRf+DDMryw++r7GZGTrMmoyfo65gTux19F6/FNZ2xdTaFC7phH5b12De4xuYcTccraeMhtzIKPcnrQ8yu+RyuxggJkxaMmTIEBw+fFjXYRi00C27sGX4JDQfEYSRJ/ehpFcFzG/ZGcq4J1m2v3UmFCu69ketbzpg1Kk/UDWgKRZ36IkHV69JbQ7MWoSji1bh63lT8eOx3TC1ssD8lp2Q+upVfp2W3uL1zl+83tplZmWJ+1cisHHQ6Cy3NxncFw2+64YNA0dgev0ApCS9xICdv8LYzExq033lfDh6lsfcgK+xoG1XuNWqicBfZnzwfdtNH4fK/o2xrPO3mNW0LWwd7dFnwzJpu0wuR/9ta2FsaoIZjVpiTe9B8A1sh4AxQ7Rz4rqWOQ9TbhcDZJhR66FChQqhaNGiug7DoB2avwy1unXEZ998BSfP8vh6XjBMLMxxau3vWbY/snAFKjaujyaD+sDRww0txg5FqaqVcGzJGgAZ374PL1iBz4cNQNXmTVHSyxPdls1BfEwswnf/mZ+nppd4vfMXr7d2XT1wFLsm/oTw3fuz3N6oXw/8MWMeLu09gAd/R2JVryDYOtqjakBGJcrBvRwqNWmAdX2H4m7oRdw6fR4bh4xB9bYtYONgn+UxzRXWqNWlA7YMn4jrx08hKvwK1vQZjLK+NeBaoxoAoIJfPTh6uGFlj4G4fzkiI85JP6F+7y4wMjHJm4tB+YIJk4aWLl0KJycnqFQqtfUtW7ZE9+7d3+mSO3/+PBo3boxixYrBxsYG9erVw4ULF9T2lclkWL58Ob788ktYWlrCzc0Nu3btUmuzb98+lC9fHhYWFmjQoAHu3r37TmwhISGoU6cOLCws4OzsjIEDByIpKUlr554f0lJSEHXxCjwb1JbWyeVyeDaog9vnwrLc5/bZC/B4oz2Q8cfq9tmM9k/uRkEZGwfPBnWk7RY2CrjWqIrbZ9V/FgUNr3f+4vXOX8VcSsHGwR6RR09I614pX+DO+XCUqekDAChT0wdJz+MRdfGy1ObakRMQKhVca3hnedzS3l4wNjVVO27sP7fwNOo+ytTMSJjKfOKDB1ev4cUblcOIQ8dhYaOAU4XyWj1PnWCXHGWnXbt2ePr0KY4ePSqte/bsGfbv34/AwMB32r948QJdunRBSEgIzpw5Azc3N/j7++PFixdq7SZMmID27dvj8uXL8Pf3R2BgIJ49ewYAiI6ORuvWrREQEIDw8HD07NkTw4cPV9v/1q1baNasGdq0aYPLly/j999/R0hICPr3758HVyHvJD59BlV6OhR2xdXWW9sVgzL2cZb7KGMfQ/HW2IE322f+/7ttikMZF6et0A0Sr3f+4vXOXwr7jOv8dnfni7jH0s9AYVccLx4/VduuSk9H0vN4af93j2uH1ORk/JugfOu4T6Cwt5PeWxmn/jPNfJ3ZxqBlPnw3t4sBMsyodaBw4cL4/PPPsWHDBmndli1bUKxYMTRo0OCd9g0bNkSnTp3g4eEBT09PLF26FC9fvsTx48fV2nXt2hUdO3ZEuXLlMHXqVCQmJuLcuXMAgEWLFqFs2bKYOXMm3N3dERgYiK5du6rtHxwcjMDAQAQFBcHNzQ2fffYZ5s2bh7Vr1+LVe8YxJCcnQ6lUqi1ERET0fkyYciAwMBBbt25FcnIyAGD9+vXo0KED5FkMYIuNjUWvXr3g5uYGGxsbKBQKJCYmIioqSq1d5cqVpf+2srKCQqFA3P+/HUZGRqJmzZpq7X19fdVeX7p0CatXr0ahQoWkpWnTplCpVLhzJ+u7ZYKDg2FjYyMtzs7OOb8YWlaoaBHIjYze+WaW8c3tfd/2imfxDfJ1+w9/y/wIvunlAq93/uL1zl8frr79v0IX9xjWxdXHncqNjGBV2PYDVb84mJiZwcJG8dZxi0EZGye999uVxMzXmW0MGrvkSBMBAQEQQmDv3r2Ijo7GiRMnsuyOA4AuXbogPDwcc+fOxalTpxAeHo6iRYsiJSVFrZ3JW4MAZTLZO+OkPiQxMRHffvstwsPDpeXSpUu4ceMGypYtm+U+I0aMQEJCgrRER0dr/H55xdjUFKW8vXDt2ElpnUqlwrVjISjziU+W+5SpWU2tPQBEHjkhjVEo5lIKCns7XDsWIm3/VxrHUC0PzsJw8HrnL17v/PXkbhQSHsXCo/7rMWDm1oX+P74rYwzY7bNhsCpsi1JVvaQ27vVrQSaX4875rKd7uHfxCtJSUtSOa+9WBkVLlZTGjd0+F4YSFT3UkjHPhnXxb4ISMZE3tHqeuiHT0mJ4ONN3Dpibm6N169ZYv349bt68CXd3d1SrlvUfppMnT2LhwoXw9/cHkDEe6cmTrG8ffh9PT893BoGfOXNG7XW1atUQERGBcuXKaXxcMzMzmL1xa62+8BvQC6t7D0Zp78pwqV4VRxasQMrLf/FZ5/YAgFU9g2Dr5IAvJ2aM42rYtwdmNm2Hg3OXwKtZI5zfsgv3LlxG4PxpADKSz4w7ZebDrpwripV2xq5JP6vdKVOQ8XrnL15v7TKzskTxsi7S62IuzihZuQKSnsXj+f2H/7+DcCDibt7Bk3vRaDFmiNodhI+u38TfB46i04IZ2DBwBIxMjNFh5mSEbtmFhEexAABbRwcE7d2I1b2CcDcsHK+UL3ByzUa0nTYWSc/j8Ur5Al/NnIRbZ0Jx53xGwhRx6Dhirt1A1+VzsW30FNjY26HFuKE4tnQN0t76wmyQ+GgU0lRgYCCaN2+Oq1evolOnTu9t5+bmhnXr1qF69epQKpUYOnQoLCwscvReffr0wcyZMzF06FD07NkTYWFhWL16tVqbH3/8EZ9++in69++Pnj17wsrKChERETh48CB++eWX/3KKOlO9bQu8ePIMuyfPhDL2MUpWroABO9ZJXQ/P7j+ATP76H1rZT6ujx6r52DXxJ+wcPwN2ZV3QZ+NylKjoIbVpMvg7JL98ifX9h+NlghLlfGtgwI51MDE3z/fz0ze83vmL11u7SlergsH7N0uv200fDwA4/esmrPl2MA7MWggzS0sE/jIdljYK3Dx9HvNbdULa/4dUAMDK7gPQYdZkBO3dCKFS4cLOfdg0ZKy03cjEGA7u5WBq+fpv9+YfJ0CoVPh2/VIYm5ki4tBx/DZopLRdqFRY0KYLvp4bjB+P7EJy0kuc2bAZuyf9nIdXg/KDTAghdB2EIVGpVChZsiRiYmJw69YtlClTBkDGTN87duxAeHg4AODixYvo3bs3/v77bzg7O2Pq1KkYMmQIgoKCEBQUBCDjG+L27dvRqlUr6fi2traYM2eONLh7z549GDRoEKKjo/HJJ5+gW7du6N69O54/fw5bW1sAGVMYjBo1CqdPn4YQAmXLlsVXX32FkSNf/yP+EKVSCRsbGyTEREGhUGS/AxFRNvpYldR1CAVKCgRWIQkJCQl58nc883MiPuIcFNaFcnesF4mwrfBJnsWaV5gwERMmItI6Jkz5K/8SpvNaSphqGFzCxEHfRERERNngGCYiIiLSDAd9ExEREWVDG7MCGGa+xC45IiIiouywwkREREQaKrglJiZMREREpJkCPIaJXXJERERE2WCFiYiIiDQjgxYqTFqJJN8xYSIiIiINcQwTERER0YdxDBMRERERvQ8rTERERKQhdskRERERfRi75IiIiIjofVhhIiIiIs0U4AoTEyYiIiLSUMEdw8QuOSIiIqJssMJEREREGpHJZJDlskstt/vrChMmIiIi0kwBHsPELjkiIiKibLDCRERERBoquIO+mTARERGRhrTQJceEiYiIiD5qHMNERERERO/DChMRERFpiGOYiIiIiD6MXXJERERE9D6sMBEREZFmCm6PHBMmIiIi0lTBzZjYJUdERESUDVaYiIiISDMFeNA3EyYiIiLSTAFOmNglR0RERJQNVpiIiIhIQwV30DcTJiIiItKMDFroktNKJPmOCRMRERFphmOYiIiIiPTTggUL4OLiAnNzc9SsWRPnzp3L9xiYMBEREZGGZFpaNPf7779j8ODBGDduHC5cuIAqVaqgadOmiIuL084paYgJExEREWkms0sut0sOzJo1C7169UK3bt1QoUIFLF68GJaWlli5cmUenWTWOIaJIIQAAChfvNBxJET0sUiB0HUIBUrm9c78e55XtPE5kXkMpVKptt7MzAxmZmZq61JSUhAWFoYRI0ZI6+RyOfz8/HD69Olcx5ITTJgIL/7/y+tcvqKOIyEiotx48eIFbGxstH5cU1NTODg4aO1zolChQnB2dlZbN27cOIwfP15t3ZMnT5Ceng57e3u19fb29rh27ZpWYtEUEyaCk5MToqOjYW1tDZkB3b2gVCrh7OyM6OhoKBQKXYdTIPCa5y9e7/xlyNdbCIEXL17AyckpT45vbm6OO3fuICUlRSvHE0K883nzdnVJ3zBhIsjlcpQsWVLXYfxnCoXC4P64GTpe8/zF652/DPV650Vl6U3m5uYwNzfP0/d4W7FixWBkZITY2Fi19bGxsXBwcMjXWDjom4iIiPSSqakpfHx8cPjwYWmdSqXC4cOH4evrm6+xsMJEREREemvw4MHo0qULqlevjk8++QRz5sxBUlISunXrlq9xMGEig2VmZoZx48bpfb/3x4TXPH/xeucvXm/99NVXX+Hx48cYO3YsHj16hKpVq2L//v3vDATPazKR1/cgEhERERk4jmEiIiIiygYTJiIiIqJsMGEiIiIiygYTJiIiIqJsMGEiIiIiygYTJiIiIqJsMGGijxJny/h48GdJ+oq/mwULJ66kj07mQx2PHj2K7du3w8HBAb6+vmjQoIGuQyMNZP78kpKSYGJiAiEEJxLUIpVKBbmc35VzI/N3ND4+HpaWlvj3339ha2ub5QNl6ePBiSvpo7R37160adMG9erVw8OHD6FSqTB48GD06NFD16HRB2R+4OzduxerV6/GjRs3UKNGDTRp0gTt2rXTdXgGJfNaXr58GTExMXjy5Anatm3L5DOX3vwdnTt3LuLj4wEA48ePh7+/v26DozzFrxn00Xn48CEiIyMxb948/Pnnn/j999/h7++PcePGYdmyZVI7flfQPzKZDLt27ULbtm3h4+ODwYMHIyUlBV999RUuX76s6/AMikwmw9atWxEQEIBRo0Zh2rRpcHd3x8GDB5Genq7r8AyWTCbDnj170LZtWzRt2hTBwcGoXLkymjdvjvDwcF2HR3lJEH1E/v77b1GhQgXh6ekpjh49Kq2/deuWGDJkiChRooRYvny57gKkD0pISBD+/v5i5syZQggh4uLiRIkSJUT//v11HJnhOXPmjChcuLBYuXKlEEKIe/fuCZlMJubOnSu1UalUugrP4GReq+TkZNGmTRsxadIkIYQQUVFRomzZsqJ3795ZtqePBytM9FF5+fIlqlSpgqioKERHR0vry5Qpg759+6JTp07o378/1q5dq8Mo6X2EELh58yY+/fRTPHz4EN7e3vD398f8+fMBAFu2bEFERISOozQMERERaNKkCbp164YbN26gbt266NWrFwYOHCi1kclkrLR+wLRp0xAUFATg9bVKTk5GeHg4ateujfj4ePj6+qJRo0ZYsmQJAGDZsmW4c+cOxzJ9hJgw0UelRo0aGDp0KJo3b46xY8di586d0jZXV1f07NkTQ4cOha+vrw6jpEyZH9ZpaWkAMp4WX6FCBVy4cAG1atWCv78/Fi9eDCCjq/WPP/5AREQEP+SzkHlNQkNDkZaWhnv37iE+Ph7x8fHw8/ND06ZNsWjRIgDA2rVrMWrUKADgB/t7CCFgY2ODefPmYezYsQAyrpW1tTXq16+PHTt2wMvLCwEBAViwYAEAICEhAYcOHcKff/7J39GPke6KW0S5k1nyvnLlijh06JDYsmWLSE1NFUJkdM198803wtPTU+zcuVNtv8w2pFuZP78DBw6IMWPGiDt37gghhBgxYoSQyWSiefPmIi0tTWo/YsQI4eHhIe7du6eLcA3CH3/8IWxsbMSJEydEWFiY8PX1FdbW1qJXr15CCCHS09OFEEIEBQWJ9u3bixcvXugyXL2XnJwsVq1aJUxNTcXIkSOl9cHBwaJo0aKifv36IjExUVo/YsQI4ebmJv0u08eFCRMZpMwP282bNwt7e3vh5uYmChcuLNzd3cW+ffuEEBmJ1DfffCMqV64sNm3apMtw6T22bt0qrK2txQ8//CCuXr0qre/Vq5ewtrYWY8aMEePHjxc9e/YUCoVCXLx4UXfB6qH09HTp30J0dLTo3bu3+OWXX4QQQsTGxoru3bsLNzc3sWjRIiGEEA8fPhSjRo0SxYsXFxERETqLW9+pVCrput68eVPMmDFDyGQyERwcLLXp2bOncHd3F1999ZUYOXKk+Prrr4WtrS1/Rz9iTJjIYJ0/f17Y2tqKNWvWiHv37omnT58Kf39/UbZsWXHgwAGpTevWrcWnn34qXrx4wYGYeiQiIkKULFlSLFu2LMvto0ePFk2bNhU1atQQ3bt3F1euXMnnCPXX5s2bRUJCgvT63LlzolWrVqJatWri1KlT0vqbN2+K9u3bi7Jlywo7OztRs2ZN4erqKi5cuKCLsA3O1q1bhYeHh+jcubOws7MTMplMDB8+XNr+008/ia+//lrUqVNH9OvXTy3pp48PEyYyCHv37hX3799XW7dhwwZRtWpVER8fL3U1CCFE06ZNRaVKlaTX4eHh4sGDB/kWK2nm6NGjonLlyuL+/ftS19ubP0chhHj16pVISUkRKSkpughRLx08eFA0bNhQREdHS+tOnz4tatSoIUxMTMS8efPU2sfFxYnw8HAxb948cejQIREVFZXfIRukiIgIYW1tLRYuXChevnwp7ty5I37++WdhbGysljQJIURaWhq/jBUATJhIr6lUKnHs2DFRvnx5ERMTo7Ztzpw5wsnJSXqdlJQkhMi4zbdw4cJSlYn00/r164WpqalUKXlzvFJoaCjHgbxHWlqaePTokRAiY6zes2fPhBBCXLp0STRo0EDUqlXrnXF7lHNHjx4V5cqVE7GxsdK6xMREMW3aNCGTycRPP/2kw+hIF3iXHOk1mUyGevXqISQkBA4ODrhx4waioqIAAG3btkVqaioGDRoEALC0tIQQAklJSShSpAgKFy6sy9DpDSKLO4Z8fX1Rvnx5TJw4Ec+fP4eRkZE0oeIvv/yC3377DSqVKr9D1WsqlQpGRkawt7fH7du30b17dwwePBjx8fGoXLkyZsyYAVNTUyxevBh79uxR249ypkiRIrh7967ahKlWVlZo1aoVbGxsMGzYMEyaNEmHEVJ+Y8JEei3zA7Ro0aKIiopCnTp1MH/+fERFRaFEiRIYN24c9uzZg++//x6pqamIi4vD77//DpVKBScnJx1HT8DrR0mEhoZiw4YN2LVrFwDAxcUFAQEBCAkJwbhx4/Do0SPcuHEDo0aNwt69e9GqVSs+8+wtb16PUqVK4fPPP8fNmzcxcuRIPH/+HNWrV8f06dPx6tUrLF26FNu2bXtnP3pXVgm9q6srvvjiCyxcuBBhYWHSejs7OzRv3hxLlizh43oKGt0WuIg+LHNcwPPnz4UQQkydOlW4uLiIUaNGicePH4vExESxaNEiYW9vL4oVKyY8PT2Fk5OTCAsL02HU9LYdO3YIExMTUbVqVSGTycRXX30loqKiRHp6upg6darw8fERMplMVKhQQZQtW5aDkjWUmpoqpkyZIj799FPx3XffSd1z58+fF97e3qJdu3acOiAbmX9jjhw5IsaNGyd+/PFH8fDhQyGEEHv27BG1a9cWAQEBYvfu3eLmzZvixx9/FF5eXuLp06e6DJt0gAkT6b3z588LV1dXkZycLIQQYubMmcLJyUmMHDlSxMXFCSGEePr0qVi7dq34448/OE+Pnsj8IHr8+LFo0qSJWLlypUhKShLnz58X9vb2okWLFuL27dtCCCFevHgh9u7dK0JDQ6UPK3rtzTnHtmzZIg4ePCj++ecfIYQQKSkpYvLkyVLSlPnlIiwsTNy9e1dXIRuUvXv3CmNjY9GsWTNRrFgxUbp0abF3714hhBD79u0T7dq1E3K5XJQrV07Y29szoS+gmDCR3ktKShKlS5cWEyZMkNbNnj1bODk5iVGjRvFDQY/9+eefolu3bqJt27ZqdypevHhRODg4iBYtWoi///5bhxHqv8xkaevWrcLJyUl4eXmJihUrisaNG4tDhw4JIV4nTbVr1xadOnUS8fHxugzZIGRe1/j4eNG7d2+1Z0x+8cUXwtXVVezatUtaFxERIUJDQ9+5+YQKDiZMpNdSU1NFamqqGDp0qAgICFD7IJg9e7YoXbq0GDRo0DtTDpB+OHjwoJDJZMLc3FyEhoYKIV5/UIWHhwtnZ2fRqFEjzl+TjcOHD4tixYqJBQsWCCGE2LRpkyhUqJDw9PQUe/bsEUJkJE0jR44UjRs35oe6hkJCQoSnp6eoXbu2CAkJUdvWvHlz4eLiInbu3CndgUsFGxMm0itvfut70+XLl4WZmZnat0AhMsY0VahQQeqaI/2R+bM8efKkMDY2Ft98841UZcrcFhoaKjw8PNTmFCrIzp49+86cPv/++6/o2bOnGDp0qBBCiPv37wsXFxfRsmVL0bx5c+Hu7i4OHz4shMj4gvHkyROdxG6oMsfPrVu37p1tX375pbC1tRW7d+/WQWSkb5gwkd4JCQkRn3/+uRg3bpxIS0uTJi0cPXq0qFOnjrh3757aBwoHX+qHzJ/Jixcv3kl4Dx48KIyMjESPHj2kMUqZ7V+9epW/geoppVIpWrRoIa5du/bOtsuXL4sTJ06IhIQE4e3tLXr27CmEEOL3338XxsbGwt7eXhpzQ5p5c5LUTz75RJQtW1acPn36nclTO3bsKG7cuJHf4ZEe4r2mpHcsLS3h5uaGtWvXolq1apg1axZiYmLQqlUrPH36FLdv34ZMJkNqaioAcL4lPSD+P3XA3r17ERAQgM8++wz+/v4ICQnBy5cv4efnhz/++AOrV6/GhAkT8ODBA8hkMgCAqampjqPXPSEEzM3NkZ6ejkKFCr2z3cvLC7Vr18Zff/0FMzMzjBs3DgDg5OSEunXr4uuvv4aHh0d+h21QxP+nDnj48CHu3LmD+Ph4advZs2ehUCjQtWtXnDt3Tm2agQ0bNqBcuXL5HS7pISZMpHOZf5yuX7+Oc+fOwcjICHPnzsWVK1ekD9oqVarg6tWrSElJwYgRI5CamgoTExMAkD54SXdkMhl2796Njh074rPPPsPixYvx+PFjDBkyBLt27cLLly/RuHFj/Pnnn1i6dClmzJghzbHFn9/ra6BSqaBSqXD06FFMmzYNffr0wbZt2/Ds2TMAQGJiIiIiIvDw4UMAwL59+1CmTBmMGzcOZcqU0Vn8+i4zod+5cycaNWqEpk2bonz58li0aBHu3bsHALhw4QIsLS3Rq1cvhISEZDk3ExVwOqxuEUndMtu3bxcuLi7Cw8NDmJubi2+++UYal/TkyRMRHBwsPv30U2FraysKFy4sHj9+rMuw6S23b98WPj4+Ys6cOUKIjEdIlCpVSjg4OAg3Nzfx+++/SwNnjx49KiIiInQZrl7K7Ar666+/RKFChcS3334rWrRoIWrWrCk+//xz8fLlS3H58mXh7+8vSpUqJerWrSusrKzE5cuXdRy5/nqze23fvn3CxsZGzJw5Uzx9+lQMGzZMFC1aVIwdO1aa3kIIIVxcXESNGjXEv//+q4uQSY8xYSKd+/PPP4Wtra1YsmSJSE5OFn/88YeQyWSiXbt24ubNm1K7a9euia1bt4rr16/rMFrKyp07d8SsWbPE8+fPxcOHD0XZsmVFv379hEqlEpUqVRI+Pj5ixYoVvNvoPTK/ONy6dUuUL19eLFy4UAghRHR0tLC2tpYGfAuR8aDd6dOnix9++EFERkbqJF599/Z4rri4OPHFF1+IKVOmCCEyBs6XK1dOVKtWTSgUCjFixAi1pOnN/ybKxISJdCohIUH07t1bmmPp9u3bomzZsqJt27bC1tZWtGzZktUIPZT5AZ854D49PV2aD6tfv36iXbt2QqlUCiGE6Nq1qzAzMxMNGjSQHrRLGQO2z5w5o7bu3LlzwtPTU6SlpYnbt2+LUqVKiV69eknbT58+Ld0EQVn7888/hY+Pj4iJiVH7PV23bp2Ijo4WcXFxwtPTUxo4P3DgQFGsWDExZMgQJkr0QRzDRDplbm4OPz8/BAYG4tmzZ2jTpg3q16+PzZs3Y9GiRdi1axeGDBmCW7du6TpU+j/xxgDvli1bIiQkBHK5HKVLlwYAxMTEwMHBAZaWlgAAW1tb7Ny5E2vXroVCodBl6Hrj+vXr+PnnnzF+/HhcuHBBWi+EgL29Pa5fv4769eujadOmWLRoEQAgLCwMGzZskP4tCI6xyVKVKlWwd+9eODg44J9//gGQ8SDdxo0bo2TJklixYgVKlCiB6dOnA8gYOG9ubo4DBw5kOeCeKBMTJtIpU1NTBAQEoGzZsti3bx/Mzc0xfvx4aXu9evVw9epVaYA36Z5MJsP27dvRoUMHNG7cGFZWVgAyPsDT09Mhk8lw8uRJLFy4EAMGDMCqVatQsWJFlCxZUseR6w93d3cMGzYMQgiMGzdOerhrxYoVcevWLVSqVAkBAQFYunQpjIyMAGTcrRUeHo5ixYoB4GD5rGQmnPb29rh58yY6dOiAQYMGAQDs7e0BAI8fP4aJiYn0QOKnT59i7ty5OHr0KIoXL66z2En/MWEinTM3NwcA3LlzBy9evJA+gC9duoQ2bdrgxo0bKFWqlC5DpDfcvXsXQ4YMQXBwMMaOHQtvb28AwMWLF2FkZIR169ZBoVBg9erVOHHiBI4dO8Zk6Q2Zdwe2bdsWvXv3xqtXrzB+/HicPXsWVlZW2Lp1K5ycnPDo0SOcP38ef/31F3744QcsX74cCxYskBImeldmEhkaGoply5bB398fhw4dwujRo6U2jo6OOH36NIYOHYp27dph4cKFqFixIooUKaKrsMlAyATruqQnLl68CF9fX1SvXh3m5uY4f/48Tpw4gcqVK+s6NMLrrrjz58+jU6dOOHPmDGQyGdasWYPt27cjJCQETZs2xcqVK1G0aFEolUoYGxuzG+4tmdcx044dO7BgwQKYm5tj3LhxqF69Oo4dO4bu3bsjPT0d5ubmKFq0KBYuXIiqVavqLnADkZaWhh49euDZs2dYt24dfvnlF/z6669o3bo1pk6dCgAYPXo0Ll++DJVKhalTp/JvDGmECRPpldOnT2PhwoWwsbHBd999h4oVK+o6pAIv8wP++fPnKFy4MJRKJcqWLQtPT0/ExMSgUqVK8Pb2RpMmTdCgQQPMmTMH3377ra7D1kuZ1/LgwYM4ceIEvv32W5QoUQLbtm3DokWLpC5pHx8fvHz5Ejdu3IC1tTUKFy7MCVpzIDIyEtWrV8fatWvRvHlzzJgxAxs2bEDLli0xbdo0AMCrV68gl8s5cSppjAkT6R2VSgWZTMYxGnog8wP+jz/+wMyZMzF27FjUrVsXV65cwYIFC+Di4oLAwEA4OjrC2NgY/v7+aNOmDXr06KHr0PXWtm3b0LVrV/Tu3Rvdu3dHhQoVAADbt2/HwoULYWZmhrFjx+KTTz7RcaSG4e2KnUqlglwuR1BQEKKiorBx40Y8e/YMy5Ytw+bNm9GgQQPMnTtXhxGToeIYJtI7crmcyZKOZX6Pkslk2LZtG9q3b48GDRpI4828vLywePFiDB8+HM7OzpDJZBgzZgwuXLiABg0a6DJ0vRYREYHvv/8es2bNws8//ywlSwDw5Zdfom/fvkhPT8eQIUMQHh6uu0ANiEwmw/Hjx/Hrr79KyRIA1K1bF8ePH8eZM2fg4OCAHj164IsvvsDZs2fx+PFjHUdNBimfpzEgIj329jw0N27cEK6urtJEipkuXbokzaK8d+9e0aZNG+Hk5CQuXLiQb7EaosOHD4sqVaqIhw8firS0NCGEeOdhr7///rto1aqViIqK0kWIBic5OVkEBQUJmUwmWrduLX766SdpW69evYSvr680J1hsbCyfEkD/GStMRAQAmD17NsaPH4+XL1+qPajUyMgIPXv2xMuXL7FgwQLUr18fPj4+aN26NR48eABbW1u4ubnhyJEj0h1zlLXo6Ghcu3YNCoUCRkZGSE9PlyoiYWFhePDgAdq3b4+1a9fC2dlZx9EaBlNTU8yePRtXr16Fvb09VqxYAU9PT6xatQqVKlVC8eLFpWqdnZ0d7zKk/4xjmIgIAHDw4EGULl0a5cuXlwZ4x8XFoVq1aihXrhweP34MNzc3VKpUCa1atcInn3yCdevWITAwEGlpaTA2Ntb1KeiliIgIODo6onDhwrh9+zYCAgLQvHlzjBw5EjY2NkhPT4eRkRG6deuG8uXLY/jw4eyS/o9evXqFxMREDB8+HNHR0bh69SoePnyIAQMGcNwS5Rr/whERAKBx48YAMu5UnDlzJgYMGIB69erht99+w8qVK9GwYUN07twZzs7OMDY2RuPGjaUkiclS1p4+fYrKlSujc+fOmDt3LlxcXODv74+//voLKSkpGDVqFJ4+fYp169Zh7969GDZsGJOlXDA3N4e5uTmWL1+Oy5cv48SJE5gzZw66d++u69DoI8AKExGp+eOPPzB06FB4eXkhKCgINWvWVNuuUqkwfvx4LF++HKdOnYKLi4tuAjUQe/bsQYcOHRAYGIiFCxdCpVIhODgYO3bswKVLl+Dp6Yl///0XW7ZsYZemFoi37ppLTk6GmZmZDiOijwUTJiJ6x969ezFp0iSUKlUKAwYMQJ06dQAA+/btw6+//oqjR49i3759/IB/y9sf1pmv//zzT7Ro0QJdunTBwoULIZfLoVQqERISAnt7e5QsWRKOjo46jPzj9fbPhOi/Yh2dqADL/DC5efMmnj9/DrlcDh8fH3zxxReQyWSYOHEi5s+fD5lMhtq1a0Mul6NEiRI4evQoPDw8dB2+3slMjs6fP4+RI0dCLpdDCIGmTZti586daNGiBUxMTDBx4kQULVoUzZs313XIHz0mS6QtTJiICqjMZGnr1q0YOnQokpOTYWpqisKFC2Pnzp3w9/eHEAKTJk3CggULIJfL0axZMzRs2JCzI3/A7du3MXbsWBgZGeHHH3+EXC6HSqVCs2bNEBwcjGHDhkmP5ODs3USGg9MKEBVQMpkMJ0+eRJcuXTBixAjs27cPq1atgqWlJerUqYOHDx/iiy++wJgxY3Dx4kUsW7YMr169YrL0lsxRDc+ePUNSUhK+++47rFu3DqNHj8aUKVPUJlMsXLgwqlWrhm3btiE5OVmXYRNRDrHCRFSAnTt3DrVr10aPHj2kD/Vdu3ahefPmaNOmDU6fPo0vvvgC5ubmKFu2rDTTN70mk8mwY8cO/PTTT3j8+DG+/vprdOjQAb/99hu+/vprAEDfvn1RtGhR3L59G/369cNXX30FCwsLHUdORDnBQd9EBUhmN9y5c+dQuXJlTJs2DatWrcK9e/cAQJpPaffu3Rg0aBD27t0Ld3d3HUet3y5cuICGDRvihx9+wNOnT/HXX3/B1dUVI0aMwP3799GmTRt4eXmhUKFC+PvvvxESEoJKlSrpOmwiyiF2yREVIJmDkv38/HDy5El8/vnnsLCwwPz58yGEkOZTKlq0KNLS0sDvUx9269Yt7Nu3D0OHDsWYMWMwZ84cTJw4Ec+fP8fkyZNRqVIlXLp0CZ9//jk+++wznD59mskSkYFilxxRARIdHY2dO3diypQpaNSoEZ49e4bPPvsMu3btQnp6OoKCgvDy5Uvs3bsXCoWCj5H4AKVSiQ4dOiAqKkptYsTMO99+/vlnDBs2DCNHjkRwcLCuwiQiLWGFiaiACA0NRd++fXHq1ClUrlwZAFCkSBFMmDABLi4uWLhwIYoXL44mTZpgyZIlWLNmDROmD1AoFFi6dClsbW1x4sQJXL16VdrWvHlzDBs2DHfu3MGcOXPw77//slpHZOBYYSIqIMzMzBAfH4+IiAicPXsW9erVAwA4Ozvjp59+wsOHD7F37144OTnB19cXZcqU0XHE+s/b2xubN29Gly5dMG/ePAwcOBAVK1YEAPj7+8PY2Bju7u4c4E30EeCgb6KPVOYA7/DwcJibm8PDwwO3bt1Cv379kJCQgB9++AFt27bVdZgfhYsXL6Jnz56oVq0aBg0ahAoVKug6JCLSMnbJEX2EMpOlbdu24YsvvsDKlSvx5MkTlC1bFrNnz4a1tTWWLl2Kbdu2SfuoVCodRmzYvL29pQe+Tpo0CdeuXdN1SESkZUyYiD5CMpkMR44cQefOnTFp0iT88MMP0ngkT09PzJ07FzKZDMuWLcOGDRsAQJqHif4bb29v/PLLL4iJiYGNjY2uwyEiLWOXHJGBS0xMRKFChd5Znzkv0OrVq6XZptPT02FkZAQAuHbtGrp27QonJyesWbMG1tbW+R36R+nVq1ec4JPoI8RB30QGbP/+/Xj58iVat26ttj49PR3nz59H6dKlAUB6CGxmshQTEwMPDw+sXr0alpaWTJa0iMkS0ceJNXgiA3b//n0cOHAAgPoYJCMjI9SuXRu3b9/GP//8AyCjm04IgXv37mHKlCm4efMmPDw8UKpUKZ3ETkRkSJgwERkwIQRiY2MBAHFxcbh37x5evnwJAGjSpAkePHiAlStX4vr16wAyKk+rVq3Cn3/+yUoIEVEOcAwTkQHKHJMUEhICOzs7xMTEICgoCEqlEjY2NmjSpAnGjRuHjRs3Yvbs2TA1NYW9vT0A4OTJkzh69Ci8vb11fBZERIaDFSYiA5R5R1vt2rURFxeHL774Ap06dUJYWBj8/PwwZ84c7Nu3D926dcOsWbPQqVMnmJmZoXr16jhz5gyTJSKiHGKFiciArFu3Di9evEDfvn0BAMnJyejXrx+sra0xe/ZsxMXFoWbNmvD398cvv/wCmUyGtLQ0GBsbS3MzERFRzvEuOSIDkZSUhLVr1yIpKQmWlpbo2rUrzMzMoFQq0aRJEzx+/Bje3t5o3rw5FixYAADYuXMnLC0t0ahRI86zRESUC/wLSmQgrKyssHbtWpQsWRJr1qzBsmXLAAA2NjaYNWsWatasiVatWknJUlJSEjZu3IgLFy7wwa9ERLnELjkiAyCEQFpaGkxMTBAREYEhQ4YgPj4eQ4YMgbe3N9q3b4+YmBjcv39f2mfUqFFYv349Dh06hHLlyukweiIiw8eEicgAZI4/2rRpE7Zu3Yro6GhcunQJTk5OGDZsGBQKBYYMGYJixYrBzc0N6enpOHbsGA4dOsQB3kREWsAuOSIDIJPJcPbsWXTr1g1NmzbFqlWrcOnSJZQoUQLr16+HUqnEkSNHUL9+fVhaWqJy5cq8G46ISIs46JvIQFy6dAkuLi7o2LEjLCwsAAC//vorOnTogBkzZqBYsWKYPXu2jqMkIvo4scJEZCAsLCyQnp6OxMREAEBqaipKliyJRYsW4dGjRxgzZgzWrFkDABzkTUSkZUyYiAyEr68v7t27h/nz5wMATExMAAApKSnw8fFB5cqV0bBhQwDgfEtERFrGLjkiA1GuXDksW7YM3bt3R3p6Onr16gVbW1vs3LkTLi4umDdvHhQKha7DJCL6KPEuOSIDIoTAxo0b0bt3bxQvXhxyuRzPnz/HwYMHUa1aNV2HR0T00WLCRGSA7t69i8uXL+Pff/9FzZo14eLiouuQiIg+akyYiIiIiLLBQd9ERERE2WDCRERERJQNJkxERERE2WDCRERERJQNJkxERERE2WDCRERERJQNJkxERERE2WDCRER6oWvXrmjVqpX0un79+ggKCsr3OI4dOwaZTIb4+Pj3tpHJZNixY4fGxxw/fjyqVq2aq7ju3r0LmUyG8PDwXB2HiP4bJkxE9F5du3aFTCaDTCaDqakpypUrh4kTJyItLS3P33vbtm2YNGmSRm01SXKIiHKDD98log9q1qwZVq1aheTkZOzbtw/9+vWDiYkJRowY8U7blJQUmJqaauV9ixQpopXjEBFpAytMRPRBZmZmcHBwQOnSpfHdd9/Bz88Pu3btAvC6G23KlClwcnKCu7s7ACA6Ohrt27eHra0tihQpgpYtW+Lu3bvSMdPT0zF48GDY2tqiaNGiGDZsGN5+StPbXXLJycn48ccf4ezsDDMzM5QrVw4rVqzA3bt30aBBAwBA4cKFIZPJ0LVrVwCASqVCcHAwXF1dYWFhgSpVqmDLli1q77Nv3z6UL18eFhYWaNCggVqcmvrxxx9Rvnx5WFpaokyZMhgzZgxSU1PfabdkyRI4OzvD0tIS7du3R0JCgtr25cuXw9PTE+bm5vDw8MDChQtzHAsR5Q0mTESUIxYWFkhJSZFeHz58GNevX8fBgwexZ88epKamomnTprC2tsaJEydw8uRJFCpUCM2aNZP2mzlzJlavXo2VK1ciJCQEz549w/bt2z/4vt988w1+++03zJs3D5GRkViyZAkKFSoEZ2dnbN26FQBw/fp1xMTEYO7cuQCA4OBgrF27FosXL8bVq1cxaNAgdOrUCcePHweQkdi1bt0aAQEBCA8PR8+ePTF8+PAcXxNra2usXr0aERERmDt3LpYtW4bZs2ertbl58yY2bdqE3bt3Y//+/bh48SL69u0rbV+/fj3Gjh2LKVOmIDIyElOnTsWYMWOwZs2aHMdDRHlAEBG9R5cuXUTLli2FEEKoVCpx8OBBYWZmJoYMGSJtt7e3F8nJydI+69atE+7u7kKlUknrkpOThYWFhfjzzz+FEEI4OjqKGTNmSNtTU1NFyZIlpfcSQoh69eqJ77//XgghxPXr1wUAcfDgwSzjPHr0qAAgnj9/Lq179eqVsLS0FKdOnVJr26NHD9GxY0chhBAjRowQFSpUUNv+448/vnOstwEQ27dvf+/2n376Sfj4+Eivx40bJ4yMjMT9+/eldX/88YeQy+UiJiZGCCFE2bJlxYYNG9SOM2nSJOHr6yuEEOLOnTsCgLh48eJ735eI8g7HMBHRB+3ZsweFChVCamoqVCoVvv76a4wfP17a7uXlpTZu6dKlS7h58yasra3VjvPq1SvcunULCQkJiImJQc2aNaVtxsbGqF69+jvdcpnCw8NhZGSEevXqaRz3zZs38fLlSzRu3FhtfUpKCry9vQEAkZGRanEAgK+vr8bvken333/HvHnzcOvWLSQmJiItLQ0KhUKtTalSpVCiRAm191GpVLh+/Tqsra1x69Yt9OjRA7169ZLapKWlwcbGJsfxEJH2MWEiog9q0KABFi1aBFNTUzg5OcHYWP3PhpWVldrrxMRE+Pj4YP369e8cq3jx4v8pBgsLixzvk5iYCADYu3evWqICZIzL0pbTp08jMDAQEyZMQNOmTWFjY4ONGzdi5syZOY512bJl7yRwRkZGWouViP47JkxE9EFWVlYoV66cxu2rVauG33//HXZ2du9UWTI5Ojri7NmzqFu3LoCMSkpYWBiqVauWZXsvLy+oVCocP34cfn5+72zPrHClp6dL6ypUqAAzMzNERUW9tzLl6ekpDWDPdObMmexP8g2nTp1C6dKlMWrUKGndvXv33mkXFRWFhw8fwsnJSXofuVwOd3d32Nvbw8nJCbdv30ZgYGCO3p+I8gcHfRORVgUGBqJYsWJo2bIlTpw4gTt37uDYsWMYOHAg7t+/DwD4/vvvMW3aNOzYsQPXrl1D3759PziHkouLC7p06YLu3btjx44d0jE3bdoEAChdujRkMhn27NmDx48fIzExEdbW1hgyZAgGDRqENWvW4NatW7hw4QLmz58vDaTu06cPbty4gaFDh+L69evYsGEDVq9enaPzdXNzQ1RUFDZu3Ihbt25h3rx5WQ5gNzc3R5cuXXDp0iWcOHECAwcORPv27eHg4AAAmDBhAoKDgzFv3jz8888/uHLlClatWoVZs2blKB4iyhtMmIhIqywtLfHXX3+hVKlSaN26NTw9PdGjRw+8evVKqjj98MMP6Ny5M7p06QJfX19YW1vjyy+//OBxFy1ahLZt26Jv377w8PBAr169kJSUBAAoUaIEJkyYgOHDh8Pe3h79+/cHAEyaNAljxoxBcHAwPD090axZM+zduxeurq4AMsYVbd26FTt27ECVKlWwePFiTJ06NUfn26JFCwwaNAj9+/dH1apVcerUKYwZM+adduXKlUPr1q3h7++PJk2aoHLlymrTBvTs2RPLly/HqlWr4OXlhXr16mH16tVSrESkWzLxvlGWRERERASAFSYiIiKibDFhIiIiIsoGEyYiIiKibDBhIiIiIsoGEyYiIiKibDBhIiIiIsoGEyYiIiKibDBhIiIiIsoGEyYiIiKibDBhIiIiIsoGEyYiIiKibDBhIiIiIsrG/wAsSypEpnRhJQAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "def evaluate(model, test_data):\n",
        "    test = Dataset(test_data)\n",
        "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=2)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    if use_cuda:\n",
        "        model = model.cuda()\n",
        "\n",
        "    total_acc_test = 0\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for test_input, test_label in test_dataloader:\n",
        "            test_label = test_label.to(device)\n",
        "            mask = test_input['attention_mask'].to(device)\n",
        "            input_id = test_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "            output = model(input_id, mask)\n",
        "\n",
        "            acc = (output.argmax(dim=1) == test_label).sum().item()\n",
        "            total_acc_test += acc\n",
        "\n",
        "            all_predictions.extend(output.argmax(dim=1).cpu().numpy())\n",
        "            all_labels.extend(test_label.cpu().numpy())\n",
        "\n",
        "    print(f'Test Accuracy: {total_acc_test / len(test_data): .3f}')\n",
        "\n",
        "    target_names = ['avion', 'décroissance', 'nucléaire', 'viande']\n",
        "    report = classification_report(all_labels, all_predictions, target_names=target_names)\n",
        "    print(\"Classification Report:\")\n",
        "    print(report)\n",
        "\n",
        "    # Plot the confusion matrix with class names and values as percentages\n",
        "    cm = confusion_matrix(all_labels, all_predictions, normalize='true')  # Normalize the confusion matrix\n",
        "    cm_percent = cm * 100  # Convert values to percentages\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm_percent, display_labels=target_names)\n",
        "    disp.plot(cmap=plt.cm.Reds, values_format='.2f')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.show()\n",
        "\n",
        "    # Return the test data and labels\n",
        "    return test_data['Text'].tolist(), all_labels\n",
        "\n",
        "# Assuming you have imported your model and df_test properly\n",
        "X_test_text, Y_test = evaluate(model, df_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xt0bltxcD_Zv"
      },
      "outputs": [],
      "source": [
        "#save my model\n",
        "torch.save(model.state_dict(), 'trained_model.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQN6MhFkEGix"
      },
      "source": [
        "Partie 4 : Attribution score for predected target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3o7XLL-fgo1p",
        "outputId": "51184d29-91bd-4315-90b2-091a0ff73a9a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CamembertClassifier(\n",
              "  (bert): CamembertModel(\n",
              "    (embeddings): CamembertEmbeddings(\n",
              "      (word_embeddings): Embedding(32005, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): CamembertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x CamembertLayer(\n",
              "          (attention): CamembertAttention(\n",
              "            (self): CamembertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): CamembertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): CamembertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): CamembertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): CamembertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (linear): Linear(in_features=768, out_features=4, bias=True)\n",
              "  (relu): ReLU()\n",
              ")"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Instanciation du modèle avec les poids saved\n",
        "\n",
        "class CamembertClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, dropout=0.5):\n",
        "\n",
        "        super(CamembertClassifier, self).__init__()\n",
        "\n",
        "        self.bert = CamembertModel.from_pretrained('camembert-base')\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear = nn.Linear(768, 4)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, input_id, mask = None):\n",
        "\n",
        "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
        "        dropout_output = self.dropout(pooled_output)\n",
        "        linear_output = self.linear(dropout_output)\n",
        "        final_layer = self.relu(linear_output)\n",
        "\n",
        "        return final_layer\n",
        "\n",
        "model = CamembertClassifier()\n",
        "model.load_state_dict(torch.load('/content/trained_model.pth', map_location=torch.device('cpu')))\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nh0SxuHXg-La"
      },
      "outputs": [],
      "source": [
        "# Define model output\n",
        "def model_output(inputs):\n",
        "    return model(inputs)\n",
        "\n",
        "# Define model input\n",
        "model_input = model.bert.embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4dTtQZ4gv7U"
      },
      "outputs": [],
      "source": [
        "#Une classe de captum pour calculer integred gradient pour une entrée donnée pour donner l'importance de chaque token de notre entrée pour comprendre les prédiction du modèle\n",
        "lig = LayerIntegratedGradients(model_output, model_input) # calcul de integred gradiend entre la baseline et l'entrée"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isnS7qxdnxUu",
        "outputId": "60195c4b-f108-4471-a64f-517afd5a6968"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "original text: tensor([[   5, 3952,   30,  295,   24, 1898,    6]])\n",
            "baseline text: tensor([[5, 1, 1, 1, 1, 1, 6]])\n"
          ]
        }
      ],
      "source": [
        "#La préparation de Imput data et baseline data\n",
        "def construct_input_and_baseline(text):\n",
        "\n",
        "    max_length = 250\n",
        "    baseline_token_id = tokenizer.pad_token_id\n",
        "    sep_token_id = tokenizer.sep_token_id\n",
        "    cls_token_id = tokenizer.cls_token_id\n",
        "    text = convert_emoji_to_text(text)\n",
        "\n",
        "    text_ids = tokenizer.encode(text, max_length=max_length, truncation=True, add_special_tokens=False)\n",
        "\n",
        "    input_ids = [cls_token_id] + text_ids + [sep_token_id]\n",
        "    token_list = tokenizer.convert_ids_to_tokens(input_ids)\n",
        "\n",
        "\n",
        "    baseline_input_ids = [cls_token_id] + [baseline_token_id] * len(text_ids) + [sep_token_id]\n",
        "    return torch.tensor([input_ids], device='cpu'), torch.tensor([baseline_input_ids], device='cpu'), token_list\n",
        "\n",
        "text = \"viande est mal pour environnement\"\n",
        "input_ids, baseline_input_ids, all_tokens = construct_input_and_baseline(text)\n",
        "\n",
        "print(f'original text: {input_ids}')\n",
        "print(f'baseline text: {baseline_input_ids}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WUAGyhhxoM7R"
      },
      "outputs": [],
      "source": [
        "#La normalisation des scores d'attribution\n",
        "def summarize_attributions(attributions):\n",
        "\n",
        "    attributions = attributions.sum(dim=-1).squeeze(0)\n",
        "    attributions = attributions / torch.norm(attributions).tolist()\n",
        "\n",
        "    return attributions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M9MnsV9do32Z"
      },
      "outputs": [],
      "source": [
        "#La mesure des score d'attribution par rapport à la classe prédite par le modèle\n",
        "def get_attribution_scores_for_predicted_class(sentences):\n",
        "    class_labels = ['avion', 'décroissance', 'nucléaire', 'viande']\n",
        "\n",
        "    attribution_scores_by_sentence = {}\n",
        "\n",
        "    for text in sentences:\n",
        "        input_ids, baseline_input_ids, all_tokens = construct_input_and_baseline(text)\n",
        "\n",
        "        model_output = model(input_ids)\n",
        "        predicted_index = torch.argmax(model_output[0]).item()\n",
        "        predicted_class = class_labels[predicted_index]\n",
        "\n",
        "        attribution_scores_for_predicted_class = {}\n",
        "\n",
        "        target_class = predicted_class\n",
        "\n",
        "        target_index = class_labels.index(target_class)\n",
        "        attributions, delta = lig.attribute(inputs=input_ids, baselines=baseline_input_ids, target=target_index, return_convergence_delta=True)\n",
        "\n",
        "        #attributions_sum = attributions.sum(dim=-1).squeeze().tolist()\n",
        "        attributions_sum = summarize_attributions(attributions)\n",
        "\n",
        "        target_score = sum(attributions_sum)\n",
        "\n",
        "        attribution_scores_for_predicted_class = {\n",
        "            \"word_attributions\": attributions_sum,\n",
        "            \"pred_prob\": torch.max(model_output[0]).item(),\n",
        "            \"pred_class\": predicted_class,\n",
        "            \"true_class\": class_labels[predicted_index],\n",
        "            \"attr_class\": text,\n",
        "            \"attr_score\": target_score,\n",
        "            \"raw_input_ids\": all_tokens,\n",
        "            \"convergence_score\": delta\n",
        "        }\n",
        "\n",
        "        attribution_scores_by_sentence[text] = attribution_scores_for_predicted_class\n",
        "\n",
        "    return attribution_scores_by_sentence\n",
        "\n",
        "#La visualisation d'influence de chaque token de l'Imput\n",
        "\n",
        "def visualize_attributions_for_predicted_class(text):\n",
        "    attribution_scores = get_attribution_scores_for_predicted_class([text])\n",
        "\n",
        "    class_labels = ['avion', 'décroissance', 'nucléaire', 'viande']\n",
        "\n",
        "    original_prob = attribution_scores[text]['pred_prob']\n",
        "\n",
        "    target_score = attribution_scores[text]['attr_score']\n",
        "\n",
        "    predicted_vis = viz.VisualizationDataRecord(\n",
        "        word_attributions=attribution_scores[text]['word_attributions'],\n",
        "        pred_prob=original_prob,\n",
        "        pred_class=attribution_scores[text]['pred_class'],\n",
        "        true_class=attribution_scores[text]['true_class'],\n",
        "        attr_class=attribution_scores[text]['attr_class'],\n",
        "        attr_score=target_score,\n",
        "        raw_input_ids=attribution_scores[text]['raw_input_ids'],\n",
        "        convergence_score=attribution_scores[text]['convergence_score']\n",
        "    )\n",
        "\n",
        "    viz.visualize_text([predicted_vis])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99
        },
        "id": "KPi8RUkupx8E",
        "outputId": "0ce5b2df-b8f4-4ea8-9131-c4b6a193d846"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>décroissance</b></text></td><td><text style=\"padding-right:2em\"><b>décroissance (2.76)</b></text></td><td><text style=\"padding-right:2em\"><b>croissance du PIB</b></text></td><td><text style=\"padding-right:2em\"><b>-0.86</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #s                    </font></mark><mark style=\"background-color: hsl(120, 75%, 80%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁croissance                    </font></mark><mark style=\"background-color: hsl(0, 75%, 69%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁PIB                    </font></mark><mark style=\"background-color: hsl(0, 75%, 81%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #/s                    </font></mark></td><tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "text=\"croissance du PIB\"\n",
        "visualize_attributions_for_predicted_class(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "gRRbk6Oyp3Dz",
        "outputId": "e67c3007-ebf6-4945-970c-e24e6838cdd5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>nucléaire</b></text></td><td><text style=\"padding-right:2em\"><b>nucléaire (4.57)</b></text></td><td><text style=\"padding-right:2em\"><b>En 2014, EDF devait vendre 25% de sa production nucléaire à prix bradé, aujourd’hui c’est 40%. Proglio raconte comment le p…</b></text></td><td><text style=\"padding-right:2em\"><b>2.51</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #s                    </font></mark><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁En                    </font></mark><mark style=\"background-color: hsl(120, 75%, 67%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁EDF                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁devait                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁vendre                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁sa                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁production                    </font></mark><mark style=\"background-color: hsl(120, 75%, 87%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁nu                    </font></mark><mark style=\"background-color: hsl(120, 75%, 84%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> cle                    </font></mark><mark style=\"background-color: hsl(120, 75%, 79%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> aire                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁prix                    </font></mark><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁brad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> e                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁aujourd                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> hui                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁c                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> est                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁Pro                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> glio                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁raconte                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁comment                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁p                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #/s                    </font></mark></td><tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "text = \"En 2014, EDF devait vendre 25% de sa production nucl\\u00e9aire \\u00e0 prix brad\\u00e9, aujourd\\u2019hui c\\u2019est 40%. Proglio raconte comment le p\\u2026\"\n",
        "visualize_attributions_for_predicted_class(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxwsBtobqKLf"
      },
      "source": [
        "Partie 5 : Attribution score for each target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nd-s_DVlqFFF"
      },
      "outputs": [],
      "source": [
        "#Le calcule des scores d'attribution par rapport à chaque target (le calcul est fait en considérant que le modèle prédit le target en question)\n",
        "def get_attribution_scores_for_all_targets(sentences):\n",
        "    class_labels = ['avion', 'décroissance', 'nucléaire', 'viande']\n",
        "\n",
        "    attribution_scores_by_sentence = {}\n",
        "\n",
        "    for text in sentences:\n",
        "        input_ids, baseline_input_ids, all_tokens = construct_input_and_baseline(text)\n",
        "\n",
        "        model_output = model(input_ids)\n",
        "        predicted_index = torch.argmax(model_output[0]).item()\n",
        "        predicted_class = class_labels[predicted_index]\n",
        "\n",
        "        attribution_scores_by_target = {}\n",
        "\n",
        "        for target_class in class_labels:\n",
        "            target_index = class_labels.index(target_class)\n",
        "            attributions, delta = lig.attribute(inputs=input_ids, baselines=baseline_input_ids, target=target_index, return_convergence_delta=True)\n",
        "\n",
        "            #attributions_sum = attributions.sum(dim=-1).squeeze().tolist()\n",
        "            attributions_sum = summarize_attributions(attributions)\n",
        "\n",
        "            target_score = sum(attributions_sum)\n",
        "\n",
        "            attribution_scores_by_target[target_class] = {\n",
        "                \"word_attributions\": attributions_sum,\n",
        "                \"pred_prob\": torch.max(model_output[0]).item(),\n",
        "                \"pred_class\": predicted_class,\n",
        "                \"true_class\": class_labels[predicted_index],\n",
        "                \"attr_class\": text,\n",
        "                \"attr_score\": target_score,\n",
        "                \"raw_input_ids\": all_tokens,\n",
        "                \"convergence_score\": delta\n",
        "            }\n",
        "\n",
        "        attribution_scores_by_sentence[text] = attribution_scores_by_target\n",
        "\n",
        "    return attribution_scores_by_sentence\n",
        "\n",
        "#Ecrire les score d'attribution de chaque token par rapport à chaque target\n",
        "def display_attribution_scores(scores):\n",
        "    for sentence, target_scores in scores.items():\n",
        "        print(\"Sentence:\", sentence)\n",
        "        for target_class, scores_dict in target_scores.items():\n",
        "            print(\"Target Class:\", target_class)\n",
        "            print(\"Token\\t\\tAttribution Score\")\n",
        "            print(\"--------------------------\")\n",
        "            word_attributions = scores_dict[\"word_attributions\"]\n",
        "            for token, score in zip(scores_dict[\"raw_input_ids\"], word_attributions):\n",
        "                print(f\"{token}\\t\\t{score:.4f}\")\n",
        "            for bigram_key, bigram_scores in scores_dict.items():\n",
        "                if bigram_key.startswith(\"bigram_\"):\n",
        "                    bigram_tokens = bigram_key.replace(\"bigram_\", \"\")\n",
        "                    print(f\"{bigram_tokens}\\t\\t{bigram_scores:.4f}\")\n",
        "            for trigram_key, trigram_scores in scores_dict.items():\n",
        "                if trigram_key.startswith(\"trigram_\"):\n",
        "                    trigram_tokens = trigram_key.replace(\"trigram_\", \"\")\n",
        "                    print(f\"{trigram_tokens}\\t\\t{trigram_scores:.4f}\")\n",
        "            print(\"\\nPredicted Class:\", scores_dict[\"pred_class\"])\n",
        "            print(\"True Class:\", scores_dict[\"true_class\"])\n",
        "            print(\"Predicted Probability:\", scores_dict[\"pred_prob\"])\n",
        "            print(\"Target Attribution Score:\", scores_dict[\"attr_score\"])\n",
        "            print(\"\\n\" + \"=\"*50 + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wj0u1pCLssdE",
        "outputId": "9cb18253-1f67-43da-e9d9-e9b0eb2259f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence: les abattoirs dans la compagne\n",
            "Target Class: avion\n",
            "Token\t\tAttribution Score\n",
            "--------------------------\n",
            "<s>\t\t0.0000\n",
            "▁\t\t-0.2810\n",
            "abattoir\t\t-0.1018\n",
            "s\t\t0.7223\n",
            "▁dans\t\t0.5076\n",
            "▁compagne\t\t0.3618\n",
            "</s>\t\t-0.0206\n",
            "\n",
            "Predicted Class: viande\n",
            "True Class: viande\n",
            "Predicted Probability: 4.396393299102783\n",
            "Target Attribution Score: tensor(1.1882, dtype=torch.float64)\n",
            "\n",
            "==================================================\n",
            "\n",
            "Target Class: décroissance\n",
            "Token\t\tAttribution Score\n",
            "--------------------------\n",
            "<s>\t\t0.0000\n",
            "▁\t\t0.4552\n",
            "abattoir\t\t0.0564\n",
            "s\t\t0.6521\n",
            "▁dans\t\t-0.5228\n",
            "▁compagne\t\t-0.2489\n",
            "</s>\t\t0.1707\n",
            "\n",
            "Predicted Class: viande\n",
            "True Class: viande\n",
            "Predicted Probability: 4.396393299102783\n",
            "Target Attribution Score: tensor(0.5626, dtype=torch.float64)\n",
            "\n",
            "==================================================\n",
            "\n",
            "Target Class: nucléaire\n",
            "Token\t\tAttribution Score\n",
            "--------------------------\n",
            "<s>\t\t0.0000\n",
            "▁\t\t-0.7110\n",
            "abattoir\t\t-0.3723\n",
            "s\t\t0.4636\n",
            "▁dans\t\t-0.1877\n",
            "▁compagne\t\t0.3144\n",
            "</s>\t\t-0.0829\n",
            "\n",
            "Predicted Class: viande\n",
            "True Class: viande\n",
            "Predicted Probability: 4.396393299102783\n",
            "Target Attribution Score: tensor(-0.5759, dtype=torch.float64)\n",
            "\n",
            "==================================================\n",
            "\n",
            "Target Class: viande\n",
            "Token\t\tAttribution Score\n",
            "--------------------------\n",
            "<s>\t\t0.0000\n",
            "▁\t\t0.4425\n",
            "abattoir\t\t0.3893\n",
            "s\t\t-0.7569\n",
            "▁dans\t\t0.1261\n",
            "▁compagne\t\t-0.2522\n",
            "</s>\t\t-0.0154\n",
            "\n",
            "Predicted Class: viande\n",
            "True Class: viande\n",
            "Predicted Probability: 4.396393299102783\n",
            "Target Attribution Score: tensor(-0.0666, dtype=torch.float64)\n",
            "\n",
            "==================================================\n",
            "\n",
            "Sentence: l'avion pollue beaucoup\n",
            "Target Class: avion\n",
            "Token\t\tAttribution Score\n",
            "--------------------------\n",
            "<s>\t\t0.0000\n",
            "▁l\t\t0.4699\n",
            "'\t\t0.7026\n",
            "avion\t\t0.5310\n",
            "▁pollue\t\t0.0122\n",
            "▁beaucoup\t\t0.0514\n",
            "</s>\t\t0.0283\n",
            "\n",
            "Predicted Class: avion\n",
            "True Class: avion\n",
            "Predicted Probability: 3.778296947479248\n",
            "Target Attribution Score: tensor(1.7954, dtype=torch.float64)\n",
            "\n",
            "==================================================\n",
            "\n",
            "Target Class: décroissance\n",
            "Token\t\tAttribution Score\n",
            "--------------------------\n",
            "<s>\t\t0.0000\n",
            "▁l\t\t0.7731\n",
            "'\t\t-0.5146\n",
            "avion\t\t-0.1944\n",
            "▁pollue\t\t0.2953\n",
            "▁beaucoup\t\t0.0026\n",
            "</s>\t\t0.1123\n",
            "\n",
            "Predicted Class: avion\n",
            "True Class: avion\n",
            "Predicted Probability: 3.778296947479248\n",
            "Target Attribution Score: tensor(0.4743, dtype=torch.float64)\n",
            "\n",
            "==================================================\n",
            "\n",
            "Target Class: nucléaire\n",
            "Token\t\tAttribution Score\n",
            "--------------------------\n",
            "<s>\t\t0.0000\n",
            "▁l\t\t-0.5088\n",
            "'\t\t-0.7590\n",
            "avion\t\t-0.2524\n",
            "▁pollue\t\t0.1968\n",
            "▁beaucoup\t\t0.2500\n",
            "</s>\t\t-0.0146\n",
            "\n",
            "Predicted Class: avion\n",
            "True Class: avion\n",
            "Predicted Probability: 3.778296947479248\n",
            "Target Attribution Score: tensor(-1.0880, dtype=torch.float64)\n",
            "\n",
            "==================================================\n",
            "\n",
            "Target Class: viande\n",
            "Token\t\tAttribution Score\n",
            "--------------------------\n",
            "<s>\t\t0.0000\n",
            "▁l\t\t-0.5434\n",
            "'\t\t-0.4664\n",
            "avion\t\t-0.6865\n",
            "▁pollue\t\t-0.1184\n",
            "▁beaucoup\t\t-0.0411\n",
            "</s>\t\t0.0146\n",
            "\n",
            "Predicted Class: avion\n",
            "True Class: avion\n",
            "Predicted Probability: 3.778296947479248\n",
            "Target Attribution Score: tensor(-1.8413, dtype=torch.float64)\n",
            "\n",
            "==================================================\n",
            "\n",
            "Sentence: l'énergie nucléaire\n",
            "Target Class: avion\n",
            "Token\t\tAttribution Score\n",
            "--------------------------\n",
            "<s>\t\t0.0000\n",
            "▁l\t\t-0.3399\n",
            "'\t\t-0.0393\n",
            "energie\t\t-0.1767\n",
            "▁nu\t\t-0.0837\n",
            "cle\t\t-0.2025\n",
            "aire\t\t0.8960\n",
            "</s>\t\t-0.0301\n",
            "\n",
            "Predicted Class: nucléaire\n",
            "True Class: nucléaire\n",
            "Predicted Probability: 4.478482723236084\n",
            "Target Attribution Score: tensor(0.0237, dtype=torch.float64)\n",
            "\n",
            "==================================================\n",
            "\n",
            "Target Class: décroissance\n",
            "Token\t\tAttribution Score\n",
            "--------------------------\n",
            "<s>\t\t0.0000\n",
            "▁l\t\t0.5896\n",
            "'\t\t0.3863\n",
            "energie\t\t0.3625\n",
            "▁nu\t\t-0.2596\n",
            "cle\t\t-0.5509\n",
            "aire\t\t-0.0284\n",
            "</s>\t\t-0.0036\n",
            "\n",
            "Predicted Class: nucléaire\n",
            "True Class: nucléaire\n",
            "Predicted Probability: 4.478482723236084\n",
            "Target Attribution Score: tensor(0.4958, dtype=torch.float64)\n",
            "\n",
            "==================================================\n",
            "\n",
            "Target Class: nucléaire\n",
            "Token\t\tAttribution Score\n",
            "--------------------------\n",
            "<s>\t\t0.0000\n",
            "▁l\t\t0.0760\n",
            "'\t\t0.1930\n",
            "energie\t\t0.2581\n",
            "▁nu\t\t0.5202\n",
            "cle\t\t0.5247\n",
            "aire\t\t0.5866\n",
            "</s>\t\t0.0169\n",
            "\n",
            "Predicted Class: nucléaire\n",
            "True Class: nucléaire\n",
            "Predicted Probability: 4.478482723236084\n",
            "Target Attribution Score: tensor(2.1756, dtype=torch.float64)\n",
            "\n",
            "==================================================\n",
            "\n",
            "Target Class: viande\n",
            "Token\t\tAttribution Score\n",
            "--------------------------\n",
            "<s>\t\t0.0000\n",
            "▁l\t\t0.0026\n",
            "'\t\t0.0850\n",
            "energie\t\t-0.3173\n",
            "▁nu\t\t-0.1705\n",
            "cle\t\t0.3447\n",
            "aire\t\t-0.8427\n",
            "</s>\t\t0.1843\n",
            "\n",
            "Predicted Class: nucléaire\n",
            "True Class: nucléaire\n",
            "Predicted Probability: 4.478482723236084\n",
            "Target Attribution Score: tensor(-0.7139, dtype=torch.float64)\n",
            "\n",
            "==================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Exemple\n",
        "sentences = [\"les abattoirs dans la compagne\", \"l'avion pollue beaucoup\", \"l'énergie nucléaire\"]\n",
        "true_class = 0\n",
        "attribution_scores = get_attribution_scores_for_all_targets(sentences)\n",
        "display_attribution_scores(attribution_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La visualisation de l'influence de chaque token par rapport au target spécifié\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ks2IAbbtzUO"
      },
      "outputs": [],
      "source": [
        "def interpret_text_for_target(text, true_class, target_class):\n",
        "    attribution_scores = get_attribution_scores_for_all_targets([text])\n",
        "\n",
        "    class_labels = ['avion', 'décroissance', 'nucléaire', 'viande']\n",
        "\n",
        "    original_prob = attribution_scores[text][class_labels[true_class]]['pred_prob']\n",
        "\n",
        "    target_score = attribution_scores[text][target_class]['attr_score']\n",
        "\n",
        "    target_vis = viz.VisualizationDataRecord(\n",
        "        word_attributions=attribution_scores[text][target_class]['word_attributions'],\n",
        "        pred_prob=original_prob,\n",
        "        pred_class=attribution_scores[text][class_labels[true_class]]['pred_class'],\n",
        "        true_class=class_labels[true_class],\n",
        "        attr_class=attribution_scores[text][target_class]['attr_class'],\n",
        "        attr_score=target_score,\n",
        "        raw_input_ids=attribution_scores[text][target_class]['raw_input_ids'],\n",
        "        convergence_score=attribution_scores[text][target_class]['convergence_score']\n",
        "    )\n",
        "\n",
        "    viz.visualize_text([target_vis])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99
        },
        "id": "Q0fh9-VZuekB",
        "outputId": "1de98708-40c8-45e0-8501-8851c80d8694"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>avion</b></text></td><td><text style=\"padding-right:2em\"><b>avion (3.58)</b></text></td><td><text style=\"padding-right:2em\"><b>augmentation nombre avion</b></text></td><td><text style=\"padding-right:2em\"><b>1.48</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #s                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁augmentation                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁nombre                    </font></mark><mark style=\"background-color: hsl(120, 75%, 53%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁avion                    </font></mark><mark style=\"background-color: hsl(120, 75%, 87%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #/s                    </font></mark></td><tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Exemple\n",
        "input_text = \"augmentation nombre avion\"\n",
        "true_class = 0\n",
        "target_class = 'avion'\n",
        "\n",
        "interpret_text_for_target(input_text, true_class, target_class)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99
        },
        "id": "Uaxg2Sn6vEGZ",
        "outputId": "ca4514da-73b1-4579-f499-aedbb269cbc3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>avion</b></text></td><td><text style=\"padding-right:2em\"><b>avion (3.58)</b></text></td><td><text style=\"padding-right:2em\"><b>augmentation nombre avion</b></text></td><td><text style=\"padding-right:2em\"><b>-1.79</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #s                    </font></mark><mark style=\"background-color: hsl(0, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁augmentation                    </font></mark><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁nombre                    </font></mark><mark style=\"background-color: hsl(0, 75%, 69%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁avion                    </font></mark><mark style=\"background-color: hsl(0, 75%, 80%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #/s                    </font></mark></td><tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Exemple\n",
        "input_text = \"augmentation nombre avion\"\n",
        "true_class = 0\n",
        "target_class = 'viande'\n",
        "\n",
        "interpret_text_for_target(input_text, true_class, target_class)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99
        },
        "id": "Id1ap0fju69y",
        "outputId": "e7e3bc92-5df4-49bd-a956-891540adac17"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>avion</b></text></td><td><text style=\"padding-right:2em\"><b>avion (3.58)</b></text></td><td><text style=\"padding-right:2em\"><b>augmentation nombre avion</b></text></td><td><text style=\"padding-right:2em\"><b>-0.11</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #s                    </font></mark><mark style=\"background-color: hsl(0, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁augmentation                    </font></mark><mark style=\"background-color: hsl(0, 75%, 83%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁nombre                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁avion                    </font></mark><mark style=\"background-color: hsl(120, 75%, 59%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #/s                    </font></mark></td><tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Exemple\n",
        "input_text = \"augmentation nombre avion\"\n",
        "true_class = 0\n",
        "target_class = 'nucléaire'\n",
        "\n",
        "interpret_text_for_target(input_text, true_class, target_class)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99
        },
        "id": "i7LcVqqdu3qn",
        "outputId": "ce49bfb8-9d31-4295-f267-7ebf276dc07b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>avion</b></text></td><td><text style=\"padding-right:2em\"><b>avion (3.58)</b></text></td><td><text style=\"padding-right:2em\"><b>augmentation nombre avion</b></text></td><td><text style=\"padding-right:2em\"><b>-0.81</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #s                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁augmentation                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁nombre                    </font></mark><mark style=\"background-color: hsl(0, 75%, 64%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁avion                    </font></mark><mark style=\"background-color: hsl(0, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #/s                    </font></mark></td><tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Exemple\n",
        "input_text = \"augmentation nombre avion\"\n",
        "true_class = 0\n",
        "target_class = 'décroissance'\n",
        "\n",
        "interpret_text_for_target(input_text, true_class, target_class)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LE0tcB3wDYU"
      },
      "source": [
        "Partie 6 : Attribution score for bigramm and trigramm, Création des clusters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RUwSRqtuwFgN"
      },
      "outputs": [],
      "source": [
        "# Le calcule des score d'attribution par rapport aux différents target pour les unigram, bigram et trigram\n",
        "\n",
        "def get_attribution_scores_for_all_targets(sentences):\n",
        "    class_labels = ['avion', 'décroissance', 'nucléaire', 'viande']\n",
        "\n",
        "    attribution_scores_by_sentence = {}\n",
        "\n",
        "    for text in sentences:\n",
        "        input_ids, baseline_input_ids, all_tokens = construct_input_and_baseline(text)\n",
        "\n",
        "        model_output = model(input_ids)\n",
        "        predicted_index = torch.argmax(model_output[0]).item()\n",
        "        predicted_class = class_labels[predicted_index]\n",
        "\n",
        "        attribution_scores_by_target = {}\n",
        "\n",
        "        for target_class in class_labels:\n",
        "            target_index = class_labels.index(target_class)\n",
        "            attributions, delta = lig.attribute(inputs=input_ids, baselines=baseline_input_ids, target=target_index, return_convergence_delta=True)\n",
        "\n",
        "            #attributions_sum = attributions.sum(dim=-1).squeeze().tolist()\n",
        "            attributions_sum = summarize_attributions(attributions).tolist()\n",
        "\n",
        "            target_score = sum(attributions_sum)\n",
        "\n",
        "            bigram_attributions_sum = []\n",
        "            for i in range(len(attributions_sum) - 1):\n",
        "                bigram_score = attributions_sum[i] + attributions_sum[i + 1]\n",
        "                bigram_attributions_sum.append(bigram_score)\n",
        "\n",
        "            trigram_attributions_sum = []\n",
        "            for i in range(len(attributions_sum) - 2):\n",
        "                trigram_score = attributions_sum[i] + attributions_sum[i + 1] + attributions_sum[i + 2]\n",
        "                trigram_attributions_sum.append(trigram_score)\n",
        "\n",
        "            attribution_scores_by_target[target_class] = {\n",
        "                \"word_attributions\": attributions_sum,\n",
        "                \"bigram_attributions\": bigram_attributions_sum,\n",
        "                \"trigram_attributions\": trigram_attributions_sum,\n",
        "                \"pred_prob\": torch.max(model_output[0]).item(),\n",
        "                \"pred_class\": predicted_class,\n",
        "                \"true_class\": class_labels[predicted_index],\n",
        "                \"attr_class\": text,\n",
        "                \"attr_score\": target_score,\n",
        "                \"raw_input_ids\": all_tokens,\n",
        "                \"convergence_score\": delta\n",
        "            }\n",
        "\n",
        "        attribution_scores_by_sentence[text] = attribution_scores_by_target\n",
        "\n",
        "    return attribution_scores_by_sentence\n",
        "#Ecrire les score d'attribution de chaque unigram, biram et trigram par rapport à chaque target\n",
        "\n",
        "def display_attribution_scores(scores):\n",
        "    for sentence, target_scores in scores.items():\n",
        "        print(\"Sentence:\", sentence)\n",
        "        for target_class, scores_dict in target_scores.items():\n",
        "            print(\"Target Class:\", target_class)\n",
        "            print(\"Token\\t\\tAttribution Score\")\n",
        "            print(\"--------------------------\")\n",
        "            word_attributions = scores_dict[\"word_attributions\"]\n",
        "            for token, score in zip(scores_dict[\"raw_input_ids\"], word_attributions):\n",
        "                print(f\"{token}\\t\\t{score:.4f}\")\n",
        "\n",
        "            print(\"\\nBigram\\t\\tAttribution Score\")\n",
        "            print(\"--------------------------\")\n",
        "            bigram_attributions = scores_dict.get(\"bigram_attributions\", [])\n",
        "            bigram_tokens = [f\"{token} {scores_dict['raw_input_ids'][i+1]}\" for i, token in enumerate(scores_dict[\"raw_input_ids\"][:-1])]\n",
        "            for token, score in zip(bigram_tokens, bigram_attributions):\n",
        "                print(f\"{token}\\t\\t{score:.4f}\")\n",
        "\n",
        "            print(\"\\nTrigram\\t\\tAttribution Score\")  # Add this section for displaying trigram attributions\n",
        "            print(\"--------------------------\")\n",
        "            trigram_attributions = scores_dict.get(\"trigram_attributions\", [])\n",
        "            trigram_tokens = [f\"{token} {scores_dict['raw_input_ids'][i+1]} {scores_dict['raw_input_ids'][i+2]}\" for i, token in enumerate(scores_dict[\"raw_input_ids\"][:-2])]\n",
        "            for token, score in zip(trigram_tokens, trigram_attributions):\n",
        "                print(f\"{token}\\t\\t{score:.4f}\")\n",
        "\n",
        "            print(\"\\nPredicted Class:\", scores_dict[\"pred_class\"])\n",
        "            print(\"True Class:\", scores_dict[\"true_class\"])\n",
        "            print(\"Predicted Probability:\", scores_dict[\"pred_prob\"])\n",
        "            print(\"Target Attribution Score:\", scores_dict[\"attr_score\"])\n",
        "            print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4yngf0qx9Xa",
        "outputId": "641b58a2-f85e-4f88-abee-2051ebdbc153"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mLe flux de sortie a été tronqué et ne contient que les 5000 dernières lignes.\u001b[0m\n",
            "▁sur ▁car go\t\t-1.0536\n",
            "▁car go s\t\t-1.3384\n",
            "go s ▁pro\t\t-0.9110\n",
            "s ▁pro pulse\t\t-0.5635\n",
            "▁pro pulse s\t\t-0.3444\n",
            "pulse s ▁au\t\t-0.2303\n",
            "s ▁au ▁fu\t\t-0.1483\n",
            "▁au ▁fu e\t\t0.0169\n",
            "▁fu e </s>\t\t0.0293\n",
            "\n",
            "Predicted Class: nucléaire\n",
            "True Class: nucléaire\n",
            "Predicted Probability: 4.629717826843262\n",
            "Target Attribution Score: -0.9601081446310711\n",
            "\n",
            "==================================================\n",
            "\n",
            "Sentence: RT @AlterKapitae: Super interview de @VinczeDegrowth\n",
            "\"Nous nous sommes enfermés dans la religion de la croissance\". Ecoutons-le pour en sor…\n",
            "Target Class: avion\n",
            "Token\t\tAttribution Score\n",
            "--------------------------\n",
            "<s>\t\t0.0000\n",
            "▁RT\t\t-0.7209\n",
            "▁Al\t\t-0.0007\n",
            "ter\t\t0.0134\n",
            "K\t\t-0.0703\n",
            "ap\t\t-0.0954\n",
            "ita\t\t-0.0495\n",
            "e\t\t-0.0347\n",
            "▁Super\t\t0.0114\n",
            "▁interview\t\t-0.0242\n",
            "▁Vin\t\t0.0246\n",
            "c\t\t0.0435\n",
            "ze\t\t0.0294\n",
            "De\t\t-0.0123\n",
            "g\t\t-0.0454\n",
            "row\t\t-0.0362\n",
            "th\t\t-0.0186\n",
            "▁sommes\t\t-0.0065\n",
            "▁en\t\t-0.0441\n",
            "ferme\t\t-0.0088\n",
            "s\t\t-0.0573\n",
            "▁dans\t\t0.0072\n",
            "▁religion\t\t-0.0302\n",
            "▁croissance\t\t0.0087\n",
            "▁E\t\t-0.1160\n",
            "cout\t\t-0.2106\n",
            "ons\t\t-0.2431\n",
            "-\t\t-0.1438\n",
            "le\t\t-0.0911\n",
            "▁pour\t\t-0.0757\n",
            "▁en\t\t-0.0524\n",
            "▁s\t\t-0.0312\n",
            "or\t\t0.0382\n",
            "</s>\t\t0.5397\n",
            "\n",
            "Bigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁RT\t\t-0.7209\n",
            "▁RT ▁Al\t\t-0.7217\n",
            "▁Al ter\t\t0.0127\n",
            "ter K\t\t-0.0569\n",
            "K ap\t\t-0.1658\n",
            "ap ita\t\t-0.1449\n",
            "ita e\t\t-0.0842\n",
            "e ▁Super\t\t-0.0233\n",
            "▁Super ▁interview\t\t-0.0128\n",
            "▁interview ▁Vin\t\t0.0004\n",
            "▁Vin c\t\t0.0681\n",
            "c ze\t\t0.0729\n",
            "ze De\t\t0.0171\n",
            "De g\t\t-0.0577\n",
            "g row\t\t-0.0816\n",
            "row th\t\t-0.0548\n",
            "th ▁sommes\t\t-0.0251\n",
            "▁sommes ▁en\t\t-0.0506\n",
            "▁en ferme\t\t-0.0529\n",
            "ferme s\t\t-0.0661\n",
            "s ▁dans\t\t-0.0501\n",
            "▁dans ▁religion\t\t-0.0230\n",
            "▁religion ▁croissance\t\t-0.0215\n",
            "▁croissance ▁E\t\t-0.1074\n",
            "▁E cout\t\t-0.3266\n",
            "cout ons\t\t-0.4537\n",
            "ons -\t\t-0.3869\n",
            "- le\t\t-0.2348\n",
            "le ▁pour\t\t-0.1667\n",
            "▁pour ▁en\t\t-0.1281\n",
            "▁en ▁s\t\t-0.0836\n",
            "▁s or\t\t0.0070\n",
            "or </s>\t\t0.5779\n",
            "\n",
            "Trigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁RT ▁Al\t\t-0.7217\n",
            "▁RT ▁Al ter\t\t-0.7083\n",
            "▁Al ter K\t\t-0.0576\n",
            "ter K ap\t\t-0.1523\n",
            "K ap ita\t\t-0.2152\n",
            "ap ita e\t\t-0.1796\n",
            "ita e ▁Super\t\t-0.0728\n",
            "e ▁Super ▁interview\t\t-0.0475\n",
            "▁Super ▁interview ▁Vin\t\t0.0118\n",
            "▁interview ▁Vin c\t\t0.0439\n",
            "▁Vin c ze\t\t0.0975\n",
            "c ze De\t\t0.0606\n",
            "ze De g\t\t-0.0283\n",
            "De g row\t\t-0.0939\n",
            "g row th\t\t-0.1002\n",
            "row th ▁sommes\t\t-0.0613\n",
            "th ▁sommes ▁en\t\t-0.0692\n",
            "▁sommes ▁en ferme\t\t-0.0594\n",
            "▁en ferme s\t\t-0.1102\n",
            "ferme s ▁dans\t\t-0.0589\n",
            "s ▁dans ▁religion\t\t-0.0803\n",
            "▁dans ▁religion ▁croissance\t\t-0.0143\n",
            "▁religion ▁croissance ▁E\t\t-0.1375\n",
            "▁croissance ▁E cout\t\t-0.3179\n",
            "▁E cout ons\t\t-0.5697\n",
            "cout ons -\t\t-0.5974\n",
            "ons - le\t\t-0.4779\n",
            "- le ▁pour\t\t-0.3105\n",
            "le ▁pour ▁en\t\t-0.2191\n",
            "▁pour ▁en ▁s\t\t-0.1593\n",
            "▁en ▁s or\t\t-0.0454\n",
            "▁s or </s>\t\t0.5467\n",
            "\n",
            "Predicted Class: décroissance\n",
            "True Class: décroissance\n",
            "Predicted Probability: 3.011197090148926\n",
            "Target Attribution Score: -1.5029515551632437\n",
            "\n",
            "==================================================\n",
            "\n",
            "Target Class: décroissance\n",
            "Token\t\tAttribution Score\n",
            "--------------------------\n",
            "<s>\t\t0.0000\n",
            "▁RT\t\t0.0124\n",
            "▁Al\t\t-0.0416\n",
            "ter\t\t0.0027\n",
            "K\t\t0.0849\n",
            "ap\t\t-0.0058\n",
            "ita\t\t0.0481\n",
            "e\t\t-0.0191\n",
            "▁Super\t\t-0.0640\n",
            "▁interview\t\t-0.0501\n",
            "▁Vin\t\t-0.0688\n",
            "c\t\t-0.0093\n",
            "ze\t\t-0.0602\n",
            "De\t\t-0.0141\n",
            "g\t\t0.2284\n",
            "row\t\t0.2170\n",
            "th\t\t0.0849\n",
            "▁sommes\t\t0.0837\n",
            "▁en\t\t0.2521\n",
            "ferme\t\t0.0730\n",
            "s\t\t0.3516\n",
            "▁dans\t\t0.3728\n",
            "▁religion\t\t0.1606\n",
            "▁croissance\t\t0.7021\n",
            "▁E\t\t0.0489\n",
            "cout\t\t-0.0014\n",
            "ons\t\t0.0644\n",
            "-\t\t0.0394\n",
            "le\t\t0.0178\n",
            "▁pour\t\t0.0046\n",
            "▁en\t\t0.0204\n",
            "▁s\t\t0.0056\n",
            "or\t\t0.0205\n",
            "</s>\t\t-0.0014\n",
            "\n",
            "Bigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁RT\t\t0.0124\n",
            "▁RT ▁Al\t\t-0.0291\n",
            "▁Al ter\t\t-0.0388\n",
            "ter K\t\t0.0876\n",
            "K ap\t\t0.0790\n",
            "ap ita\t\t0.0423\n",
            "ita e\t\t0.0291\n",
            "e ▁Super\t\t-0.0831\n",
            "▁Super ▁interview\t\t-0.1141\n",
            "▁interview ▁Vin\t\t-0.1189\n",
            "▁Vin c\t\t-0.0781\n",
            "c ze\t\t-0.0695\n",
            "ze De\t\t-0.0742\n",
            "De g\t\t0.2143\n",
            "g row\t\t0.4453\n",
            "row th\t\t0.3019\n",
            "th ▁sommes\t\t0.1686\n",
            "▁sommes ▁en\t\t0.3358\n",
            "▁en ferme\t\t0.3252\n",
            "ferme s\t\t0.4247\n",
            "s ▁dans\t\t0.7244\n",
            "▁dans ▁religion\t\t0.5334\n",
            "▁religion ▁croissance\t\t0.8627\n",
            "▁croissance ▁E\t\t0.7510\n",
            "▁E cout\t\t0.0475\n",
            "cout ons\t\t0.0629\n",
            "ons -\t\t0.1038\n",
            "- le\t\t0.0572\n",
            "le ▁pour\t\t0.0224\n",
            "▁pour ▁en\t\t0.0249\n",
            "▁en ▁s\t\t0.0260\n",
            "▁s or\t\t0.0261\n",
            "or </s>\t\t0.0191\n",
            "\n",
            "Trigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁RT ▁Al\t\t-0.0291\n",
            "▁RT ▁Al ter\t\t-0.0264\n",
            "▁Al ter K\t\t0.0460\n",
            "ter K ap\t\t0.0818\n",
            "K ap ita\t\t0.1272\n",
            "ap ita e\t\t0.0232\n",
            "ita e ▁Super\t\t-0.0349\n",
            "e ▁Super ▁interview\t\t-0.1332\n",
            "▁Super ▁interview ▁Vin\t\t-0.1829\n",
            "▁interview ▁Vin c\t\t-0.1282\n",
            "▁Vin c ze\t\t-0.1382\n",
            "c ze De\t\t-0.0835\n",
            "ze De g\t\t0.1541\n",
            "De g row\t\t0.4313\n",
            "g row th\t\t0.5303\n",
            "row th ▁sommes\t\t0.3856\n",
            "th ▁sommes ▁en\t\t0.4208\n",
            "▁sommes ▁en ferme\t\t0.4089\n",
            "▁en ferme s\t\t0.6768\n",
            "ferme s ▁dans\t\t0.7974\n",
            "s ▁dans ▁religion\t\t0.8850\n",
            "▁dans ▁religion ▁croissance\t\t1.2355\n",
            "▁religion ▁croissance ▁E\t\t0.9116\n",
            "▁croissance ▁E cout\t\t0.7496\n",
            "▁E cout ons\t\t0.1119\n",
            "cout ons -\t\t0.1024\n",
            "ons - le\t\t0.1216\n",
            "- le ▁pour\t\t0.0618\n",
            "le ▁pour ▁en\t\t0.0427\n",
            "▁pour ▁en ▁s\t\t0.0305\n",
            "▁en ▁s or\t\t0.0465\n",
            "▁s or </s>\t\t0.0248\n",
            "\n",
            "Predicted Class: décroissance\n",
            "True Class: décroissance\n",
            "Predicted Probability: 3.011197090148926\n",
            "Target Attribution Score: 2.560234151973852\n",
            "\n",
            "==================================================\n",
            "\n",
            "Target Class: nucléaire\n",
            "Token\t\tAttribution Score\n",
            "--------------------------\n",
            "<s>\t\t0.0000\n",
            "▁RT\t\t0.1303\n",
            "▁Al\t\t-0.1858\n",
            "ter\t\t-0.1931\n",
            "K\t\t0.4249\n",
            "ap\t\t-0.1662\n",
            "ita\t\t-0.0833\n",
            "e\t\t0.0675\n",
            "▁Super\t\t-0.0142\n",
            "▁interview\t\t-0.0255\n",
            "▁Vin\t\t-0.2077\n",
            "c\t\t-0.4394\n",
            "ze\t\t-0.5935\n",
            "De\t\t-0.0630\n",
            "g\t\t-0.0924\n",
            "row\t\t-0.0696\n",
            "th\t\t-0.0667\n",
            "▁sommes\t\t-0.0700\n",
            "▁en\t\t-0.0624\n",
            "ferme\t\t-0.0877\n",
            "s\t\t-0.1014\n",
            "▁dans\t\t-0.0511\n",
            "▁religion\t\t0.0010\n",
            "▁croissance\t\t-0.0487\n",
            "▁E\t\t-0.0340\n",
            "cout\t\t0.0431\n",
            "ons\t\t-0.0194\n",
            "-\t\t-0.0379\n",
            "le\t\t-0.0124\n",
            "▁pour\t\t-0.0402\n",
            "▁en\t\t-0.0461\n",
            "▁s\t\t-0.0140\n",
            "or\t\t-0.1433\n",
            "</s>\t\t-0.1387\n",
            "\n",
            "Bigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁RT\t\t0.1303\n",
            "▁RT ▁Al\t\t-0.0555\n",
            "▁Al ter\t\t-0.3788\n",
            "ter K\t\t0.2319\n",
            "K ap\t\t0.2587\n",
            "ap ita\t\t-0.2495\n",
            "ita e\t\t-0.0158\n",
            "e ▁Super\t\t0.0533\n",
            "▁Super ▁interview\t\t-0.0397\n",
            "▁interview ▁Vin\t\t-0.2332\n",
            "▁Vin c\t\t-0.6471\n",
            "c ze\t\t-1.0329\n",
            "ze De\t\t-0.6565\n",
            "De g\t\t-0.1555\n",
            "g row\t\t-0.1620\n",
            "row th\t\t-0.1363\n",
            "th ▁sommes\t\t-0.1367\n",
            "▁sommes ▁en\t\t-0.1324\n",
            "▁en ferme\t\t-0.1501\n",
            "ferme s\t\t-0.1891\n",
            "s ▁dans\t\t-0.1525\n",
            "▁dans ▁religion\t\t-0.0501\n",
            "▁religion ▁croissance\t\t-0.0477\n",
            "▁croissance ▁E\t\t-0.0828\n",
            "▁E cout\t\t0.0090\n",
            "cout ons\t\t0.0237\n",
            "ons -\t\t-0.0573\n",
            "- le\t\t-0.0503\n",
            "le ▁pour\t\t-0.0526\n",
            "▁pour ▁en\t\t-0.0863\n",
            "▁en ▁s\t\t-0.0600\n",
            "▁s or\t\t-0.1573\n",
            "or </s>\t\t-0.2820\n",
            "\n",
            "Trigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁RT ▁Al\t\t-0.0555\n",
            "▁RT ▁Al ter\t\t-0.2486\n",
            "▁Al ter K\t\t0.0461\n",
            "ter K ap\t\t0.0656\n",
            "K ap ita\t\t0.1754\n",
            "ap ita e\t\t-0.1820\n",
            "ita e ▁Super\t\t-0.0300\n",
            "e ▁Super ▁interview\t\t0.0278\n",
            "▁Super ▁interview ▁Vin\t\t-0.2474\n",
            "▁interview ▁Vin c\t\t-0.6726\n",
            "▁Vin c ze\t\t-1.2406\n",
            "c ze De\t\t-1.0959\n",
            "ze De g\t\t-0.7490\n",
            "De g row\t\t-0.2250\n",
            "g row th\t\t-0.2288\n",
            "row th ▁sommes\t\t-0.2063\n",
            "th ▁sommes ▁en\t\t-0.1991\n",
            "▁sommes ▁en ferme\t\t-0.2201\n",
            "▁en ferme s\t\t-0.2515\n",
            "ferme s ▁dans\t\t-0.2402\n",
            "s ▁dans ▁religion\t\t-0.1515\n",
            "▁dans ▁religion ▁croissance\t\t-0.0988\n",
            "▁religion ▁croissance ▁E\t\t-0.0818\n",
            "▁croissance ▁E cout\t\t-0.0397\n",
            "▁E cout ons\t\t-0.0104\n",
            "cout ons -\t\t-0.0142\n",
            "ons - le\t\t-0.0697\n",
            "- le ▁pour\t\t-0.0905\n",
            "le ▁pour ▁en\t\t-0.0987\n",
            "▁pour ▁en ▁s\t\t-0.1003\n",
            "▁en ▁s or\t\t-0.2034\n",
            "▁s or </s>\t\t-0.2960\n",
            "\n",
            "Predicted Class: décroissance\n",
            "True Class: décroissance\n",
            "Predicted Probability: 3.011197090148926\n",
            "Target Attribution Score: -2.4408990767339827\n",
            "\n",
            "==================================================\n",
            "\n",
            "Target Class: viande\n",
            "Token\t\tAttribution Score\n",
            "--------------------------\n",
            "<s>\t\t0.0000\n",
            "▁RT\t\t0.0409\n",
            "▁Al\t\t0.1456\n",
            "ter\t\t0.0301\n",
            "K\t\t-0.0973\n",
            "ap\t\t0.1255\n",
            "ita\t\t0.0820\n",
            "e\t\t0.0550\n",
            "▁Super\t\t0.1081\n",
            "▁interview\t\t0.0796\n",
            "▁Vin\t\t0.1010\n",
            "c\t\t0.1420\n",
            "ze\t\t0.1711\n",
            "De\t\t0.1047\n",
            "g\t\t-0.1881\n",
            "row\t\t-0.1817\n",
            "th\t\t-0.0566\n",
            "▁sommes\t\t0.0244\n",
            "▁en\t\t-0.1807\n",
            "ferme\t\t0.1633\n",
            "s\t\t-0.1066\n",
            "▁dans\t\t-0.2568\n",
            "▁religion\t\t-0.2188\n",
            "▁croissance\t\t-0.7400\n",
            "▁E\t\t0.0173\n",
            "cout\t\t0.0339\n",
            "ons\t\t0.0350\n",
            "-\t\t0.0542\n",
            "le\t\t0.0500\n",
            "▁pour\t\t0.0758\n",
            "▁en\t\t0.0871\n",
            "▁s\t\t0.1334\n",
            "or\t\t-0.0049\n",
            "</s>\t\t-0.0956\n",
            "\n",
            "Bigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁RT\t\t0.0409\n",
            "▁RT ▁Al\t\t0.1865\n",
            "▁Al ter\t\t0.1757\n",
            "ter K\t\t-0.0672\n",
            "K ap\t\t0.0282\n",
            "ap ita\t\t0.2075\n",
            "ita e\t\t0.1370\n",
            "e ▁Super\t\t0.1631\n",
            "▁Super ▁interview\t\t0.1877\n",
            "▁interview ▁Vin\t\t0.1805\n",
            "▁Vin c\t\t0.2429\n",
            "c ze\t\t0.3131\n",
            "ze De\t\t0.2758\n",
            "De g\t\t-0.0834\n",
            "g row\t\t-0.3698\n",
            "row th\t\t-0.2384\n",
            "th ▁sommes\t\t-0.0323\n",
            "▁sommes ▁en\t\t-0.1564\n",
            "▁en ferme\t\t-0.0175\n",
            "ferme s\t\t0.0567\n",
            "s ▁dans\t\t-0.3634\n",
            "▁dans ▁religion\t\t-0.4756\n",
            "▁religion ▁croissance\t\t-0.9587\n",
            "▁croissance ▁E\t\t-0.7227\n",
            "▁E cout\t\t0.0512\n",
            "cout ons\t\t0.0689\n",
            "ons -\t\t0.0892\n",
            "- le\t\t0.1042\n",
            "le ▁pour\t\t0.1258\n",
            "▁pour ▁en\t\t0.1628\n",
            "▁en ▁s\t\t0.2205\n",
            "▁s or\t\t0.1285\n",
            "or </s>\t\t-0.1005\n",
            "\n",
            "Trigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁RT ▁Al\t\t0.1865\n",
            "▁RT ▁Al ter\t\t0.2166\n",
            "▁Al ter K\t\t0.0784\n",
            "ter K ap\t\t0.0582\n",
            "K ap ita\t\t0.1102\n",
            "ap ita e\t\t0.2625\n",
            "ita e ▁Super\t\t0.2451\n",
            "e ▁Super ▁interview\t\t0.2426\n",
            "▁Super ▁interview ▁Vin\t\t0.2886\n",
            "▁interview ▁Vin c\t\t0.3225\n",
            "▁Vin c ze\t\t0.4140\n",
            "c ze De\t\t0.4177\n",
            "ze De g\t\t0.0877\n",
            "De g row\t\t-0.2652\n",
            "g row th\t\t-0.4265\n",
            "row th ▁sommes\t\t-0.2140\n",
            "th ▁sommes ▁en\t\t-0.2130\n",
            "▁sommes ▁en ferme\t\t0.0069\n",
            "▁en ferme s\t\t-0.1240\n",
            "ferme s ▁dans\t\t-0.2001\n",
            "s ▁dans ▁religion\t\t-0.5822\n",
            "▁dans ▁religion ▁croissance\t\t-1.2156\n",
            "▁religion ▁croissance ▁E\t\t-0.9414\n",
            "▁croissance ▁E cout\t\t-0.6887\n",
            "▁E cout ons\t\t0.0862\n",
            "cout ons -\t\t0.1231\n",
            "ons - le\t\t0.1392\n",
            "- le ▁pour\t\t0.1800\n",
            "le ▁pour ▁en\t\t0.2129\n",
            "▁pour ▁en ▁s\t\t0.2962\n",
            "▁en ▁s or\t\t0.2156\n",
            "▁s or </s>\t\t0.0329\n",
            "\n",
            "Predicted Class: décroissance\n",
            "True Class: décroissance\n",
            "Predicted Probability: 3.011197090148926\n",
            "Target Attribution Score: -0.26744702858891145\n",
            "\n",
            "==================================================\n",
            "\n",
            "Sentence: Entre les transactivistes myopes qui s'abonnent puis se désabonnent, et les trolls soutiens des éleveurs intensifs et de l'agriculture productiviste qui commentent à côté de la plaque, je n'en peux plus. Marc Lesggy leur met des favoris, en plus.  💣\n",
            "Target Class: avion\n",
            "Token\t\tAttribution Score\n",
            "--------------------------\n",
            "<s>\t\t0.0000\n",
            "▁Entre\t\t-0.0737\n",
            "▁trans\t\t-0.0983\n",
            "activiste\t\t0.8741\n",
            "s\t\t0.0080\n",
            "▁my\t\t-0.0528\n",
            "ope\t\t0.0155\n",
            "s\t\t0.0517\n",
            "▁qui\t\t0.0336\n",
            "▁s\t\t-0.0374\n",
            "'\t\t0.0896\n",
            "a\t\t0.1217\n",
            "bonne\t\t-0.0034\n",
            "nt\t\t0.0105\n",
            "▁puis\t\t-0.0090\n",
            "▁se\t\t-0.0285\n",
            "▁des\t\t-0.1125\n",
            "a\t\t-0.0785\n",
            "bonne\t\t0.0249\n",
            "nt\t\t0.0184\n",
            "▁et\t\t0.0170\n",
            "▁troll\t\t-0.0003\n",
            "s\t\t0.0154\n",
            "▁soutien\t\t-0.0261\n",
            "s\t\t-0.0159\n",
            "▁e\t\t-0.0587\n",
            "lev\t\t0.0337\n",
            "eurs\t\t-0.0555\n",
            "▁intensif\t\t-0.0071\n",
            "s\t\t0.0103\n",
            "▁et\t\t0.0445\n",
            "▁l\t\t0.0311\n",
            "'\t\t0.1344\n",
            "agriculture\t\t0.0520\n",
            "▁\t\t0.0046\n",
            "product\t\t0.0028\n",
            "iv\t\t0.0360\n",
            "iste\t\t-0.0124\n",
            "▁qui\t\t-0.0075\n",
            "▁comment\t\t-0.0342\n",
            "ent\t\t-0.0062\n",
            "▁a\t\t0.0869\n",
            "▁cote\t\t-0.0394\n",
            "▁plaque\t\t0.0487\n",
            "▁n\t\t-0.0136\n",
            "'\t\t0.0757\n",
            "en\t\t-0.0030\n",
            "▁peux\t\t0.1313\n",
            "▁plus\t\t0.0308\n",
            "▁Marc\t\t-0.0344\n",
            "▁Les\t\t-0.0827\n",
            "ggy\t\t0.0047\n",
            "▁leur\t\t0.0447\n",
            "▁met\t\t0.0441\n",
            "▁favoris\t\t0.0280\n",
            "▁en\t\t0.1319\n",
            "▁plus\t\t0.0259\n",
            "▁b\t\t-0.0153\n",
            "omb\t\t0.1791\n",
            "</s>\t\t0.1858\n",
            "\n",
            "Bigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁Entre\t\t-0.0737\n",
            "▁Entre ▁trans\t\t-0.1719\n",
            "▁trans activiste\t\t0.7758\n",
            "activiste s\t\t0.8820\n",
            "s ▁my\t\t-0.0448\n",
            "▁my ope\t\t-0.0373\n",
            "ope s\t\t0.0672\n",
            "s ▁qui\t\t0.0853\n",
            "▁qui ▁s\t\t-0.0037\n",
            "▁s '\t\t0.0522\n",
            "' a\t\t0.2113\n",
            "a bonne\t\t0.1183\n",
            "bonne nt\t\t0.0071\n",
            "nt ▁puis\t\t0.0014\n",
            "▁puis ▁se\t\t-0.0375\n",
            "▁se ▁des\t\t-0.1410\n",
            "▁des a\t\t-0.1909\n",
            "a bonne\t\t-0.0535\n",
            "bonne nt\t\t0.0433\n",
            "nt ▁et\t\t0.0354\n",
            "▁et ▁troll\t\t0.0167\n",
            "▁troll s\t\t0.0150\n",
            "s ▁soutien\t\t-0.0107\n",
            "▁soutien s\t\t-0.0420\n",
            "s ▁e\t\t-0.0745\n",
            "▁e lev\t\t-0.0250\n",
            "lev eurs\t\t-0.0218\n",
            "eurs ▁intensif\t\t-0.0625\n",
            "▁intensif s\t\t0.0033\n",
            "s ▁et\t\t0.0548\n",
            "▁et ▁l\t\t0.0756\n",
            "▁l '\t\t0.1655\n",
            "' agriculture\t\t0.1864\n",
            "agriculture ▁\t\t0.0566\n",
            "▁ product\t\t0.0074\n",
            "product iv\t\t0.0389\n",
            "iv iste\t\t0.0237\n",
            "iste ▁qui\t\t-0.0198\n",
            "▁qui ▁comment\t\t-0.0416\n",
            "▁comment ent\t\t-0.0404\n",
            "ent ▁a\t\t0.0807\n",
            "▁a ▁cote\t\t0.0476\n",
            "▁cote ▁plaque\t\t0.0093\n",
            "▁plaque ▁n\t\t0.0351\n",
            "▁n '\t\t0.0621\n",
            "' en\t\t0.0727\n",
            "en ▁peux\t\t0.1283\n",
            "▁peux ▁plus\t\t0.1622\n",
            "▁plus ▁Marc\t\t-0.0036\n",
            "▁Marc ▁Les\t\t-0.1172\n",
            "▁Les ggy\t\t-0.0781\n",
            "ggy ▁leur\t\t0.0493\n",
            "▁leur ▁met\t\t0.0888\n",
            "▁met ▁favoris\t\t0.0721\n",
            "▁favoris ▁en\t\t0.1599\n",
            "▁en ▁plus\t\t0.1578\n",
            "▁plus ▁b\t\t0.0106\n",
            "▁b omb\t\t0.1638\n",
            "omb </s>\t\t0.3649\n",
            "\n",
            "Trigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁Entre ▁trans\t\t-0.1719\n",
            "▁Entre ▁trans activiste\t\t0.7021\n",
            "▁trans activiste s\t\t0.7838\n",
            "activiste s ▁my\t\t0.8292\n",
            "s ▁my ope\t\t-0.0293\n",
            "▁my ope s\t\t0.0144\n",
            "ope s ▁qui\t\t0.1008\n",
            "s ▁qui ▁s\t\t0.0480\n",
            "▁qui ▁s '\t\t0.0858\n",
            "▁s ' a\t\t0.1739\n",
            "' a bonne\t\t0.2079\n",
            "a bonne nt\t\t0.1287\n",
            "bonne nt ▁puis\t\t-0.0020\n",
            "nt ▁puis ▁se\t\t-0.0271\n",
            "▁puis ▁se ▁des\t\t-0.1500\n",
            "▁se ▁des a\t\t-0.2194\n",
            "▁des a bonne\t\t-0.1660\n",
            "a bonne nt\t\t-0.0352\n",
            "bonne nt ▁et\t\t0.0603\n",
            "nt ▁et ▁troll\t\t0.0351\n",
            "▁et ▁troll s\t\t0.0321\n",
            "▁troll s ▁soutien\t\t-0.0110\n",
            "s ▁soutien s\t\t-0.0266\n",
            "▁soutien s ▁e\t\t-0.1006\n",
            "s ▁e lev\t\t-0.0408\n",
            "▁e lev eurs\t\t-0.0804\n",
            "lev eurs ▁intensif\t\t-0.0288\n",
            "eurs ▁intensif s\t\t-0.0522\n",
            "▁intensif s ▁et\t\t0.0478\n",
            "s ▁et ▁l\t\t0.0860\n",
            "▁et ▁l '\t\t0.2100\n",
            "▁l ' agriculture\t\t0.2175\n",
            "' agriculture ▁\t\t0.1910\n",
            "agriculture ▁ product\t\t0.0594\n",
            "▁ product iv\t\t0.0435\n",
            "product iv iste\t\t0.0265\n",
            "iv iste ▁qui\t\t0.0162\n",
            "iste ▁qui ▁comment\t\t-0.0540\n",
            "▁qui ▁comment ent\t\t-0.0478\n",
            "▁comment ent ▁a\t\t0.0466\n",
            "ent ▁a ▁cote\t\t0.0414\n",
            "▁a ▁cote ▁plaque\t\t0.0962\n",
            "▁cote ▁plaque ▁n\t\t-0.0043\n",
            "▁plaque ▁n '\t\t0.1108\n",
            "▁n ' en\t\t0.0591\n",
            "' en ▁peux\t\t0.2040\n",
            "en ▁peux ▁plus\t\t0.1591\n",
            "▁peux ▁plus ▁Marc\t\t0.1277\n",
            "▁plus ▁Marc ▁Les\t\t-0.0863\n",
            "▁Marc ▁Les ggy\t\t-0.1125\n",
            "▁Les ggy ▁leur\t\t-0.0334\n",
            "ggy ▁leur ▁met\t\t0.0934\n",
            "▁leur ▁met ▁favoris\t\t0.1168\n",
            "▁met ▁favoris ▁en\t\t0.2040\n",
            "▁favoris ▁en ▁plus\t\t0.1858\n",
            "▁en ▁plus ▁b\t\t0.1425\n",
            "▁plus ▁b omb\t\t0.1897\n",
            "▁b omb </s>\t\t0.3496\n",
            "\n",
            "Predicted Class: décroissance\n",
            "True Class: décroissance\n",
            "Predicted Probability: 3.0050876140594482\n",
            "Target Attribution Score: 1.7412060087959198\n",
            "\n",
            "==================================================\n",
            "\n",
            "Target Class: décroissance\n",
            "Token\t\tAttribution Score\n",
            "--------------------------\n",
            "<s>\t\t0.0000\n",
            "▁Entre\t\t-0.0162\n",
            "▁trans\t\t-0.0929\n",
            "activiste\t\t-0.0038\n",
            "s\t\t0.0925\n",
            "▁my\t\t0.0814\n",
            "ope\t\t-0.0141\n",
            "s\t\t0.1167\n",
            "▁qui\t\t0.1986\n",
            "▁s\t\t0.2895\n",
            "'\t\t0.1595\n",
            "a\t\t0.2745\n",
            "bonne\t\t0.3162\n",
            "nt\t\t0.3839\n",
            "▁puis\t\t0.0680\n",
            "▁se\t\t0.1022\n",
            "▁des\t\t0.0659\n",
            "a\t\t0.0181\n",
            "bonne\t\t0.0030\n",
            "nt\t\t0.0649\n",
            "▁et\t\t-0.0026\n",
            "▁troll\t\t-0.0397\n",
            "s\t\t-0.0006\n",
            "▁soutien\t\t0.0758\n",
            "s\t\t0.0561\n",
            "▁e\t\t-0.0068\n",
            "lev\t\t-0.1223\n",
            "eurs\t\t-0.1642\n",
            "▁intensif\t\t-0.0372\n",
            "s\t\t-0.0904\n",
            "▁et\t\t-0.2130\n",
            "▁l\t\t-0.2522\n",
            "'\t\t-0.1970\n",
            "agriculture\t\t-0.3035\n",
            "▁\t\t0.0891\n",
            "product\t\t0.1838\n",
            "iv\t\t0.1683\n",
            "iste\t\t0.2596\n",
            "▁qui\t\t0.0531\n",
            "▁comment\t\t0.0231\n",
            "ent\t\t0.0202\n",
            "▁a\t\t-0.0036\n",
            "▁cote\t\t0.0366\n",
            "▁plaque\t\t-0.0424\n",
            "▁n\t\t0.0057\n",
            "'\t\t0.0296\n",
            "en\t\t0.0405\n",
            "▁peux\t\t-0.0844\n",
            "▁plus\t\t-0.0230\n",
            "▁Marc\t\t0.0452\n",
            "▁Les\t\t0.0394\n",
            "ggy\t\t-0.0245\n",
            "▁leur\t\t0.0063\n",
            "▁met\t\t0.0202\n",
            "▁favoris\t\t-0.0117\n",
            "▁en\t\t-0.0351\n",
            "▁plus\t\t-0.0083\n",
            "▁b\t\t0.0107\n",
            "omb\t\t-0.0467\n",
            "</s>\t\t-0.0438\n",
            "\n",
            "Bigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁Entre\t\t-0.0162\n",
            "▁Entre ▁trans\t\t-0.1091\n",
            "▁trans activiste\t\t-0.0967\n",
            "activiste s\t\t0.0887\n",
            "s ▁my\t\t0.1738\n",
            "▁my ope\t\t0.0673\n",
            "ope s\t\t0.1026\n",
            "s ▁qui\t\t0.3153\n",
            "▁qui ▁s\t\t0.4881\n",
            "▁s '\t\t0.4490\n",
            "' a\t\t0.4340\n",
            "a bonne\t\t0.5907\n",
            "bonne nt\t\t0.7000\n",
            "nt ▁puis\t\t0.4518\n",
            "▁puis ▁se\t\t0.1702\n",
            "▁se ▁des\t\t0.1681\n",
            "▁des a\t\t0.0840\n",
            "a bonne\t\t0.0211\n",
            "bonne nt\t\t0.0679\n",
            "nt ▁et\t\t0.0623\n",
            "▁et ▁troll\t\t-0.0424\n",
            "▁troll s\t\t-0.0403\n",
            "s ▁soutien\t\t0.0753\n",
            "▁soutien s\t\t0.1319\n",
            "s ▁e\t\t0.0493\n",
            "▁e lev\t\t-0.1291\n",
            "lev eurs\t\t-0.2865\n",
            "eurs ▁intensif\t\t-0.2014\n",
            "▁intensif s\t\t-0.1277\n",
            "s ▁et\t\t-0.3035\n",
            "▁et ▁l\t\t-0.4652\n",
            "▁l '\t\t-0.4492\n",
            "' agriculture\t\t-0.5006\n",
            "agriculture ▁\t\t-0.2144\n",
            "▁ product\t\t0.2729\n",
            "product iv\t\t0.3521\n",
            "iv iste\t\t0.4278\n",
            "iste ▁qui\t\t0.3127\n",
            "▁qui ▁comment\t\t0.0762\n",
            "▁comment ent\t\t0.0433\n",
            "ent ▁a\t\t0.0166\n",
            "▁a ▁cote\t\t0.0330\n",
            "▁cote ▁plaque\t\t-0.0057\n",
            "▁plaque ▁n\t\t-0.0366\n",
            "▁n '\t\t0.0353\n",
            "' en\t\t0.0701\n",
            "en ▁peux\t\t-0.0439\n",
            "▁peux ▁plus\t\t-0.1074\n",
            "▁plus ▁Marc\t\t0.0222\n",
            "▁Marc ▁Les\t\t0.0846\n",
            "▁Les ggy\t\t0.0148\n",
            "ggy ▁leur\t\t-0.0182\n",
            "▁leur ▁met\t\t0.0265\n",
            "▁met ▁favoris\t\t0.0086\n",
            "▁favoris ▁en\t\t-0.0467\n",
            "▁en ▁plus\t\t-0.0434\n",
            "▁plus ▁b\t\t0.0024\n",
            "▁b omb\t\t-0.0360\n",
            "omb </s>\t\t-0.0905\n",
            "\n",
            "Trigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁Entre ▁trans\t\t-0.1091\n",
            "▁Entre ▁trans activiste\t\t-0.1129\n",
            "▁trans activiste s\t\t-0.0042\n",
            "activiste s ▁my\t\t0.1700\n",
            "s ▁my ope\t\t0.1598\n",
            "▁my ope s\t\t0.1840\n",
            "ope s ▁qui\t\t0.3012\n",
            "s ▁qui ▁s\t\t0.6048\n",
            "▁qui ▁s '\t\t0.6476\n",
            "▁s ' a\t\t0.7235\n",
            "' a bonne\t\t0.7501\n",
            "a bonne nt\t\t0.9745\n",
            "bonne nt ▁puis\t\t0.7680\n",
            "nt ▁puis ▁se\t\t0.5540\n",
            "▁puis ▁se ▁des\t\t0.2361\n",
            "▁se ▁des a\t\t0.1862\n",
            "▁des a bonne\t\t0.0870\n",
            "a bonne nt\t\t0.0860\n",
            "bonne nt ▁et\t\t0.0652\n",
            "nt ▁et ▁troll\t\t0.0225\n",
            "▁et ▁troll s\t\t-0.0429\n",
            "▁troll s ▁soutien\t\t0.0356\n",
            "s ▁soutien s\t\t0.1314\n",
            "▁soutien s ▁e\t\t0.1251\n",
            "s ▁e lev\t\t-0.0730\n",
            "▁e lev eurs\t\t-0.2933\n",
            "lev eurs ▁intensif\t\t-0.3237\n",
            "eurs ▁intensif s\t\t-0.2919\n",
            "▁intensif s ▁et\t\t-0.3407\n",
            "s ▁et ▁l\t\t-0.5557\n",
            "▁et ▁l '\t\t-0.6623\n",
            "▁l ' agriculture\t\t-0.7528\n",
            "' agriculture ▁\t\t-0.4115\n",
            "agriculture ▁ product\t\t-0.0306\n",
            "▁ product iv\t\t0.4412\n",
            "product iv iste\t\t0.6117\n",
            "iv iste ▁qui\t\t0.4809\n",
            "iste ▁qui ▁comment\t\t0.3358\n",
            "▁qui ▁comment ent\t\t0.0964\n",
            "▁comment ent ▁a\t\t0.0397\n",
            "ent ▁a ▁cote\t\t0.0532\n",
            "▁a ▁cote ▁plaque\t\t-0.0093\n",
            "▁cote ▁plaque ▁n\t\t0.0000\n",
            "▁plaque ▁n '\t\t-0.0070\n",
            "▁n ' en\t\t0.0759\n",
            "' en ▁peux\t\t-0.0143\n",
            "en ▁peux ▁plus\t\t-0.0669\n",
            "▁peux ▁plus ▁Marc\t\t-0.0622\n",
            "▁plus ▁Marc ▁Les\t\t0.0616\n",
            "▁Marc ▁Les ggy\t\t0.0601\n",
            "▁Les ggy ▁leur\t\t0.0211\n",
            "ggy ▁leur ▁met\t\t0.0020\n",
            "▁leur ▁met ▁favoris\t\t0.0149\n",
            "▁met ▁favoris ▁en\t\t-0.0265\n",
            "▁favoris ▁en ▁plus\t\t-0.0550\n",
            "▁en ▁plus ▁b\t\t-0.0327\n",
            "▁plus ▁b omb\t\t-0.0443\n",
            "▁b omb </s>\t\t-0.0799\n",
            "\n",
            "Predicted Class: décroissance\n",
            "True Class: décroissance\n",
            "Predicted Probability: 3.0050876140594482\n",
            "Target Attribution Score: 1.5179755539940512\n",
            "\n",
            "==================================================\n",
            "\n",
            "Target Class: nucléaire\n",
            "Token\t\tAttribution Score\n",
            "--------------------------\n",
            "<s>\t\t0.0000\n",
            "▁Entre\t\t0.0734\n",
            "▁trans\t\t0.1143\n",
            "activiste\t\t-0.8456\n",
            "s\t\t-0.0413\n",
            "▁my\t\t0.0346\n",
            "ope\t\t-0.0007\n",
            "s\t\t-0.0295\n",
            "▁qui\t\t0.0103\n",
            "▁s\t\t0.1632\n",
            "'\t\t-0.2305\n",
            "a\t\t-0.2052\n",
            "bonne\t\t-0.0523\n",
            "nt\t\t-0.0295\n",
            "▁puis\t\t-0.0203\n",
            "▁se\t\t0.0195\n",
            "▁des\t\t0.0508\n",
            "a\t\t0.0817\n",
            "bonne\t\t-0.0284\n",
            "nt\t\t-0.0032\n",
            "▁et\t\t-0.0327\n",
            "▁troll\t\t0.0078\n",
            "s\t\t-0.0370\n",
            "▁soutien\t\t0.0152\n",
            "s\t\t-0.0137\n",
            "▁e\t\t0.0353\n",
            "lev\t\t-0.0234\n",
            "eurs\t\t0.0296\n",
            "▁intensif\t\t0.0154\n",
            "s\t\t-0.0219\n",
            "▁et\t\t-0.0298\n",
            "▁l\t\t-0.0130\n",
            "'\t\t-0.0924\n",
            "agriculture\t\t-0.0267\n",
            "▁\t\t-0.0110\n",
            "product\t\t-0.0038\n",
            "iv\t\t-0.0215\n",
            "iste\t\t0.0115\n",
            "▁qui\t\t0.0131\n",
            "▁comment\t\t0.0355\n",
            "ent\t\t0.0527\n",
            "▁a\t\t-0.0497\n",
            "▁cote\t\t0.0436\n",
            "▁plaque\t\t-0.0273\n",
            "▁n\t\t0.0382\n",
            "'\t\t-0.0209\n",
            "en\t\t0.0294\n",
            "▁peux\t\t-0.2455\n",
            "▁plus\t\t0.0106\n",
            "▁Marc\t\t0.0549\n",
            "▁Les\t\t0.0793\n",
            "ggy\t\t0.0360\n",
            "▁leur\t\t0.0356\n",
            "▁met\t\t0.1072\n",
            "▁favoris\t\t-0.0159\n",
            "▁en\t\t-0.0531\n",
            "▁plus\t\t-0.0100\n",
            "▁b\t\t-0.0174\n",
            "omb\t\t0.0417\n",
            "</s>\t\t0.0889\n",
            "\n",
            "Bigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁Entre\t\t0.0734\n",
            "▁Entre ▁trans\t\t0.1878\n",
            "▁trans activiste\t\t-0.7312\n",
            "activiste s\t\t-0.8869\n",
            "s ▁my\t\t-0.0067\n",
            "▁my ope\t\t0.0339\n",
            "ope s\t\t-0.0302\n",
            "s ▁qui\t\t-0.0192\n",
            "▁qui ▁s\t\t0.1736\n",
            "▁s '\t\t-0.0673\n",
            "' a\t\t-0.4357\n",
            "a bonne\t\t-0.2575\n",
            "bonne nt\t\t-0.0817\n",
            "nt ▁puis\t\t-0.0498\n",
            "▁puis ▁se\t\t-0.0008\n",
            "▁se ▁des\t\t0.0702\n",
            "▁des a\t\t0.1324\n",
            "a bonne\t\t0.0532\n",
            "bonne nt\t\t-0.0316\n",
            "nt ▁et\t\t-0.0358\n",
            "▁et ▁troll\t\t-0.0249\n",
            "▁troll s\t\t-0.0292\n",
            "s ▁soutien\t\t-0.0219\n",
            "▁soutien s\t\t0.0015\n",
            "s ▁e\t\t0.0216\n",
            "▁e lev\t\t0.0119\n",
            "lev eurs\t\t0.0062\n",
            "eurs ▁intensif\t\t0.0449\n",
            "▁intensif s\t\t-0.0065\n",
            "s ▁et\t\t-0.0517\n",
            "▁et ▁l\t\t-0.0429\n",
            "▁l '\t\t-0.1054\n",
            "' agriculture\t\t-0.1191\n",
            "agriculture ▁\t\t-0.0376\n",
            "▁ product\t\t-0.0148\n",
            "product iv\t\t-0.0253\n",
            "iv iste\t\t-0.0100\n",
            "iste ▁qui\t\t0.0246\n",
            "▁qui ▁comment\t\t0.0486\n",
            "▁comment ent\t\t0.0882\n",
            "ent ▁a\t\t0.0030\n",
            "▁a ▁cote\t\t-0.0061\n",
            "▁cote ▁plaque\t\t0.0163\n",
            "▁plaque ▁n\t\t0.0109\n",
            "▁n '\t\t0.0173\n",
            "' en\t\t0.0085\n",
            "en ▁peux\t\t-0.2161\n",
            "▁peux ▁plus\t\t-0.2349\n",
            "▁plus ▁Marc\t\t0.0654\n",
            "▁Marc ▁Les\t\t0.1342\n",
            "▁Les ggy\t\t0.1153\n",
            "ggy ▁leur\t\t0.0716\n",
            "▁leur ▁met\t\t0.1428\n",
            "▁met ▁favoris\t\t0.0913\n",
            "▁favoris ▁en\t\t-0.0690\n",
            "▁en ▁plus\t\t-0.0631\n",
            "▁plus ▁b\t\t-0.0274\n",
            "▁b omb\t\t0.0243\n",
            "omb </s>\t\t0.1306\n",
            "\n",
            "Trigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁Entre ▁trans\t\t0.1878\n",
            "▁Entre ▁trans activiste\t\t-0.6578\n",
            "▁trans activiste s\t\t-0.7726\n",
            "activiste s ▁my\t\t-0.8523\n",
            "s ▁my ope\t\t-0.0074\n",
            "▁my ope s\t\t0.0044\n",
            "ope s ▁qui\t\t-0.0199\n",
            "s ▁qui ▁s\t\t0.1440\n",
            "▁qui ▁s '\t\t-0.0569\n",
            "▁s ' a\t\t-0.2725\n",
            "' a bonne\t\t-0.4880\n",
            "a bonne nt\t\t-0.2870\n",
            "bonne nt ▁puis\t\t-0.1020\n",
            "nt ▁puis ▁se\t\t-0.0303\n",
            "▁puis ▁se ▁des\t\t0.0499\n",
            "▁se ▁des a\t\t0.1519\n",
            "▁des a bonne\t\t0.1040\n",
            "a bonne nt\t\t0.0501\n",
            "bonne nt ▁et\t\t-0.0643\n",
            "nt ▁et ▁troll\t\t-0.0280\n",
            "▁et ▁troll s\t\t-0.0619\n",
            "▁troll s ▁soutien\t\t-0.0141\n",
            "s ▁soutien s\t\t-0.0356\n",
            "▁soutien s ▁e\t\t0.0367\n",
            "s ▁e lev\t\t-0.0018\n",
            "▁e lev eurs\t\t0.0414\n",
            "lev eurs ▁intensif\t\t0.0215\n",
            "eurs ▁intensif s\t\t0.0230\n",
            "▁intensif s ▁et\t\t-0.0364\n",
            "s ▁et ▁l\t\t-0.0647\n",
            "▁et ▁l '\t\t-0.1353\n",
            "▁l ' agriculture\t\t-0.1321\n",
            "' agriculture ▁\t\t-0.1301\n",
            "agriculture ▁ product\t\t-0.0415\n",
            "▁ product iv\t\t-0.0363\n",
            "product iv iste\t\t-0.0139\n",
            "iv iste ▁qui\t\t0.0031\n",
            "iste ▁qui ▁comment\t\t0.0601\n",
            "▁qui ▁comment ent\t\t0.1013\n",
            "▁comment ent ▁a\t\t0.0384\n",
            "ent ▁a ▁cote\t\t0.0466\n",
            "▁a ▁cote ▁plaque\t\t-0.0334\n",
            "▁cote ▁plaque ▁n\t\t0.0545\n",
            "▁plaque ▁n '\t\t-0.0100\n",
            "▁n ' en\t\t0.0467\n",
            "' en ▁peux\t\t-0.2370\n",
            "en ▁peux ▁plus\t\t-0.2055\n",
            "▁peux ▁plus ▁Marc\t\t-0.1800\n",
            "▁plus ▁Marc ▁Les\t\t0.1448\n",
            "▁Marc ▁Les ggy\t\t0.1702\n",
            "▁Les ggy ▁leur\t\t0.1509\n",
            "ggy ▁leur ▁met\t\t0.1788\n",
            "▁leur ▁met ▁favoris\t\t0.1269\n",
            "▁met ▁favoris ▁en\t\t0.0382\n",
            "▁favoris ▁en ▁plus\t\t-0.0790\n",
            "▁en ▁plus ▁b\t\t-0.0805\n",
            "▁plus ▁b omb\t\t0.0143\n",
            "▁b omb </s>\t\t0.1132\n",
            "\n",
            "Predicted Class: décroissance\n",
            "True Class: décroissance\n",
            "Predicted Probability: 3.0050876140594482\n",
            "Target Attribution Score: -0.9241292466408525\n",
            "\n",
            "==================================================\n",
            "\n",
            "Target Class: viande\n",
            "Token\t\tAttribution Score\n",
            "--------------------------\n",
            "<s>\t\t0.0000\n",
            "▁Entre\t\t-0.0256\n",
            "▁trans\t\t0.1213\n",
            "activiste\t\t-0.1555\n",
            "s\t\t-0.0777\n",
            "▁my\t\t-0.0384\n",
            "ope\t\t0.0255\n",
            "s\t\t-0.0663\n",
            "▁qui\t\t-0.0684\n",
            "▁s\t\t0.0155\n",
            "'\t\t-0.0613\n",
            "a\t\t-0.1411\n",
            "bonne\t\t-0.2060\n",
            "nt\t\t-0.2689\n",
            "▁puis\t\t-0.0629\n",
            "▁se\t\t-0.0649\n",
            "▁des\t\t-0.0179\n",
            "a\t\t0.0040\n",
            "bonne\t\t-0.0013\n",
            "nt\t\t-0.0260\n",
            "▁et\t\t0.0035\n",
            "▁troll\t\t-0.0145\n",
            "s\t\t-0.0070\n",
            "▁soutien\t\t-0.0441\n",
            "s\t\t-0.0051\n",
            "▁e\t\t0.0156\n",
            "lev\t\t0.2322\n",
            "eurs\t\t0.4051\n",
            "▁intensif\t\t0.0896\n",
            "s\t\t0.1000\n",
            "▁et\t\t0.2731\n",
            "▁l\t\t0.3500\n",
            "'\t\t0.2161\n",
            "agriculture\t\t0.3185\n",
            "▁\t\t-0.0534\n",
            "product\t\t-0.0377\n",
            "iv\t\t-0.1685\n",
            "iste\t\t-0.3135\n",
            "▁qui\t\t-0.0235\n",
            "▁comment\t\t-0.0212\n",
            "ent\t\t-0.0326\n",
            "▁a\t\t0.0141\n",
            "▁cote\t\t0.0107\n",
            "▁plaque\t\t0.0284\n",
            "▁n\t\t-0.0321\n",
            "'\t\t-0.0066\n",
            "en\t\t-0.0064\n",
            "▁peux\t\t0.1515\n",
            "▁plus\t\t-0.0253\n",
            "▁Marc\t\t0.0094\n",
            "▁Les\t\t-0.0010\n",
            "ggy\t\t0.0064\n",
            "▁leur\t\t0.0027\n",
            "▁met\t\t0.0082\n",
            "▁favoris\t\t0.0151\n",
            "▁en\t\t-0.0173\n",
            "▁plus\t\t-0.0058\n",
            "▁b\t\t-0.0196\n",
            "omb\t\t0.0617\n",
            "</s>\t\t-0.2186\n",
            "\n",
            "Bigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁Entre\t\t-0.0256\n",
            "▁Entre ▁trans\t\t0.0957\n",
            "▁trans activiste\t\t-0.0343\n",
            "activiste s\t\t-0.2332\n",
            "s ▁my\t\t-0.1161\n",
            "▁my ope\t\t-0.0130\n",
            "ope s\t\t-0.0408\n",
            "s ▁qui\t\t-0.1347\n",
            "▁qui ▁s\t\t-0.0528\n",
            "▁s '\t\t-0.0458\n",
            "' a\t\t-0.2024\n",
            "a bonne\t\t-0.3472\n",
            "bonne nt\t\t-0.4749\n",
            "nt ▁puis\t\t-0.3318\n",
            "▁puis ▁se\t\t-0.1278\n",
            "▁se ▁des\t\t-0.0828\n",
            "▁des a\t\t-0.0139\n",
            "a bonne\t\t0.0028\n",
            "bonne nt\t\t-0.0273\n",
            "nt ▁et\t\t-0.0225\n",
            "▁et ▁troll\t\t-0.0110\n",
            "▁troll s\t\t-0.0216\n",
            "s ▁soutien\t\t-0.0511\n",
            "▁soutien s\t\t-0.0492\n",
            "s ▁e\t\t0.0105\n",
            "▁e lev\t\t0.2478\n",
            "lev eurs\t\t0.6373\n",
            "eurs ▁intensif\t\t0.4946\n",
            "▁intensif s\t\t0.1896\n",
            "s ▁et\t\t0.3731\n",
            "▁et ▁l\t\t0.6231\n",
            "▁l '\t\t0.5661\n",
            "' agriculture\t\t0.5346\n",
            "agriculture ▁\t\t0.2651\n",
            "▁ product\t\t-0.0911\n",
            "product iv\t\t-0.2063\n",
            "iv iste\t\t-0.4821\n",
            "iste ▁qui\t\t-0.3370\n",
            "▁qui ▁comment\t\t-0.0446\n",
            "▁comment ent\t\t-0.0538\n",
            "ent ▁a\t\t-0.0186\n",
            "▁a ▁cote\t\t0.0248\n",
            "▁cote ▁plaque\t\t0.0391\n",
            "▁plaque ▁n\t\t-0.0037\n",
            "▁n '\t\t-0.0387\n",
            "' en\t\t-0.0130\n",
            "en ▁peux\t\t0.1451\n",
            "▁peux ▁plus\t\t0.1262\n",
            "▁plus ▁Marc\t\t-0.0159\n",
            "▁Marc ▁Les\t\t0.0084\n",
            "▁Les ggy\t\t0.0055\n",
            "ggy ▁leur\t\t0.0092\n",
            "▁leur ▁met\t\t0.0110\n",
            "▁met ▁favoris\t\t0.0234\n",
            "▁favoris ▁en\t\t-0.0021\n",
            "▁en ▁plus\t\t-0.0231\n",
            "▁plus ▁b\t\t-0.0254\n",
            "▁b omb\t\t0.0421\n",
            "omb </s>\t\t-0.1570\n",
            "\n",
            "Trigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁Entre ▁trans\t\t0.0957\n",
            "▁Entre ▁trans activiste\t\t-0.0598\n",
            "▁trans activiste s\t\t-0.1120\n",
            "activiste s ▁my\t\t-0.2717\n",
            "s ▁my ope\t\t-0.0907\n",
            "▁my ope s\t\t-0.0793\n",
            "ope s ▁qui\t\t-0.1092\n",
            "s ▁qui ▁s\t\t-0.1191\n",
            "▁qui ▁s '\t\t-0.1141\n",
            "▁s ' a\t\t-0.1869\n",
            "' a bonne\t\t-0.4084\n",
            "a bonne nt\t\t-0.6160\n",
            "bonne nt ▁puis\t\t-0.5378\n",
            "nt ▁puis ▁se\t\t-0.3966\n",
            "▁puis ▁se ▁des\t\t-0.1457\n",
            "▁se ▁des a\t\t-0.0788\n",
            "▁des a bonne\t\t-0.0152\n",
            "a bonne nt\t\t-0.0233\n",
            "bonne nt ▁et\t\t-0.0238\n",
            "nt ▁et ▁troll\t\t-0.0370\n",
            "▁et ▁troll s\t\t-0.0180\n",
            "▁troll s ▁soutien\t\t-0.0657\n",
            "s ▁soutien s\t\t-0.0563\n",
            "▁soutien s ▁e\t\t-0.0336\n",
            "s ▁e lev\t\t0.2427\n",
            "▁e lev eurs\t\t0.6529\n",
            "lev eurs ▁intensif\t\t0.7268\n",
            "eurs ▁intensif s\t\t0.5947\n",
            "▁intensif s ▁et\t\t0.4627\n",
            "s ▁et ▁l\t\t0.7231\n",
            "▁et ▁l '\t\t0.8392\n",
            "▁l ' agriculture\t\t0.8846\n",
            "' agriculture ▁\t\t0.4812\n",
            "agriculture ▁ product\t\t0.2274\n",
            "▁ product iv\t\t-0.2596\n",
            "product iv iste\t\t-0.5198\n",
            "iv iste ▁qui\t\t-0.5056\n",
            "iste ▁qui ▁comment\t\t-0.3582\n",
            "▁qui ▁comment ent\t\t-0.0773\n",
            "▁comment ent ▁a\t\t-0.0397\n",
            "ent ▁a ▁cote\t\t-0.0078\n",
            "▁a ▁cote ▁plaque\t\t0.0532\n",
            "▁cote ▁plaque ▁n\t\t0.0070\n",
            "▁plaque ▁n '\t\t-0.0103\n",
            "▁n ' en\t\t-0.0451\n",
            "' en ▁peux\t\t0.1385\n",
            "en ▁peux ▁plus\t\t0.1198\n",
            "▁peux ▁plus ▁Marc\t\t0.1356\n",
            "▁plus ▁Marc ▁Les\t\t-0.0169\n",
            "▁Marc ▁Les ggy\t\t0.0149\n",
            "▁Les ggy ▁leur\t\t0.0082\n",
            "ggy ▁leur ▁met\t\t0.0174\n",
            "▁leur ▁met ▁favoris\t\t0.0261\n",
            "▁met ▁favoris ▁en\t\t0.0061\n",
            "▁favoris ▁en ▁plus\t\t-0.0079\n",
            "▁en ▁plus ▁b\t\t-0.0426\n",
            "▁plus ▁b omb\t\t0.0363\n",
            "▁b omb </s>\t\t-0.1765\n",
            "\n",
            "Predicted Class: décroissance\n",
            "True Class: décroissance\n",
            "Predicted Probability: 3.0050876140594482\n",
            "Target Attribution Score: 0.1422043160075675\n",
            "\n",
            "==================================================\n",
            "\n",
            "Sentence: L'equipe du @journalaviation est ready et en route pour le @DubaiAirshow. Premier segment en 777-300ER de @qatarairways (A7-BET) https://t.co/gOL3MoMF9i\n",
            "Target Class: avion\n",
            "Token\t\tAttribution Score\n",
            "--------------------------\n",
            "<s>\t\t0.0000\n",
            "▁L\t\t0.0354\n",
            "'\t\t0.0042\n",
            "equipe\t\t0.0080\n",
            "▁journal\t\t0.0110\n",
            "aviation\t\t0.1118\n",
            "▁est\t\t0.0175\n",
            "▁\t\t-0.0700\n",
            "read\t\t-0.1086\n",
            "y\t\t0.0272\n",
            "▁et\t\t0.1878\n",
            "▁en\t\t0.2878\n",
            "▁route\t\t0.3473\n",
            "▁pour\t\t0.2562\n",
            "▁Dub\t\t0.1047\n",
            "ai\t\t0.1595\n",
            "Air\t\t0.2242\n",
            "show\t\t0.0965\n",
            "▁Premier\t\t0.0013\n",
            "▁segment\t\t0.0037\n",
            "▁en\t\t0.0390\n",
            "▁-\t\t0.0399\n",
            "ER\t\t0.0483\n",
            "▁q\t\t0.1440\n",
            "a\t\t0.2622\n",
            "tar\t\t0.2689\n",
            "air\t\t0.3464\n",
            "way\t\t0.3255\n",
            "s\t\t0.2895\n",
            "▁A\t\t0.0590\n",
            "-\t\t0.2265\n",
            "B\t\t0.1502\n",
            "ET\t\t0.1169\n",
            "</s>\t\t0.0026\n",
            "\n",
            "Bigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁L\t\t0.0354\n",
            "▁L '\t\t0.0396\n",
            "' equipe\t\t0.0122\n",
            "equipe ▁journal\t\t0.0190\n",
            "▁journal aviation\t\t0.1229\n",
            "aviation ▁est\t\t0.1293\n",
            "▁est ▁\t\t-0.0525\n",
            "▁ read\t\t-0.1786\n",
            "read y\t\t-0.0814\n",
            "y ▁et\t\t0.2149\n",
            "▁et ▁en\t\t0.4756\n",
            "▁en ▁route\t\t0.6350\n",
            "▁route ▁pour\t\t0.6034\n",
            "▁pour ▁Dub\t\t0.3608\n",
            "▁Dub ai\t\t0.2642\n",
            "ai Air\t\t0.3837\n",
            "Air show\t\t0.3207\n",
            "show ▁Premier\t\t0.0978\n",
            "▁Premier ▁segment\t\t0.0051\n",
            "▁segment ▁en\t\t0.0427\n",
            "▁en ▁-\t\t0.0789\n",
            "▁- ER\t\t0.0882\n",
            "ER ▁q\t\t0.1922\n",
            "▁q a\t\t0.4062\n",
            "a tar\t\t0.5312\n",
            "tar air\t\t0.6153\n",
            "air way\t\t0.6719\n",
            "way s\t\t0.6150\n",
            "s ▁A\t\t0.3485\n",
            "▁A -\t\t0.2854\n",
            "- B\t\t0.3767\n",
            "B ET\t\t0.2671\n",
            "ET </s>\t\t0.1195\n",
            "\n",
            "Trigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁L '\t\t0.0396\n",
            "▁L ' equipe\t\t0.0476\n",
            "' equipe ▁journal\t\t0.0233\n",
            "equipe ▁journal aviation\t\t0.1309\n",
            "▁journal aviation ▁est\t\t0.1403\n",
            "aviation ▁est ▁\t\t0.0593\n",
            "▁est ▁ read\t\t-0.1611\n",
            "▁ read y\t\t-0.1514\n",
            "read y ▁et\t\t0.1064\n",
            "y ▁et ▁en\t\t0.5027\n",
            "▁et ▁en ▁route\t\t0.8228\n",
            "▁en ▁route ▁pour\t\t0.8912\n",
            "▁route ▁pour ▁Dub\t\t0.7081\n",
            "▁pour ▁Dub ai\t\t0.5204\n",
            "▁Dub ai Air\t\t0.4884\n",
            "ai Air show\t\t0.4802\n",
            "Air show ▁Premier\t\t0.3220\n",
            "show ▁Premier ▁segment\t\t0.1015\n",
            "▁Premier ▁segment ▁en\t\t0.0441\n",
            "▁segment ▁en ▁-\t\t0.0827\n",
            "▁en ▁- ER\t\t0.1272\n",
            "▁- ER ▁q\t\t0.2322\n",
            "ER ▁q a\t\t0.4545\n",
            "▁q a tar\t\t0.6751\n",
            "a tar air\t\t0.8775\n",
            "tar air way\t\t0.9408\n",
            "air way s\t\t0.9614\n",
            "way s ▁A\t\t0.6740\n",
            "s ▁A -\t\t0.5750\n",
            "▁A - B\t\t0.4357\n",
            "- B ET\t\t0.4936\n",
            "B ET </s>\t\t0.2697\n",
            "\n",
            "Predicted Class: avion\n",
            "True Class: avion\n",
            "Predicted Probability: 3.9401962757110596\n",
            "Target Attribution Score: 4.024381380343744\n",
            "\n",
            "==================================================\n",
            "\n",
            "Target Class: décroissance\n",
            "Token\t\tAttribution Score\n",
            "--------------------------\n",
            "<s>\t\t0.0000\n",
            "▁L\t\t0.2211\n",
            "'\t\t0.2732\n",
            "equipe\t\t0.0068\n",
            "▁journal\t\t0.1700\n",
            "aviation\t\t-0.1426\n",
            "▁est\t\t-0.0223\n",
            "▁\t\t0.2297\n",
            "read\t\t0.2136\n",
            "y\t\t0.1444\n",
            "▁et\t\t0.0785\n",
            "▁en\t\t0.1103\n",
            "▁route\t\t-0.0368\n",
            "▁pour\t\t-0.0446\n",
            "▁Dub\t\t-0.0689\n",
            "ai\t\t-0.0741\n",
            "Air\t\t-0.1928\n",
            "show\t\t-0.0739\n",
            "▁Premier\t\t-0.0031\n",
            "▁segment\t\t-0.0284\n",
            "▁en\t\t0.0246\n",
            "▁-\t\t0.0095\n",
            "ER\t\t-0.0190\n",
            "▁q\t\t0.1850\n",
            "a\t\t-0.0038\n",
            "tar\t\t-0.2108\n",
            "air\t\t-0.3417\n",
            "way\t\t-0.3357\n",
            "s\t\t-0.0590\n",
            "▁A\t\t0.3493\n",
            "-\t\t0.3813\n",
            "B\t\t0.1159\n",
            "ET\t\t0.1684\n",
            "</s>\t\t-0.1015\n",
            "\n",
            "Bigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁L\t\t0.2211\n",
            "▁L '\t\t0.4943\n",
            "' equipe\t\t0.2800\n",
            "equipe ▁journal\t\t0.1768\n",
            "▁journal aviation\t\t0.0274\n",
            "aviation ▁est\t\t-0.1648\n",
            "▁est ▁\t\t0.2074\n",
            "▁ read\t\t0.4433\n",
            "read y\t\t0.3580\n",
            "y ▁et\t\t0.2229\n",
            "▁et ▁en\t\t0.1888\n",
            "▁en ▁route\t\t0.0736\n",
            "▁route ▁pour\t\t-0.0814\n",
            "▁pour ▁Dub\t\t-0.1135\n",
            "▁Dub ai\t\t-0.1430\n",
            "ai Air\t\t-0.2669\n",
            "Air show\t\t-0.2666\n",
            "show ▁Premier\t\t-0.0769\n",
            "▁Premier ▁segment\t\t-0.0314\n",
            "▁segment ▁en\t\t-0.0037\n",
            "▁en ▁-\t\t0.0341\n",
            "▁- ER\t\t-0.0095\n",
            "ER ▁q\t\t0.1660\n",
            "▁q a\t\t0.1812\n",
            "a tar\t\t-0.2147\n",
            "tar air\t\t-0.5525\n",
            "air way\t\t-0.6774\n",
            "way s\t\t-0.3947\n",
            "s ▁A\t\t0.2903\n",
            "▁A -\t\t0.7306\n",
            "- B\t\t0.4971\n",
            "B ET\t\t0.2843\n",
            "ET </s>\t\t0.0669\n",
            "\n",
            "Trigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁L '\t\t0.4943\n",
            "▁L ' equipe\t\t0.5011\n",
            "' equipe ▁journal\t\t0.4500\n",
            "equipe ▁journal aviation\t\t0.0342\n",
            "▁journal aviation ▁est\t\t0.0052\n",
            "aviation ▁est ▁\t\t0.0648\n",
            "▁est ▁ read\t\t0.4210\n",
            "▁ read y\t\t0.5876\n",
            "read y ▁et\t\t0.4365\n",
            "y ▁et ▁en\t\t0.3332\n",
            "▁et ▁en ▁route\t\t0.1521\n",
            "▁en ▁route ▁pour\t\t0.0289\n",
            "▁route ▁pour ▁Dub\t\t-0.1503\n",
            "▁pour ▁Dub ai\t\t-0.1876\n",
            "▁Dub ai Air\t\t-0.3358\n",
            "ai Air show\t\t-0.3407\n",
            "Air show ▁Premier\t\t-0.2697\n",
            "show ▁Premier ▁segment\t\t-0.1053\n",
            "▁Premier ▁segment ▁en\t\t-0.0068\n",
            "▁segment ▁en ▁-\t\t0.0057\n",
            "▁en ▁- ER\t\t0.0151\n",
            "▁- ER ▁q\t\t0.1755\n",
            "ER ▁q a\t\t0.1622\n",
            "▁q a tar\t\t-0.0296\n",
            "a tar air\t\t-0.5564\n",
            "tar air way\t\t-0.8882\n",
            "air way s\t\t-0.7364\n",
            "way s ▁A\t\t-0.0454\n",
            "s ▁A -\t\t0.6716\n",
            "▁A - B\t\t0.8465\n",
            "- B ET\t\t0.6656\n",
            "B ET </s>\t\t0.1828\n",
            "\n",
            "Predicted Class: avion\n",
            "True Class: avion\n",
            "Predicted Probability: 3.9401962757110596\n",
            "Target Attribution Score: 0.9227405527345709\n",
            "\n",
            "==================================================\n",
            "\n",
            "Target Class: nucléaire\n",
            "Token\t\tAttribution Score\n",
            "--------------------------\n",
            "<s>\t\t0.0000\n",
            "▁L\t\t-0.3205\n",
            "'\t\t-0.3371\n",
            "equipe\t\t-0.0090\n",
            "▁journal\t\t-0.0334\n",
            "aviation\t\t-0.0540\n",
            "▁est\t\t-0.1073\n",
            "▁\t\t-0.1661\n",
            "read\t\t-0.1931\n",
            "y\t\t-0.1990\n",
            "▁et\t\t-0.2957\n",
            "▁en\t\t-0.3223\n",
            "▁route\t\t-0.5794\n",
            "▁pour\t\t-0.2379\n",
            "▁Dub\t\t-0.0628\n",
            "ai\t\t-0.0330\n",
            "Air\t\t-0.0478\n",
            "show\t\t-0.0500\n",
            "▁Premier\t\t0.0040\n",
            "▁segment\t\t-0.0486\n",
            "▁en\t\t-0.0244\n",
            "▁-\t\t0.0072\n",
            "ER\t\t0.0012\n",
            "▁q\t\t-0.0533\n",
            "a\t\t0.0899\n",
            "tar\t\t-0.0456\n",
            "air\t\t-0.0690\n",
            "way\t\t-0.0544\n",
            "s\t\t-0.0605\n",
            "▁A\t\t-0.0824\n",
            "-\t\t-0.1246\n",
            "B\t\t-0.1015\n",
            "ET\t\t-0.0681\n",
            "</s>\t\t0.0732\n",
            "\n",
            "Bigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁L\t\t-0.3205\n",
            "▁L '\t\t-0.6577\n",
            "' equipe\t\t-0.3462\n",
            "equipe ▁journal\t\t-0.0424\n",
            "▁journal aviation\t\t-0.0874\n",
            "aviation ▁est\t\t-0.1614\n",
            "▁est ▁\t\t-0.2734\n",
            "▁ read\t\t-0.3592\n",
            "read y\t\t-0.3921\n",
            "y ▁et\t\t-0.4947\n",
            "▁et ▁en\t\t-0.6180\n",
            "▁en ▁route\t\t-0.9018\n",
            "▁route ▁pour\t\t-0.8174\n",
            "▁pour ▁Dub\t\t-0.3007\n",
            "▁Dub ai\t\t-0.0958\n",
            "ai Air\t\t-0.0808\n",
            "Air show\t\t-0.0978\n",
            "show ▁Premier\t\t-0.0460\n",
            "▁Premier ▁segment\t\t-0.0446\n",
            "▁segment ▁en\t\t-0.0730\n",
            "▁en ▁-\t\t-0.0172\n",
            "▁- ER\t\t0.0085\n",
            "ER ▁q\t\t-0.0521\n",
            "▁q a\t\t0.0366\n",
            "a tar\t\t0.0443\n",
            "tar air\t\t-0.1146\n",
            "air way\t\t-0.1235\n",
            "way s\t\t-0.1149\n",
            "s ▁A\t\t-0.1428\n",
            "▁A -\t\t-0.2070\n",
            "- B\t\t-0.2261\n",
            "B ET\t\t-0.1696\n",
            "ET </s>\t\t0.0051\n",
            "\n",
            "Trigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁L '\t\t-0.6577\n",
            "▁L ' equipe\t\t-0.6667\n",
            "' equipe ▁journal\t\t-0.3795\n",
            "equipe ▁journal aviation\t\t-0.0964\n",
            "▁journal aviation ▁est\t\t-0.1947\n",
            "aviation ▁est ▁\t\t-0.3275\n",
            "▁est ▁ read\t\t-0.4665\n",
            "▁ read y\t\t-0.5582\n",
            "read y ▁et\t\t-0.6877\n",
            "y ▁et ▁en\t\t-0.8170\n",
            "▁et ▁en ▁route\t\t-1.1974\n",
            "▁en ▁route ▁pour\t\t-1.1397\n",
            "▁route ▁pour ▁Dub\t\t-0.8802\n",
            "▁pour ▁Dub ai\t\t-0.3337\n",
            "▁Dub ai Air\t\t-0.1436\n",
            "ai Air show\t\t-0.1308\n",
            "Air show ▁Premier\t\t-0.0938\n",
            "show ▁Premier ▁segment\t\t-0.0946\n",
            "▁Premier ▁segment ▁en\t\t-0.0690\n",
            "▁segment ▁en ▁-\t\t-0.0658\n",
            "▁en ▁- ER\t\t-0.0159\n",
            "▁- ER ▁q\t\t-0.0448\n",
            "ER ▁q a\t\t0.0378\n",
            "▁q a tar\t\t-0.0090\n",
            "a tar air\t\t-0.0247\n",
            "tar air way\t\t-0.1691\n",
            "air way s\t\t-0.1839\n",
            "way s ▁A\t\t-0.1973\n",
            "s ▁A -\t\t-0.2675\n",
            "▁A - B\t\t-0.3085\n",
            "- B ET\t\t-0.2942\n",
            "B ET </s>\t\t-0.0964\n",
            "\n",
            "Predicted Class: avion\n",
            "True Class: avion\n",
            "Predicted Probability: 3.9401962757110596\n",
            "Target Attribution Score: -3.605409515207949\n",
            "\n",
            "==================================================\n",
            "\n",
            "Target Class: viande\n",
            "Token\t\tAttribution Score\n",
            "--------------------------\n",
            "<s>\t\t0.0000\n",
            "▁L\t\t0.1734\n",
            "'\t\t0.0566\n",
            "equipe\t\t0.1899\n",
            "▁journal\t\t-0.0103\n",
            "aviation\t\t0.0122\n",
            "▁est\t\t0.1122\n",
            "▁\t\t0.1496\n",
            "read\t\t0.1481\n",
            "y\t\t0.1182\n",
            "▁et\t\t-0.2322\n",
            "▁en\t\t-0.4000\n",
            "▁route\t\t-0.6105\n",
            "▁pour\t\t-0.2630\n",
            "▁Dub\t\t-0.0368\n",
            "ai\t\t-0.0345\n",
            "Air\t\t-0.0599\n",
            "show\t\t-0.0031\n",
            "▁Premier\t\t0.0389\n",
            "▁segment\t\t0.0717\n",
            "▁en\t\t0.0053\n",
            "▁-\t\t0.0342\n",
            "ER\t\t0.0126\n",
            "▁q\t\t-0.1573\n",
            "a\t\t-0.2082\n",
            "tar\t\t-0.1922\n",
            "air\t\t-0.0974\n",
            "way\t\t-0.1031\n",
            "s\t\t-0.1138\n",
            "▁A\t\t-0.0204\n",
            "-\t\t-0.1889\n",
            "B\t\t-0.0033\n",
            "ET\t\t-0.0526\n",
            "</s>\t\t-0.1129\n",
            "\n",
            "Bigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁L\t\t0.1734\n",
            "▁L '\t\t0.2300\n",
            "' equipe\t\t0.2465\n",
            "equipe ▁journal\t\t0.1796\n",
            "▁journal aviation\t\t0.0020\n",
            "aviation ▁est\t\t0.1244\n",
            "▁est ▁\t\t0.2618\n",
            "▁ read\t\t0.2977\n",
            "read y\t\t0.2663\n",
            "y ▁et\t\t-0.1140\n",
            "▁et ▁en\t\t-0.6322\n",
            "▁en ▁route\t\t-1.0104\n",
            "▁route ▁pour\t\t-0.8734\n",
            "▁pour ▁Dub\t\t-0.2998\n",
            "▁Dub ai\t\t-0.0713\n",
            "ai Air\t\t-0.0943\n",
            "Air show\t\t-0.0630\n",
            "show ▁Premier\t\t0.0358\n",
            "▁Premier ▁segment\t\t0.1106\n",
            "▁segment ▁en\t\t0.0770\n",
            "▁en ▁-\t\t0.0395\n",
            "▁- ER\t\t0.0468\n",
            "ER ▁q\t\t-0.1447\n",
            "▁q a\t\t-0.3655\n",
            "a tar\t\t-0.4003\n",
            "tar air\t\t-0.2896\n",
            "air way\t\t-0.2005\n",
            "way s\t\t-0.2169\n",
            "s ▁A\t\t-0.1342\n",
            "▁A -\t\t-0.2093\n",
            "- B\t\t-0.1922\n",
            "B ET\t\t-0.0560\n",
            "ET </s>\t\t-0.1655\n",
            "\n",
            "Trigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁L '\t\t0.2300\n",
            "▁L ' equipe\t\t0.4199\n",
            "' equipe ▁journal\t\t0.2362\n",
            "equipe ▁journal aviation\t\t0.1918\n",
            "▁journal aviation ▁est\t\t0.1142\n",
            "aviation ▁est ▁\t\t0.2740\n",
            "▁est ▁ read\t\t0.4099\n",
            "▁ read y\t\t0.4158\n",
            "read y ▁et\t\t0.0341\n",
            "y ▁et ▁en\t\t-0.5140\n",
            "▁et ▁en ▁route\t\t-1.2426\n",
            "▁en ▁route ▁pour\t\t-1.2734\n",
            "▁route ▁pour ▁Dub\t\t-0.9103\n",
            "▁pour ▁Dub ai\t\t-0.3343\n",
            "▁Dub ai Air\t\t-0.1311\n",
            "ai Air show\t\t-0.0974\n",
            "Air show ▁Premier\t\t-0.0241\n",
            "show ▁Premier ▁segment\t\t0.1075\n",
            "▁Premier ▁segment ▁en\t\t0.1159\n",
            "▁segment ▁en ▁-\t\t0.1112\n",
            "▁en ▁- ER\t\t0.0521\n",
            "▁- ER ▁q\t\t-0.1105\n",
            "ER ▁q a\t\t-0.3528\n",
            "▁q a tar\t\t-0.5576\n",
            "a tar air\t\t-0.4977\n",
            "tar air way\t\t-0.3927\n",
            "air way s\t\t-0.3143\n",
            "way s ▁A\t\t-0.2373\n",
            "s ▁A -\t\t-0.3231\n",
            "▁A - B\t\t-0.2126\n",
            "- B ET\t\t-0.2448\n",
            "B ET </s>\t\t-0.1689\n",
            "\n",
            "Predicted Class: avion\n",
            "True Class: avion\n",
            "Predicted Probability: 3.9401962757110596\n",
            "Target Attribution Score: -1.777517310741309\n",
            "\n",
            "==================================================\n",
            "\n",
            "Sentence: RT @RMCStory: 1 poulet sur 2 consommé en France est importé : scandaleux ?\n",
            "\n",
            "🗣\"Je trouve ça scandaleux, mais s’est aussi aux consommateurs d…\n",
            "Target Class: avion\n",
            "Token\t\tAttribution Score\n",
            "--------------------------\n",
            "<s>\t\t0.0000\n",
            "▁RT\t\t0.0552\n",
            "▁R\t\t-0.0196\n",
            "MC\t\t0.0063\n",
            "St\t\t-0.0627\n",
            "ory\t\t0.0176\n",
            "▁poulet\t\t-0.0237\n",
            "▁sur\t\t0.0459\n",
            "▁consomme\t\t0.0108\n",
            "▁en\t\t-0.0269\n",
            "▁France\t\t-0.0175\n",
            "▁est\t\t0.0393\n",
            "▁importe\t\t-0.0048\n",
            "▁scandale\t\t0.0481\n",
            "ux\t\t0.0385\n",
            "▁s\t\t0.0079\n",
            "peak\t\t-0.0005\n",
            "ing\t\t-0.0048\n",
            "_\t\t-0.0218\n",
            "head\t\t0.0307\n",
            "Je\t\t-0.0311\n",
            "▁trouve\t\t-0.0244\n",
            "▁ca\t\t0.0023\n",
            "▁scandale\t\t0.0555\n",
            "ux\t\t0.9391\n",
            "▁mais\t\t0.1039\n",
            "▁s\t\t0.0451\n",
            "est\t\t0.0407\n",
            "▁aussi\t\t0.0290\n",
            "▁aux\t\t-0.0043\n",
            "▁consommateurs\t\t-0.0130\n",
            "▁d\t\t-0.1226\n",
            "</s>\t\t0.2541\n",
            "\n",
            "Bigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁RT\t\t0.0552\n",
            "▁RT ▁R\t\t0.0355\n",
            "▁R MC\t\t-0.0134\n",
            "MC St\t\t-0.0564\n",
            "St ory\t\t-0.0451\n",
            "ory ▁poulet\t\t-0.0061\n",
            "▁poulet ▁sur\t\t0.0221\n",
            "▁sur ▁consomme\t\t0.0566\n",
            "▁consomme ▁en\t\t-0.0162\n",
            "▁en ▁France\t\t-0.0445\n",
            "▁France ▁est\t\t0.0218\n",
            "▁est ▁importe\t\t0.0345\n",
            "▁importe ▁scandale\t\t0.0432\n",
            "▁scandale ux\t\t0.0865\n",
            "ux ▁s\t\t0.0464\n",
            "▁s peak\t\t0.0074\n",
            "peak ing\t\t-0.0053\n",
            "ing _\t\t-0.0266\n",
            "_ head\t\t0.0089\n",
            "head Je\t\t-0.0004\n",
            "Je ▁trouve\t\t-0.0554\n",
            "▁trouve ▁ca\t\t-0.0221\n",
            "▁ca ▁scandale\t\t0.0578\n",
            "▁scandale ux\t\t0.9946\n",
            "ux ▁mais\t\t1.0430\n",
            "▁mais ▁s\t\t0.1490\n",
            "▁s est\t\t0.0858\n",
            "est ▁aussi\t\t0.0697\n",
            "▁aussi ▁aux\t\t0.0246\n",
            "▁aux ▁consommateurs\t\t-0.0173\n",
            "▁consommateurs ▁d\t\t-0.1356\n",
            "▁d </s>\t\t0.1316\n",
            "\n",
            "Trigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁RT ▁R\t\t0.0355\n",
            "▁RT ▁R MC\t\t0.0418\n",
            "▁R MC St\t\t-0.0760\n",
            "MC St ory\t\t-0.0388\n",
            "St ory ▁poulet\t\t-0.0688\n",
            "ory ▁poulet ▁sur\t\t0.0397\n",
            "▁poulet ▁sur ▁consomme\t\t0.0329\n",
            "▁sur ▁consomme ▁en\t\t0.0297\n",
            "▁consomme ▁en ▁France\t\t-0.0337\n",
            "▁en ▁France ▁est\t\t-0.0051\n",
            "▁France ▁est ▁importe\t\t0.0170\n",
            "▁est ▁importe ▁scandale\t\t0.0826\n",
            "▁importe ▁scandale ux\t\t0.0817\n",
            "▁scandale ux ▁s\t\t0.0944\n",
            "ux ▁s peak\t\t0.0458\n",
            "▁s peak ing\t\t0.0026\n",
            "peak ing _\t\t-0.0271\n",
            "ing _ head\t\t0.0041\n",
            "_ head Je\t\t-0.0221\n",
            "head Je ▁trouve\t\t-0.0247\n",
            "Je ▁trouve ▁ca\t\t-0.0532\n",
            "▁trouve ▁ca ▁scandale\t\t0.0335\n",
            "▁ca ▁scandale ux\t\t0.9969\n",
            "▁scandale ux ▁mais\t\t1.0985\n",
            "ux ▁mais ▁s\t\t1.0881\n",
            "▁mais ▁s est\t\t0.1898\n",
            "▁s est ▁aussi\t\t0.1148\n",
            "est ▁aussi ▁aux\t\t0.0654\n",
            "▁aussi ▁aux ▁consommateurs\t\t0.0117\n",
            "▁aux ▁consommateurs ▁d\t\t-0.1399\n",
            "▁consommateurs ▁d </s>\t\t0.1186\n",
            "\n",
            "Predicted Class: viande\n",
            "True Class: viande\n",
            "Predicted Probability: 4.289041996002197\n",
            "Target Attribution Score: 1.392152097688521\n",
            "\n",
            "==================================================\n",
            "\n",
            "Target Class: décroissance\n",
            "Token\t\tAttribution Score\n",
            "--------------------------\n",
            "<s>\t\t0.0000\n",
            "▁RT\t\t0.0109\n",
            "▁R\t\t0.0297\n",
            "MC\t\t0.0505\n",
            "St\t\t-0.0263\n",
            "ory\t\t0.0765\n",
            "▁poulet\t\t-0.5956\n",
            "▁sur\t\t-0.6632\n",
            "▁consomme\t\t0.0741\n",
            "▁en\t\t-0.0237\n",
            "▁France\t\t-0.0441\n",
            "▁est\t\t-0.0637\n",
            "▁importe\t\t-0.0580\n",
            "▁scandale\t\t-0.0012\n",
            "ux\t\t0.0343\n",
            "▁s\t\t0.0255\n",
            "peak\t\t0.0167\n",
            "ing\t\t0.0262\n",
            "_\t\t0.0391\n",
            "head\t\t0.0402\n",
            "Je\t\t-0.0627\n",
            "▁trouve\t\t-0.0825\n",
            "▁ca\t\t-0.0542\n",
            "▁scandale\t\t0.0619\n",
            "ux\t\t0.0825\n",
            "▁mais\t\t0.1271\n",
            "▁s\t\t0.1119\n",
            "est\t\t0.0960\n",
            "▁aussi\t\t0.1610\n",
            "▁aux\t\t0.2194\n",
            "▁consommateurs\t\t0.1892\n",
            "▁d\t\t0.0429\n",
            "</s>\t\t0.0110\n",
            "\n",
            "Bigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁RT\t\t0.0109\n",
            "▁RT ▁R\t\t0.0406\n",
            "▁R MC\t\t0.0802\n",
            "MC St\t\t0.0242\n",
            "St ory\t\t0.0502\n",
            "ory ▁poulet\t\t-0.5191\n",
            "▁poulet ▁sur\t\t-1.2588\n",
            "▁sur ▁consomme\t\t-0.5891\n",
            "▁consomme ▁en\t\t0.0504\n",
            "▁en ▁France\t\t-0.0678\n",
            "▁France ▁est\t\t-0.1078\n",
            "▁est ▁importe\t\t-0.1217\n",
            "▁importe ▁scandale\t\t-0.0592\n",
            "▁scandale ux\t\t0.0331\n",
            "ux ▁s\t\t0.0598\n",
            "▁s peak\t\t0.0422\n",
            "peak ing\t\t0.0429\n",
            "ing _\t\t0.0652\n",
            "_ head\t\t0.0793\n",
            "head Je\t\t-0.0225\n",
            "Je ▁trouve\t\t-0.1452\n",
            "▁trouve ▁ca\t\t-0.1366\n",
            "▁ca ▁scandale\t\t0.0077\n",
            "▁scandale ux\t\t0.1444\n",
            "ux ▁mais\t\t0.2095\n",
            "▁mais ▁s\t\t0.2389\n",
            "▁s est\t\t0.2079\n",
            "est ▁aussi\t\t0.2569\n",
            "▁aussi ▁aux\t\t0.3804\n",
            "▁aux ▁consommateurs\t\t0.4086\n",
            "▁consommateurs ▁d\t\t0.2321\n",
            "▁d </s>\t\t0.0540\n",
            "\n",
            "Trigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁RT ▁R\t\t0.0406\n",
            "▁RT ▁R MC\t\t0.0911\n",
            "▁R MC St\t\t0.0539\n",
            "MC St ory\t\t0.1007\n",
            "St ory ▁poulet\t\t-0.5454\n",
            "ory ▁poulet ▁sur\t\t-1.1823\n",
            "▁poulet ▁sur ▁consomme\t\t-1.1847\n",
            "▁sur ▁consomme ▁en\t\t-0.6128\n",
            "▁consomme ▁en ▁France\t\t0.0062\n",
            "▁en ▁France ▁est\t\t-0.1315\n",
            "▁France ▁est ▁importe\t\t-0.1658\n",
            "▁est ▁importe ▁scandale\t\t-0.1229\n",
            "▁importe ▁scandale ux\t\t-0.0249\n",
            "▁scandale ux ▁s\t\t0.0586\n",
            "ux ▁s peak\t\t0.0765\n",
            "▁s peak ing\t\t0.0684\n",
            "peak ing _\t\t0.0819\n",
            "ing _ head\t\t0.1055\n",
            "_ head Je\t\t0.0166\n",
            "head Je ▁trouve\t\t-0.1050\n",
            "Je ▁trouve ▁ca\t\t-0.1994\n",
            "▁trouve ▁ca ▁scandale\t\t-0.0747\n",
            "▁ca ▁scandale ux\t\t0.0902\n",
            "▁scandale ux ▁mais\t\t0.2714\n",
            "ux ▁mais ▁s\t\t0.3214\n",
            "▁mais ▁s est\t\t0.3349\n",
            "▁s est ▁aussi\t\t0.3688\n",
            "est ▁aussi ▁aux\t\t0.4764\n",
            "▁aussi ▁aux ▁consommateurs\t\t0.5696\n",
            "▁aux ▁consommateurs ▁d\t\t0.4515\n",
            "▁consommateurs ▁d </s>\t\t0.2431\n",
            "\n",
            "Predicted Class: viande\n",
            "True Class: viande\n",
            "Predicted Probability: 4.289041996002197\n",
            "Target Attribution Score: -0.14872396239504612\n",
            "\n",
            "==================================================\n",
            "\n",
            "Target Class: nucléaire\n",
            "Token\t\tAttribution Score\n",
            "--------------------------\n",
            "<s>\t\t0.0000\n",
            "▁RT\t\t-0.2589\n",
            "▁R\t\t-0.1468\n",
            "MC\t\t-0.1317\n",
            "St\t\t-0.1141\n",
            "ory\t\t-0.0064\n",
            "▁poulet\t\t0.0154\n",
            "▁sur\t\t0.4093\n",
            "▁consomme\t\t-0.0385\n",
            "▁en\t\t-0.0235\n",
            "▁France\t\t-0.0379\n",
            "▁est\t\t-0.1342\n",
            "▁importe\t\t-0.0483\n",
            "▁scandale\t\t-0.0459\n",
            "ux\t\t-0.7179\n",
            "▁s\t\t-0.0243\n",
            "peak\t\t-0.0194\n",
            "ing\t\t0.0053\n",
            "_\t\t0.0446\n",
            "head\t\t-0.0200\n",
            "Je\t\t0.0019\n",
            "▁trouve\t\t-0.0012\n",
            "▁ca\t\t0.0238\n",
            "▁scandale\t\t-0.0435\n",
            "ux\t\t0.1421\n",
            "▁mais\t\t-0.0428\n",
            "▁s\t\t-0.0934\n",
            "est\t\t-0.0715\n",
            "▁aussi\t\t-0.0268\n",
            "▁aux\t\t-0.0367\n",
            "▁consommateurs\t\t0.2073\n",
            "▁d\t\t0.0934\n",
            "</s>\t\t0.2765\n",
            "\n",
            "Bigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁RT\t\t-0.2589\n",
            "▁RT ▁R\t\t-0.4057\n",
            "▁R MC\t\t-0.2786\n",
            "MC St\t\t-0.2458\n",
            "St ory\t\t-0.1204\n",
            "ory ▁poulet\t\t0.0090\n",
            "▁poulet ▁sur\t\t0.4247\n",
            "▁sur ▁consomme\t\t0.3709\n",
            "▁consomme ▁en\t\t-0.0620\n",
            "▁en ▁France\t\t-0.0615\n",
            "▁France ▁est\t\t-0.1721\n",
            "▁est ▁importe\t\t-0.1824\n",
            "▁importe ▁scandale\t\t-0.0942\n",
            "▁scandale ux\t\t-0.7638\n",
            "ux ▁s\t\t-0.7422\n",
            "▁s peak\t\t-0.0436\n",
            "peak ing\t\t-0.0141\n",
            "ing _\t\t0.0499\n",
            "_ head\t\t0.0246\n",
            "head Je\t\t-0.0181\n",
            "Je ▁trouve\t\t0.0006\n",
            "▁trouve ▁ca\t\t0.0226\n",
            "▁ca ▁scandale\t\t-0.0196\n",
            "▁scandale ux\t\t0.0987\n",
            "ux ▁mais\t\t0.0993\n",
            "▁mais ▁s\t\t-0.1363\n",
            "▁s est\t\t-0.1650\n",
            "est ▁aussi\t\t-0.0984\n",
            "▁aussi ▁aux\t\t-0.0635\n",
            "▁aux ▁consommateurs\t\t0.1706\n",
            "▁consommateurs ▁d\t\t0.3006\n",
            "▁d </s>\t\t0.3699\n",
            "\n",
            "Trigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁RT ▁R\t\t-0.4057\n",
            "▁RT ▁R MC\t\t-0.5375\n",
            "▁R MC St\t\t-0.3926\n",
            "MC St ory\t\t-0.2522\n",
            "St ory ▁poulet\t\t-0.1050\n",
            "ory ▁poulet ▁sur\t\t0.4184\n",
            "▁poulet ▁sur ▁consomme\t\t0.3863\n",
            "▁sur ▁consomme ▁en\t\t0.3473\n",
            "▁consomme ▁en ▁France\t\t-0.0999\n",
            "▁en ▁France ▁est\t\t-0.1956\n",
            "▁France ▁est ▁importe\t\t-0.2204\n",
            "▁est ▁importe ▁scandale\t\t-0.2284\n",
            "▁importe ▁scandale ux\t\t-0.8121\n",
            "▁scandale ux ▁s\t\t-0.7881\n",
            "ux ▁s peak\t\t-0.7615\n",
            "▁s peak ing\t\t-0.0383\n",
            "peak ing _\t\t0.0305\n",
            "ing _ head\t\t0.0299\n",
            "_ head Je\t\t0.0265\n",
            "head Je ▁trouve\t\t-0.0193\n",
            "Je ▁trouve ▁ca\t\t0.0245\n",
            "▁trouve ▁ca ▁scandale\t\t-0.0208\n",
            "▁ca ▁scandale ux\t\t0.1225\n",
            "▁scandale ux ▁mais\t\t0.0558\n",
            "ux ▁mais ▁s\t\t0.0059\n",
            "▁mais ▁s est\t\t-0.2078\n",
            "▁s est ▁aussi\t\t-0.1918\n",
            "est ▁aussi ▁aux\t\t-0.1351\n",
            "▁aussi ▁aux ▁consommateurs\t\t0.1437\n",
            "▁aux ▁consommateurs ▁d\t\t0.2639\n",
            "▁consommateurs ▁d </s>\t\t0.5771\n",
            "\n",
            "Predicted Class: viande\n",
            "True Class: viande\n",
            "Predicted Probability: 4.289041996002197\n",
            "Target Attribution Score: -0.8641175405559003\n",
            "\n",
            "==================================================\n",
            "\n",
            "Target Class: viande\n",
            "Token\t\tAttribution Score\n",
            "--------------------------\n",
            "<s>\t\t0.0000\n",
            "▁RT\t\t0.0808\n",
            "▁R\t\t0.0250\n",
            "MC\t\t-0.0413\n",
            "St\t\t0.0746\n",
            "ory\t\t-0.0482\n",
            "▁poulet\t\t0.5637\n",
            "▁sur\t\t0.7294\n",
            "▁consomme\t\t-0.0954\n",
            "▁en\t\t0.0331\n",
            "▁France\t\t0.0499\n",
            "▁est\t\t0.0827\n",
            "▁importe\t\t0.0700\n",
            "▁scandale\t\t0.0220\n",
            "ux\t\t-0.0477\n",
            "▁s\t\t-0.0002\n",
            "peak\t\t0.0131\n",
            "ing\t\t-0.0040\n",
            "_\t\t-0.0148\n",
            "head\t\t-0.0337\n",
            "Je\t\t0.0811\n",
            "▁trouve\t\t0.0921\n",
            "▁ca\t\t0.0989\n",
            "▁scandale\t\t-0.0392\n",
            "ux\t\t-0.2064\n",
            "▁mais\t\t-0.0519\n",
            "▁s\t\t-0.0203\n",
            "est\t\t-0.0311\n",
            "▁aussi\t\t-0.0278\n",
            "▁aux\t\t-0.0828\n",
            "▁consommateurs\t\t-0.1162\n",
            "▁d\t\t0.0071\n",
            "</s>\t\t-0.1028\n",
            "\n",
            "Bigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁RT\t\t0.0808\n",
            "▁RT ▁R\t\t0.1057\n",
            "▁R MC\t\t-0.0163\n",
            "MC St\t\t0.0334\n",
            "St ory\t\t0.0264\n",
            "ory ▁poulet\t\t0.5155\n",
            "▁poulet ▁sur\t\t1.2931\n",
            "▁sur ▁consomme\t\t0.6340\n",
            "▁consomme ▁en\t\t-0.0623\n",
            "▁en ▁France\t\t0.0830\n",
            "▁France ▁est\t\t0.1326\n",
            "▁est ▁importe\t\t0.1527\n",
            "▁importe ▁scandale\t\t0.0920\n",
            "▁scandale ux\t\t-0.0258\n",
            "ux ▁s\t\t-0.0480\n",
            "▁s peak\t\t0.0129\n",
            "peak ing\t\t0.0091\n",
            "ing _\t\t-0.0188\n",
            "_ head\t\t-0.0484\n",
            "head Je\t\t0.0474\n",
            "Je ▁trouve\t\t0.1733\n",
            "▁trouve ▁ca\t\t0.1910\n",
            "▁ca ▁scandale\t\t0.0597\n",
            "▁scandale ux\t\t-0.2456\n",
            "ux ▁mais\t\t-0.2583\n",
            "▁mais ▁s\t\t-0.0722\n",
            "▁s est\t\t-0.0514\n",
            "est ▁aussi\t\t-0.0588\n",
            "▁aussi ▁aux\t\t-0.1106\n",
            "▁aux ▁consommateurs\t\t-0.1990\n",
            "▁consommateurs ▁d\t\t-0.1091\n",
            "▁d </s>\t\t-0.0957\n",
            "\n",
            "Trigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁RT ▁R\t\t0.1057\n",
            "▁RT ▁R MC\t\t0.0644\n",
            "▁R MC St\t\t0.0583\n",
            "MC St ory\t\t-0.0149\n",
            "St ory ▁poulet\t\t0.5901\n",
            "ory ▁poulet ▁sur\t\t1.2448\n",
            "▁poulet ▁sur ▁consomme\t\t1.1977\n",
            "▁sur ▁consomme ▁en\t\t0.6670\n",
            "▁consomme ▁en ▁France\t\t-0.0124\n",
            "▁en ▁France ▁est\t\t0.1657\n",
            "▁France ▁est ▁importe\t\t0.2026\n",
            "▁est ▁importe ▁scandale\t\t0.1747\n",
            "▁importe ▁scandale ux\t\t0.0443\n",
            "▁scandale ux ▁s\t\t-0.0260\n",
            "ux ▁s peak\t\t-0.0348\n",
            "▁s peak ing\t\t0.0089\n",
            "peak ing _\t\t-0.0057\n",
            "ing _ head\t\t-0.0524\n",
            "_ head Je\t\t0.0327\n",
            "head Je ▁trouve\t\t0.1396\n",
            "Je ▁trouve ▁ca\t\t0.2721\n",
            "▁trouve ▁ca ▁scandale\t\t0.1519\n",
            "▁ca ▁scandale ux\t\t-0.1467\n",
            "▁scandale ux ▁mais\t\t-0.2974\n",
            "ux ▁mais ▁s\t\t-0.2786\n",
            "▁mais ▁s est\t\t-0.1032\n",
            "▁s est ▁aussi\t\t-0.0791\n",
            "est ▁aussi ▁aux\t\t-0.1416\n",
            "▁aussi ▁aux ▁consommateurs\t\t-0.2268\n",
            "▁aux ▁consommateurs ▁d\t\t-0.1919\n",
            "▁consommateurs ▁d </s>\t\t-0.2119\n",
            "\n",
            "Predicted Class: viande\n",
            "True Class: viande\n",
            "Predicted Probability: 4.289041996002197\n",
            "Target Attribution Score: 1.0598006399552191\n",
            "\n",
            "==================================================\n",
            "\n",
            "Sentence: @HeleneThouy @PartiAnimaliste @TF1 Terrine et Pâté 🤷‍♂️\n",
            "Target Class: avion\n",
            "Token\t\tAttribution Score\n",
            "--------------------------\n",
            "<s>\t\t0.0000\n",
            "▁Hel\t\t0.0274\n",
            "en\t\t-0.0339\n",
            "e\t\t-0.0094\n",
            "T\t\t0.0089\n",
            "hou\t\t-0.0141\n",
            "y\t\t0.0118\n",
            "▁Parti\t\t0.0542\n",
            "Anim\t\t0.0183\n",
            "aliste\t\t0.0229\n",
            "▁TF\t\t0.0276\n",
            "▁Terr\t\t0.0459\n",
            "ine\t\t0.0567\n",
            "▁et\t\t0.1014\n",
            "▁Pat\t\t0.0647\n",
            "e\t\t-0.0271\n",
            "▁man\t\t0.0359\n",
            "_\t\t0.0142\n",
            "sh\t\t0.0139\n",
            "ru\t\t-0.1580\n",
            "gging\t\t-0.8000\n",
            "</s>\t\t-0.5530\n",
            "\n",
            "Bigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁Hel\t\t0.0274\n",
            "▁Hel en\t\t-0.0065\n",
            "en e\t\t-0.0433\n",
            "e T\t\t-0.0005\n",
            "T hou\t\t-0.0052\n",
            "hou y\t\t-0.0023\n",
            "y ▁Parti\t\t0.0660\n",
            "▁Parti Anim\t\t0.0725\n",
            "Anim aliste\t\t0.0412\n",
            "aliste ▁TF\t\t0.0505\n",
            "▁TF ▁Terr\t\t0.0735\n",
            "▁Terr ine\t\t0.1026\n",
            "ine ▁et\t\t0.1581\n",
            "▁et ▁Pat\t\t0.1661\n",
            "▁Pat e\t\t0.0375\n",
            "e ▁man\t\t0.0087\n",
            "▁man _\t\t0.0501\n",
            "_ sh\t\t0.0282\n",
            "sh ru\t\t-0.1441\n",
            "ru gging\t\t-0.9580\n",
            "gging </s>\t\t-1.3530\n",
            "\n",
            "Trigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁Hel en\t\t-0.0065\n",
            "▁Hel en e\t\t-0.0159\n",
            "en e T\t\t-0.0344\n",
            "e T hou\t\t-0.0146\n",
            "T hou y\t\t0.0066\n",
            "hou y ▁Parti\t\t0.0519\n",
            "y ▁Parti Anim\t\t0.0843\n",
            "▁Parti Anim aliste\t\t0.0955\n",
            "Anim aliste ▁TF\t\t0.0688\n",
            "aliste ▁TF ▁Terr\t\t0.0964\n",
            "▁TF ▁Terr ine\t\t0.1302\n",
            "▁Terr ine ▁et\t\t0.2040\n",
            "ine ▁et ▁Pat\t\t0.2228\n",
            "▁et ▁Pat e\t\t0.1389\n",
            "▁Pat e ▁man\t\t0.0734\n",
            "e ▁man _\t\t0.0230\n",
            "▁man _ sh\t\t0.0640\n",
            "_ sh ru\t\t-0.1298\n",
            "sh ru gging\t\t-0.9441\n",
            "ru gging </s>\t\t-1.5110\n",
            "\n",
            "Predicted Class: viande\n",
            "True Class: viande\n",
            "Predicted Probability: 4.440113067626953\n",
            "Target Attribution Score: -1.0918194790150255\n",
            "\n",
            "==================================================\n",
            "\n",
            "Target Class: décroissance\n",
            "Token\t\tAttribution Score\n",
            "--------------------------\n",
            "<s>\t\t0.0000\n",
            "▁Hel\t\t-0.0363\n",
            "en\t\t-0.1198\n",
            "e\t\t-0.1637\n",
            "T\t\t-0.1689\n",
            "hou\t\t-0.2515\n",
            "y\t\t-0.0046\n",
            "▁Parti\t\t-0.0507\n",
            "Anim\t\t-0.0904\n",
            "aliste\t\t-0.1085\n",
            "▁TF\t\t-0.7119\n",
            "▁Terr\t\t0.0505\n",
            "ine\t\t0.0066\n",
            "▁et\t\t0.0086\n",
            "▁Pat\t\t0.2401\n",
            "e\t\t-0.0272\n",
            "▁man\t\t-0.0282\n",
            "_\t\t0.4405\n",
            "sh\t\t-0.1177\n",
            "ru\t\t-0.1104\n",
            "gging\t\t-0.2334\n",
            "</s>\t\t0.0027\n",
            "\n",
            "Bigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁Hel\t\t-0.0363\n",
            "▁Hel en\t\t-0.1561\n",
            "en e\t\t-0.2835\n",
            "e T\t\t-0.3326\n",
            "T hou\t\t-0.4203\n",
            "hou y\t\t-0.2561\n",
            "y ▁Parti\t\t-0.0553\n",
            "▁Parti Anim\t\t-0.1411\n",
            "Anim aliste\t\t-0.1989\n",
            "aliste ▁TF\t\t-0.8204\n",
            "▁TF ▁Terr\t\t-0.6613\n",
            "▁Terr ine\t\t0.0571\n",
            "ine ▁et\t\t0.0152\n",
            "▁et ▁Pat\t\t0.2488\n",
            "▁Pat e\t\t0.2129\n",
            "e ▁man\t\t-0.0554\n",
            "▁man _\t\t0.4123\n",
            "_ sh\t\t0.3228\n",
            "sh ru\t\t-0.2282\n",
            "ru gging\t\t-0.3438\n",
            "gging </s>\t\t-0.2307\n",
            "\n",
            "Trigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁Hel en\t\t-0.1561\n",
            "▁Hel en e\t\t-0.3198\n",
            "en e T\t\t-0.4524\n",
            "e T hou\t\t-0.5840\n",
            "T hou y\t\t-0.4249\n",
            "hou y ▁Parti\t\t-0.3067\n",
            "y ▁Parti Anim\t\t-0.1457\n",
            "▁Parti Anim aliste\t\t-0.2496\n",
            "Anim aliste ▁TF\t\t-0.9108\n",
            "aliste ▁TF ▁Terr\t\t-0.7698\n",
            "▁TF ▁Terr ine\t\t-0.6547\n",
            "▁Terr ine ▁et\t\t0.0657\n",
            "ine ▁et ▁Pat\t\t0.2554\n",
            "▁et ▁Pat e\t\t0.2216\n",
            "▁Pat e ▁man\t\t0.1847\n",
            "e ▁man _\t\t0.3851\n",
            "▁man _ sh\t\t0.2945\n",
            "_ sh ru\t\t0.2124\n",
            "sh ru gging\t\t-0.4616\n",
            "ru gging </s>\t\t-0.3411\n",
            "\n",
            "Predicted Class: viande\n",
            "True Class: viande\n",
            "Predicted Probability: 4.440113067626953\n",
            "Target Attribution Score: -1.4740647414082397\n",
            "\n",
            "==================================================\n",
            "\n",
            "Target Class: nucléaire\n",
            "Token\t\tAttribution Score\n",
            "--------------------------\n",
            "<s>\t\t0.0000\n",
            "▁Hel\t\t-0.1574\n",
            "en\t\t0.0322\n",
            "e\t\t-0.0308\n",
            "T\t\t0.0100\n",
            "hou\t\t-0.0860\n",
            "y\t\t-0.0560\n",
            "▁Parti\t\t-0.0335\n",
            "Anim\t\t0.1416\n",
            "aliste\t\t-0.0986\n",
            "▁TF\t\t0.0002\n",
            "▁Terr\t\t-0.0789\n",
            "ine\t\t-0.0108\n",
            "▁et\t\t-0.0969\n",
            "▁Pat\t\t-0.1990\n",
            "e\t\t0.0008\n",
            "▁man\t\t-0.0200\n",
            "_\t\t0.3076\n",
            "sh\t\t-0.1012\n",
            "ru\t\t0.0314\n",
            "gging\t\t0.7193\n",
            "</s>\t\t0.5027\n",
            "\n",
            "Bigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁Hel\t\t-0.1574\n",
            "▁Hel en\t\t-0.1252\n",
            "en e\t\t0.0014\n",
            "e T\t\t-0.0208\n",
            "T hou\t\t-0.0760\n",
            "hou y\t\t-0.1419\n",
            "y ▁Parti\t\t-0.0895\n",
            "▁Parti Anim\t\t0.1081\n",
            "Anim aliste\t\t0.0430\n",
            "aliste ▁TF\t\t-0.0984\n",
            "▁TF ▁Terr\t\t-0.0787\n",
            "▁Terr ine\t\t-0.0897\n",
            "ine ▁et\t\t-0.1077\n",
            "▁et ▁Pat\t\t-0.2959\n",
            "▁Pat e\t\t-0.1982\n",
            "e ▁man\t\t-0.0192\n",
            "▁man _\t\t0.2876\n",
            "_ sh\t\t0.2064\n",
            "sh ru\t\t-0.0698\n",
            "ru gging\t\t0.7508\n",
            "gging </s>\t\t1.2221\n",
            "\n",
            "Trigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁Hel en\t\t-0.1252\n",
            "▁Hel en e\t\t-0.1560\n",
            "en e T\t\t0.0114\n",
            "e T hou\t\t-0.1068\n",
            "T hou y\t\t-0.1320\n",
            "hou y ▁Parti\t\t-0.1754\n",
            "y ▁Parti Anim\t\t0.0521\n",
            "▁Parti Anim aliste\t\t0.0095\n",
            "Anim aliste ▁TF\t\t0.0432\n",
            "aliste ▁TF ▁Terr\t\t-0.1773\n",
            "▁TF ▁Terr ine\t\t-0.0895\n",
            "▁Terr ine ▁et\t\t-0.1866\n",
            "ine ▁et ▁Pat\t\t-0.3066\n",
            "▁et ▁Pat e\t\t-0.2951\n",
            "▁Pat e ▁man\t\t-0.2182\n",
            "e ▁man _\t\t0.2884\n",
            "▁man _ sh\t\t0.1864\n",
            "_ sh ru\t\t0.2378\n",
            "sh ru gging\t\t0.6496\n",
            "ru gging </s>\t\t1.2535\n",
            "\n",
            "Predicted Class: viande\n",
            "True Class: viande\n",
            "Predicted Probability: 4.440113067626953\n",
            "Target Attribution Score: 0.776863487785952\n",
            "\n",
            "==================================================\n",
            "\n",
            "Target Class: viande\n",
            "Token\t\tAttribution Score\n",
            "--------------------------\n",
            "<s>\t\t0.0000\n",
            "▁Hel\t\t0.1373\n",
            "en\t\t0.1272\n",
            "e\t\t0.1921\n",
            "T\t\t0.0383\n",
            "hou\t\t0.1409\n",
            "y\t\t0.1417\n",
            "▁Parti\t\t0.0052\n",
            "Anim\t\t-0.0215\n",
            "aliste\t\t0.1408\n",
            "▁TF\t\t0.1445\n",
            "▁Terr\t\t0.1085\n",
            "ine\t\t0.1897\n",
            "▁et\t\t0.1189\n",
            "▁Pat\t\t0.4140\n",
            "e\t\t0.2115\n",
            "▁man\t\t0.0020\n",
            "_\t\t-0.2910\n",
            "sh\t\t0.1371\n",
            "ru\t\t0.1578\n",
            "gging\t\t0.5991\n",
            "</s>\t\t0.2830\n",
            "\n",
            "Bigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁Hel\t\t0.1373\n",
            "▁Hel en\t\t0.2645\n",
            "en e\t\t0.3193\n",
            "e T\t\t0.2305\n",
            "T hou\t\t0.1792\n",
            "hou y\t\t0.2826\n",
            "y ▁Parti\t\t0.1470\n",
            "▁Parti Anim\t\t-0.0163\n",
            "Anim aliste\t\t0.1193\n",
            "aliste ▁TF\t\t0.2853\n",
            "▁TF ▁Terr\t\t0.2530\n",
            "▁Terr ine\t\t0.2982\n",
            "ine ▁et\t\t0.3086\n",
            "▁et ▁Pat\t\t0.5329\n",
            "▁Pat e\t\t0.6256\n",
            "e ▁man\t\t0.2135\n",
            "▁man _\t\t-0.2890\n",
            "_ sh\t\t-0.1540\n",
            "sh ru\t\t0.2949\n",
            "ru gging\t\t0.7569\n",
            "gging </s>\t\t0.8821\n",
            "\n",
            "Trigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁Hel en\t\t0.2645\n",
            "▁Hel en e\t\t0.4567\n",
            "en e T\t\t0.3577\n",
            "e T hou\t\t0.3714\n",
            "T hou y\t\t0.3210\n",
            "hou y ▁Parti\t\t0.2879\n",
            "y ▁Parti Anim\t\t0.1254\n",
            "▁Parti Anim aliste\t\t0.1245\n",
            "Anim aliste ▁TF\t\t0.2637\n",
            "aliste ▁TF ▁Terr\t\t0.3938\n",
            "▁TF ▁Terr ine\t\t0.4427\n",
            "▁Terr ine ▁et\t\t0.4171\n",
            "ine ▁et ▁Pat\t\t0.7226\n",
            "▁et ▁Pat e\t\t0.7444\n",
            "▁Pat e ▁man\t\t0.6276\n",
            "e ▁man _\t\t-0.0775\n",
            "▁man _ sh\t\t-0.1520\n",
            "_ sh ru\t\t0.0039\n",
            "sh ru gging\t\t0.8940\n",
            "ru gging </s>\t\t1.0399\n",
            "\n",
            "Predicted Class: viande\n",
            "True Class: viande\n",
            "Predicted Probability: 4.440113067626953\n",
            "Target Attribution Score: 2.9772346715816274\n",
            "\n",
            "==================================================\n",
            "\n",
            "Sentence: @CeliaGautier @Kako_line Du reste l’EPR entrera en service avant 2030, ce qui confirme bien mon point sur l’anticipation, et vous omettez le rôle néfaste de la désinformation des anti-nucléaires sur les citoyens.\n",
            "Target Class: avion\n",
            "Token\t\tAttribution Score\n",
            "--------------------------\n",
            "<s>\t\t0.0000\n",
            "▁Ce\t\t-0.0355\n",
            "lia\t\t0.8072\n",
            "G\t\t-0.0040\n",
            "au\t\t0.0446\n",
            "tier\t\t0.0208\n",
            "▁Ka\t\t0.0468\n",
            "ko\t\t0.0195\n",
            "_\t\t0.0091\n",
            "line\t\t-0.0009\n",
            "▁reste\t\t0.0740\n",
            "▁l\t\t-0.1659\n",
            "EP\t\t-0.3420\n",
            "R\t\t-0.2584\n",
            "▁entre\t\t0.0425\n",
            "ra\t\t0.0594\n",
            "▁en\t\t0.0233\n",
            "▁service\t\t0.0304\n",
            "▁avant\t\t0.0274\n",
            "▁ce\t\t0.0115\n",
            "▁qui\t\t0.0263\n",
            "▁confirme\t\t0.0170\n",
            "▁bien\t\t0.0056\n",
            "▁mon\t\t0.0076\n",
            "▁point\t\t0.0538\n",
            "▁sur\t\t0.0551\n",
            "▁l\t\t0.0273\n",
            "anticipation\t\t0.0075\n",
            "▁et\t\t0.0332\n",
            "▁om\t\t0.0220\n",
            "ette\t\t0.0099\n",
            "z\t\t0.0119\n",
            "▁role\t\t0.0016\n",
            "▁ne\t\t0.0706\n",
            "f\t\t0.1742\n",
            "aste\t\t0.0962\n",
            "▁des\t\t0.0719\n",
            "information\t\t0.1099\n",
            "▁anti\t\t0.0596\n",
            "-\t\t0.0365\n",
            "nu\t\t0.0646\n",
            "cle\t\t0.0952\n",
            "aires\t\t0.0923\n",
            "▁sur\t\t0.1066\n",
            "▁citoyens\t\t0.0781\n",
            "</s>\t\t0.0463\n",
            "\n",
            "Bigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁Ce\t\t-0.0355\n",
            "▁Ce lia\t\t0.7717\n",
            "lia G\t\t0.8032\n",
            "G au\t\t0.0407\n",
            "au tier\t\t0.0654\n",
            "tier ▁Ka\t\t0.0676\n",
            "▁Ka ko\t\t0.0662\n",
            "ko _\t\t0.0286\n",
            "_ line\t\t0.0082\n",
            "line ▁reste\t\t0.0730\n",
            "▁reste ▁l\t\t-0.0919\n",
            "▁l EP\t\t-0.5079\n",
            "EP R\t\t-0.6004\n",
            "R ▁entre\t\t-0.2159\n",
            "▁entre ra\t\t0.1019\n",
            "ra ▁en\t\t0.0827\n",
            "▁en ▁service\t\t0.0537\n",
            "▁service ▁avant\t\t0.0578\n",
            "▁avant ▁ce\t\t0.0390\n",
            "▁ce ▁qui\t\t0.0378\n",
            "▁qui ▁confirme\t\t0.0432\n",
            "▁confirme ▁bien\t\t0.0226\n",
            "▁bien ▁mon\t\t0.0132\n",
            "▁mon ▁point\t\t0.0615\n",
            "▁point ▁sur\t\t0.1090\n",
            "▁sur ▁l\t\t0.0824\n",
            "▁l anticipation\t\t0.0348\n",
            "anticipation ▁et\t\t0.0407\n",
            "▁et ▁om\t\t0.0552\n",
            "▁om ette\t\t0.0319\n",
            "ette z\t\t0.0218\n",
            "z ▁role\t\t0.0135\n",
            "▁role ▁ne\t\t0.0722\n",
            "▁ne f\t\t0.2448\n",
            "f aste\t\t0.2705\n",
            "aste ▁des\t\t0.1682\n",
            "▁des information\t\t0.1818\n",
            "information ▁anti\t\t0.1694\n",
            "▁anti -\t\t0.0960\n",
            "- nu\t\t0.1010\n",
            "nu cle\t\t0.1598\n",
            "cle aires\t\t0.1875\n",
            "aires ▁sur\t\t0.1989\n",
            "▁sur ▁citoyens\t\t0.1847\n",
            "▁citoyens </s>\t\t0.1243\n",
            "\n",
            "Trigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁Ce lia\t\t0.7717\n",
            "▁Ce lia G\t\t0.7677\n",
            "lia G au\t\t0.8478\n",
            "G au tier\t\t0.0614\n",
            "au tier ▁Ka\t\t0.1122\n",
            "tier ▁Ka ko\t\t0.0870\n",
            "▁Ka ko _\t\t0.0754\n",
            "ko _ line\t\t0.0276\n",
            "_ line ▁reste\t\t0.0821\n",
            "line ▁reste ▁l\t\t-0.0929\n",
            "▁reste ▁l EP\t\t-0.4339\n",
            "▁l EP R\t\t-0.7663\n",
            "EP R ▁entre\t\t-0.5579\n",
            "R ▁entre ra\t\t-0.1565\n",
            "▁entre ra ▁en\t\t0.1253\n",
            "ra ▁en ▁service\t\t0.1131\n",
            "▁en ▁service ▁avant\t\t0.0811\n",
            "▁service ▁avant ▁ce\t\t0.0694\n",
            "▁avant ▁ce ▁qui\t\t0.0652\n",
            "▁ce ▁qui ▁confirme\t\t0.0548\n",
            "▁qui ▁confirme ▁bien\t\t0.0488\n",
            "▁confirme ▁bien ▁mon\t\t0.0302\n",
            "▁bien ▁mon ▁point\t\t0.0671\n",
            "▁mon ▁point ▁sur\t\t0.1166\n",
            "▁point ▁sur ▁l\t\t0.1362\n",
            "▁sur ▁l anticipation\t\t0.0899\n",
            "▁l anticipation ▁et\t\t0.0679\n",
            "anticipation ▁et ▁om\t\t0.0627\n",
            "▁et ▁om ette\t\t0.0650\n",
            "▁om ette z\t\t0.0438\n",
            "ette z ▁role\t\t0.0234\n",
            "z ▁role ▁ne\t\t0.0841\n",
            "▁role ▁ne f\t\t0.2464\n",
            "▁ne f aste\t\t0.3411\n",
            "f aste ▁des\t\t0.3424\n",
            "aste ▁des information\t\t0.2780\n",
            "▁des information ▁anti\t\t0.2413\n",
            "information ▁anti -\t\t0.2059\n",
            "▁anti - nu\t\t0.1606\n",
            "- nu cle\t\t0.1962\n",
            "nu cle aires\t\t0.2521\n",
            "cle aires ▁sur\t\t0.2941\n",
            "aires ▁sur ▁citoyens\t\t0.2770\n",
            "▁sur ▁citoyens </s>\t\t0.2310\n",
            "\n",
            "Predicted Class: nucléaire\n",
            "True Class: nucléaire\n",
            "Predicted Probability: 4.621401786804199\n",
            "Target Attribution Score: 1.7904841977760422\n",
            "\n",
            "==================================================\n",
            "\n",
            "Target Class: décroissance\n",
            "Token\t\tAttribution Score\n",
            "--------------------------\n",
            "<s>\t\t0.0000\n",
            "▁Ce\t\t-0.0837\n",
            "lia\t\t-0.1172\n",
            "G\t\t-0.0554\n",
            "au\t\t0.2422\n",
            "tier\t\t0.2261\n",
            "▁Ka\t\t0.0324\n",
            "ko\t\t-0.0013\n",
            "_\t\t-0.0641\n",
            "line\t\t0.0360\n",
            "▁reste\t\t-0.1790\n",
            "▁l\t\t-0.3014\n",
            "EP\t\t-0.3040\n",
            "R\t\t-0.3464\n",
            "▁entre\t\t-0.2349\n",
            "ra\t\t-0.1173\n",
            "▁en\t\t0.0816\n",
            "▁service\t\t-0.0572\n",
            "▁avant\t\t-0.1444\n",
            "▁ce\t\t0.0323\n",
            "▁qui\t\t0.0060\n",
            "▁confirme\t\t-0.1446\n",
            "▁bien\t\t-0.1065\n",
            "▁mon\t\t0.1290\n",
            "▁point\t\t-0.0540\n",
            "▁sur\t\t-0.1263\n",
            "▁l\t\t0.0214\n",
            "anticipation\t\t0.0217\n",
            "▁et\t\t-0.0024\n",
            "▁om\t\t-0.1587\n",
            "ette\t\t0.0631\n",
            "z\t\t0.0835\n",
            "▁role\t\t-0.1151\n",
            "▁ne\t\t-0.1019\n",
            "f\t\t0.0162\n",
            "aste\t\t0.1274\n",
            "▁des\t\t-0.2741\n",
            "information\t\t-0.1641\n",
            "▁anti\t\t0.1592\n",
            "-\t\t0.1042\n",
            "nu\t\t-0.0178\n",
            "cle\t\t-0.1243\n",
            "aires\t\t-0.0016\n",
            "▁sur\t\t-0.1171\n",
            "▁citoyens\t\t-0.2249\n",
            "</s>\t\t-0.2461\n",
            "\n",
            "Bigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁Ce\t\t-0.0837\n",
            "▁Ce lia\t\t-0.2008\n",
            "lia G\t\t-0.1726\n",
            "G au\t\t0.1868\n",
            "au tier\t\t0.4683\n",
            "tier ▁Ka\t\t0.2585\n",
            "▁Ka ko\t\t0.0311\n",
            "ko _\t\t-0.0654\n",
            "_ line\t\t-0.0282\n",
            "line ▁reste\t\t-0.1431\n",
            "▁reste ▁l\t\t-0.4805\n",
            "▁l EP\t\t-0.6055\n",
            "EP R\t\t-0.6504\n",
            "R ▁entre\t\t-0.5813\n",
            "▁entre ra\t\t-0.3522\n",
            "ra ▁en\t\t-0.0358\n",
            "▁en ▁service\t\t0.0244\n",
            "▁service ▁avant\t\t-0.2016\n",
            "▁avant ▁ce\t\t-0.1121\n",
            "▁ce ▁qui\t\t0.0383\n",
            "▁qui ▁confirme\t\t-0.1386\n",
            "▁confirme ▁bien\t\t-0.2512\n",
            "▁bien ▁mon\t\t0.0225\n",
            "▁mon ▁point\t\t0.0750\n",
            "▁point ▁sur\t\t-0.1802\n",
            "▁sur ▁l\t\t-0.1049\n",
            "▁l anticipation\t\t0.0431\n",
            "anticipation ▁et\t\t0.0192\n",
            "▁et ▁om\t\t-0.1612\n",
            "▁om ette\t\t-0.0956\n",
            "ette z\t\t0.1466\n",
            "z ▁role\t\t-0.0316\n",
            "▁role ▁ne\t\t-0.2170\n",
            "▁ne f\t\t-0.0858\n",
            "f aste\t\t0.1435\n",
            "aste ▁des\t\t-0.1467\n",
            "▁des information\t\t-0.4382\n",
            "information ▁anti\t\t-0.0049\n",
            "▁anti -\t\t0.2634\n",
            "- nu\t\t0.0864\n",
            "nu cle\t\t-0.1421\n",
            "cle aires\t\t-0.1259\n",
            "aires ▁sur\t\t-0.1187\n",
            "▁sur ▁citoyens\t\t-0.3419\n",
            "▁citoyens </s>\t\t-0.4709\n",
            "\n",
            "Trigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁Ce lia\t\t-0.2008\n",
            "▁Ce lia G\t\t-0.2563\n",
            "lia G au\t\t0.0696\n",
            "G au tier\t\t0.4129\n",
            "au tier ▁Ka\t\t0.5008\n",
            "tier ▁Ka ko\t\t0.2573\n",
            "▁Ka ko _\t\t-0.0330\n",
            "ko _ line\t\t-0.0294\n",
            "_ line ▁reste\t\t-0.2072\n",
            "line ▁reste ▁l\t\t-0.4445\n",
            "▁reste ▁l EP\t\t-0.7845\n",
            "▁l EP R\t\t-0.9519\n",
            "EP R ▁entre\t\t-0.8853\n",
            "R ▁entre ra\t\t-0.6986\n",
            "▁entre ra ▁en\t\t-0.2706\n",
            "ra ▁en ▁service\t\t-0.0930\n",
            "▁en ▁service ▁avant\t\t-0.1200\n",
            "▁service ▁avant ▁ce\t\t-0.1693\n",
            "▁avant ▁ce ▁qui\t\t-0.1061\n",
            "▁ce ▁qui ▁confirme\t\t-0.1063\n",
            "▁qui ▁confirme ▁bien\t\t-0.2451\n",
            "▁confirme ▁bien ▁mon\t\t-0.1221\n",
            "▁bien ▁mon ▁point\t\t-0.0315\n",
            "▁mon ▁point ▁sur\t\t-0.0512\n",
            "▁point ▁sur ▁l\t\t-0.1588\n",
            "▁sur ▁l anticipation\t\t-0.0832\n",
            "▁l anticipation ▁et\t\t0.0406\n",
            "anticipation ▁et ▁om\t\t-0.1395\n",
            "▁et ▁om ette\t\t-0.0980\n",
            "▁om ette z\t\t-0.0121\n",
            "ette z ▁role\t\t0.0315\n",
            "z ▁role ▁ne\t\t-0.1335\n",
            "▁role ▁ne f\t\t-0.2009\n",
            "▁ne f aste\t\t0.0416\n",
            "f aste ▁des\t\t-0.1305\n",
            "aste ▁des information\t\t-0.3108\n",
            "▁des information ▁anti\t\t-0.2790\n",
            "information ▁anti -\t\t0.0993\n",
            "▁anti - nu\t\t0.2456\n",
            "- nu cle\t\t-0.0379\n",
            "nu cle aires\t\t-0.1437\n",
            "cle aires ▁sur\t\t-0.2429\n",
            "aires ▁sur ▁citoyens\t\t-0.3435\n",
            "▁sur ▁citoyens </s>\t\t-0.5880\n",
            "\n",
            "Predicted Class: nucléaire\n",
            "True Class: nucléaire\n",
            "Predicted Probability: 4.621401786804199\n",
            "Target Attribution Score: -2.603502962033481\n",
            "\n",
            "==================================================\n",
            "\n",
            "Target Class: nucléaire\n",
            "Token\t\tAttribution Score\n",
            "--------------------------\n",
            "<s>\t\t0.0000\n",
            "▁Ce\t\t-0.2408\n",
            "lia\t\t-0.4368\n",
            "G\t\t-0.0501\n",
            "au\t\t-0.2746\n",
            "tier\t\t-0.4742\n",
            "▁Ka\t\t0.0090\n",
            "ko\t\t-0.0229\n",
            "_\t\t0.0225\n",
            "line\t\t-0.0067\n",
            "▁reste\t\t0.0166\n",
            "▁l\t\t0.2450\n",
            "EP\t\t0.2830\n",
            "R\t\t0.2496\n",
            "▁entre\t\t0.1798\n",
            "ra\t\t0.1465\n",
            "▁en\t\t0.0707\n",
            "▁service\t\t0.0311\n",
            "▁avant\t\t0.0656\n",
            "▁ce\t\t0.0469\n",
            "▁qui\t\t0.0500\n",
            "▁confirme\t\t0.0658\n",
            "▁bien\t\t0.0668\n",
            "▁mon\t\t0.0017\n",
            "▁point\t\t0.0264\n",
            "▁sur\t\t0.0494\n",
            "▁l\t\t0.0518\n",
            "anticipation\t\t0.0595\n",
            "▁et\t\t0.0319\n",
            "▁om\t\t0.0459\n",
            "ette\t\t0.0110\n",
            "z\t\t-0.0130\n",
            "▁role\t\t0.0525\n",
            "▁ne\t\t0.0014\n",
            "f\t\t-0.0649\n",
            "aste\t\t-0.0264\n",
            "▁des\t\t0.0804\n",
            "information\t\t0.0037\n",
            "▁anti\t\t-0.0234\n",
            "-\t\t-0.0123\n",
            "nu\t\t-0.0564\n",
            "cle\t\t-0.1272\n",
            "aires\t\t-0.0215\n",
            "▁sur\t\t-0.1296\n",
            "▁citoyens\t\t0.3148\n",
            "</s>\t\t0.0601\n",
            "\n",
            "Bigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁Ce\t\t-0.2408\n",
            "▁Ce lia\t\t-0.6777\n",
            "lia G\t\t-0.4870\n",
            "G au\t\t-0.3248\n",
            "au tier\t\t-0.7488\n",
            "tier ▁Ka\t\t-0.4651\n",
            "▁Ka ko\t\t-0.0139\n",
            "ko _\t\t-0.0004\n",
            "_ line\t\t0.0158\n",
            "line ▁reste\t\t0.0099\n",
            "▁reste ▁l\t\t0.2616\n",
            "▁l EP\t\t0.5280\n",
            "EP R\t\t0.5326\n",
            "R ▁entre\t\t0.4295\n",
            "▁entre ra\t\t0.3264\n",
            "ra ▁en\t\t0.2172\n",
            "▁en ▁service\t\t0.1018\n",
            "▁service ▁avant\t\t0.0967\n",
            "▁avant ▁ce\t\t0.1124\n",
            "▁ce ▁qui\t\t0.0969\n",
            "▁qui ▁confirme\t\t0.1158\n",
            "▁confirme ▁bien\t\t0.1326\n",
            "▁bien ▁mon\t\t0.0685\n",
            "▁mon ▁point\t\t0.0281\n",
            "▁point ▁sur\t\t0.0758\n",
            "▁sur ▁l\t\t0.1012\n",
            "▁l anticipation\t\t0.1113\n",
            "anticipation ▁et\t\t0.0914\n",
            "▁et ▁om\t\t0.0778\n",
            "▁om ette\t\t0.0569\n",
            "ette z\t\t-0.0020\n",
            "z ▁role\t\t0.0395\n",
            "▁role ▁ne\t\t0.0539\n",
            "▁ne f\t\t-0.0635\n",
            "f aste\t\t-0.0913\n",
            "aste ▁des\t\t0.0540\n",
            "▁des information\t\t0.0841\n",
            "information ▁anti\t\t-0.0197\n",
            "▁anti -\t\t-0.0357\n",
            "- nu\t\t-0.0687\n",
            "nu cle\t\t-0.1836\n",
            "cle aires\t\t-0.1487\n",
            "aires ▁sur\t\t-0.1511\n",
            "▁sur ▁citoyens\t\t0.1852\n",
            "▁citoyens </s>\t\t0.3749\n",
            "\n",
            "Trigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁Ce lia\t\t-0.6777\n",
            "▁Ce lia G\t\t-0.7278\n",
            "lia G au\t\t-0.7616\n",
            "G au tier\t\t-0.7989\n",
            "au tier ▁Ka\t\t-0.7398\n",
            "tier ▁Ka ko\t\t-0.4880\n",
            "▁Ka ko _\t\t0.0087\n",
            "ko _ line\t\t-0.0071\n",
            "_ line ▁reste\t\t0.0325\n",
            "line ▁reste ▁l\t\t0.2549\n",
            "▁reste ▁l EP\t\t0.5446\n",
            "▁l EP R\t\t0.7776\n",
            "EP R ▁entre\t\t0.7125\n",
            "R ▁entre ra\t\t0.5760\n",
            "▁entre ra ▁en\t\t0.3970\n",
            "ra ▁en ▁service\t\t0.2483\n",
            "▁en ▁service ▁avant\t\t0.1674\n",
            "▁service ▁avant ▁ce\t\t0.1436\n",
            "▁avant ▁ce ▁qui\t\t0.1625\n",
            "▁ce ▁qui ▁confirme\t\t0.1627\n",
            "▁qui ▁confirme ▁bien\t\t0.1826\n",
            "▁confirme ▁bien ▁mon\t\t0.1343\n",
            "▁bien ▁mon ▁point\t\t0.0949\n",
            "▁mon ▁point ▁sur\t\t0.0775\n",
            "▁point ▁sur ▁l\t\t0.1276\n",
            "▁sur ▁l anticipation\t\t0.1607\n",
            "▁l anticipation ▁et\t\t0.1432\n",
            "anticipation ▁et ▁om\t\t0.1373\n",
            "▁et ▁om ette\t\t0.0888\n",
            "▁om ette z\t\t0.0439\n",
            "ette z ▁role\t\t0.0505\n",
            "z ▁role ▁ne\t\t0.0409\n",
            "▁role ▁ne f\t\t-0.0110\n",
            "▁ne f aste\t\t-0.0899\n",
            "f aste ▁des\t\t-0.0109\n",
            "aste ▁des information\t\t0.0577\n",
            "▁des information ▁anti\t\t0.0607\n",
            "information ▁anti -\t\t-0.0320\n",
            "▁anti - nu\t\t-0.0921\n",
            "- nu cle\t\t-0.1958\n",
            "nu cle aires\t\t-0.2050\n",
            "cle aires ▁sur\t\t-0.2783\n",
            "aires ▁sur ▁citoyens\t\t0.1637\n",
            "▁sur ▁citoyens </s>\t\t0.2453\n",
            "\n",
            "Predicted Class: nucléaire\n",
            "True Class: nucléaire\n",
            "Predicted Probability: 4.621401786804199\n",
            "Target Attribution Score: 0.35868032094921065\n",
            "\n",
            "==================================================\n",
            "\n",
            "Target Class: viande\n",
            "Token\t\tAttribution Score\n",
            "--------------------------\n",
            "<s>\t\t0.0000\n",
            "▁Ce\t\t0.4182\n",
            "lia\t\t-0.4860\n",
            "G\t\t0.1654\n",
            "au\t\t0.3233\n",
            "tier\t\t0.2668\n",
            "▁Ka\t\t0.0623\n",
            "ko\t\t0.0959\n",
            "_\t\t0.1265\n",
            "line\t\t0.1140\n",
            "▁reste\t\t0.0598\n",
            "▁l\t\t-0.0123\n",
            "EP\t\t-0.0979\n",
            "R\t\t0.0540\n",
            "▁entre\t\t-0.0780\n",
            "ra\t\t-0.0556\n",
            "▁en\t\t0.0416\n",
            "▁service\t\t-0.0143\n",
            "▁avant\t\t-0.0024\n",
            "▁ce\t\t0.0176\n",
            "▁qui\t\t0.0032\n",
            "▁confirme\t\t0.0470\n",
            "▁bien\t\t0.0289\n",
            "▁mon\t\t0.0422\n",
            "▁point\t\t0.0037\n",
            "▁sur\t\t0.0055\n",
            "▁l\t\t0.0384\n",
            "anticipation\t\t0.0643\n",
            "▁et\t\t0.0288\n",
            "▁om\t\t0.0414\n",
            "ette\t\t0.0474\n",
            "z\t\t0.0570\n",
            "▁role\t\t0.0310\n",
            "▁ne\t\t0.0843\n",
            "f\t\t0.0307\n",
            "aste\t\t0.0462\n",
            "▁des\t\t-0.0015\n",
            "information\t\t0.0207\n",
            "▁anti\t\t0.1311\n",
            "-\t\t0.0583\n",
            "nu\t\t-0.4379\n",
            "cle\t\t-0.0202\n",
            "aires\t\t0.0822\n",
            "▁sur\t\t0.0292\n",
            "▁citoyens\t\t0.2540\n",
            "</s>\t\t-0.0334\n",
            "\n",
            "Bigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁Ce\t\t0.4182\n",
            "▁Ce lia\t\t-0.0678\n",
            "lia G\t\t-0.3206\n",
            "G au\t\t0.4887\n",
            "au tier\t\t0.5901\n",
            "tier ▁Ka\t\t0.3291\n",
            "▁Ka ko\t\t0.1582\n",
            "ko _\t\t0.2224\n",
            "_ line\t\t0.2405\n",
            "line ▁reste\t\t0.1738\n",
            "▁reste ▁l\t\t0.0475\n",
            "▁l EP\t\t-0.1102\n",
            "EP R\t\t-0.0439\n",
            "R ▁entre\t\t-0.0240\n",
            "▁entre ra\t\t-0.1337\n",
            "ra ▁en\t\t-0.0140\n",
            "▁en ▁service\t\t0.0273\n",
            "▁service ▁avant\t\t-0.0167\n",
            "▁avant ▁ce\t\t0.0152\n",
            "▁ce ▁qui\t\t0.0208\n",
            "▁qui ▁confirme\t\t0.0502\n",
            "▁confirme ▁bien\t\t0.0759\n",
            "▁bien ▁mon\t\t0.0711\n",
            "▁mon ▁point\t\t0.0459\n",
            "▁point ▁sur\t\t0.0091\n",
            "▁sur ▁l\t\t0.0439\n",
            "▁l anticipation\t\t0.1027\n",
            "anticipation ▁et\t\t0.0931\n",
            "▁et ▁om\t\t0.0702\n",
            "▁om ette\t\t0.0887\n",
            "ette z\t\t0.1043\n",
            "z ▁role\t\t0.0880\n",
            "▁role ▁ne\t\t0.1153\n",
            "▁ne f\t\t0.1151\n",
            "f aste\t\t0.0769\n",
            "aste ▁des\t\t0.0447\n",
            "▁des information\t\t0.0191\n",
            "information ▁anti\t\t0.1518\n",
            "▁anti -\t\t0.1894\n",
            "- nu\t\t-0.3796\n",
            "nu cle\t\t-0.4581\n",
            "cle aires\t\t0.0620\n",
            "aires ▁sur\t\t0.1114\n",
            "▁sur ▁citoyens\t\t0.2833\n",
            "▁citoyens </s>\t\t0.2206\n",
            "\n",
            "Trigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁Ce lia\t\t-0.0678\n",
            "▁Ce lia G\t\t0.0976\n",
            "lia G au\t\t0.0027\n",
            "G au tier\t\t0.7555\n",
            "au tier ▁Ka\t\t0.6524\n",
            "tier ▁Ka ko\t\t0.4250\n",
            "▁Ka ko _\t\t0.2847\n",
            "ko _ line\t\t0.3364\n",
            "_ line ▁reste\t\t0.3003\n",
            "line ▁reste ▁l\t\t0.1615\n",
            "▁reste ▁l EP\t\t-0.0504\n",
            "▁l EP R\t\t-0.0562\n",
            "EP R ▁entre\t\t-0.1219\n",
            "R ▁entre ra\t\t-0.0797\n",
            "▁entre ra ▁en\t\t-0.0921\n",
            "ra ▁en ▁service\t\t-0.0283\n",
            "▁en ▁service ▁avant\t\t0.0249\n",
            "▁service ▁avant ▁ce\t\t0.0009\n",
            "▁avant ▁ce ▁qui\t\t0.0184\n",
            "▁ce ▁qui ▁confirme\t\t0.0678\n",
            "▁qui ▁confirme ▁bien\t\t0.0791\n",
            "▁confirme ▁bien ▁mon\t\t0.1181\n",
            "▁bien ▁mon ▁point\t\t0.0748\n",
            "▁mon ▁point ▁sur\t\t0.0513\n",
            "▁point ▁sur ▁l\t\t0.0475\n",
            "▁sur ▁l anticipation\t\t0.1082\n",
            "▁l anticipation ▁et\t\t0.1315\n",
            "anticipation ▁et ▁om\t\t0.1345\n",
            "▁et ▁om ette\t\t0.1175\n",
            "▁om ette z\t\t0.1457\n",
            "ette z ▁role\t\t0.1353\n",
            "z ▁role ▁ne\t\t0.1723\n",
            "▁role ▁ne f\t\t0.1461\n",
            "▁ne f aste\t\t0.1612\n",
            "f aste ▁des\t\t0.0754\n",
            "aste ▁des information\t\t0.0653\n",
            "▁des information ▁anti\t\t0.1503\n",
            "information ▁anti -\t\t0.2101\n",
            "▁anti - nu\t\t-0.2484\n",
            "- nu cle\t\t-0.3998\n",
            "nu cle aires\t\t-0.3759\n",
            "cle aires ▁sur\t\t0.0912\n",
            "aires ▁sur ▁citoyens\t\t0.3654\n",
            "▁sur ▁citoyens </s>\t\t0.2498\n",
            "\n",
            "Predicted Class: nucléaire\n",
            "True Class: nucléaire\n",
            "Predicted Probability: 4.621401786804199\n",
            "Target Attribution Score: 1.6811769544077204\n",
            "\n",
            "==================================================\n",
            "\n",
            "Sentence: « La décroissance n'est pas une option pour les pays pauvres ou riches face au changement climatique » ou des enjeux du découplage croissance-co2 \n",
            "https://t.co/3igWtjLj3N\n",
            "Target Class: avion\n",
            "Token\t\tAttribution Score\n",
            "--------------------------\n",
            "<s>\t\t0.0000\n",
            "▁de\t\t-0.3612\n",
            "croissance\t\t0.2285\n",
            "▁n\t\t0.3046\n",
            "'\t\t0.3159\n",
            "est\t\t0.3707\n",
            "▁pas\t\t0.4211\n",
            "▁une\t\t0.2333\n",
            "▁option\t\t0.0356\n",
            "▁pour\t\t-0.0226\n",
            "▁pays\t\t0.0805\n",
            "▁pauvres\t\t0.0822\n",
            "▁ou\t\t0.0723\n",
            "▁riches\t\t0.0976\n",
            "▁face\t\t0.0511\n",
            "▁au\t\t0.0501\n",
            "▁changement\t\t0.0470\n",
            "▁climatique\t\t0.0818\n",
            "▁ou\t\t0.0281\n",
            "▁enjeux\t\t0.0435\n",
            "▁de\t\t0.0779\n",
            "coup\t\t0.1140\n",
            "lage\t\t0.1795\n",
            "▁croissance\t\t0.1870\n",
            "-\t\t0.1683\n",
            "co\t\t0.1844\n",
            "</s>\t\t0.2459\n",
            "\n",
            "Bigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁de\t\t-0.3612\n",
            "▁de croissance\t\t-0.1327\n",
            "croissance ▁n\t\t0.5331\n",
            "▁n '\t\t0.6205\n",
            "' est\t\t0.6866\n",
            "est ▁pas\t\t0.7918\n",
            "▁pas ▁une\t\t0.6545\n",
            "▁une ▁option\t\t0.2689\n",
            "▁option ▁pour\t\t0.0130\n",
            "▁pour ▁pays\t\t0.0578\n",
            "▁pays ▁pauvres\t\t0.1627\n",
            "▁pauvres ▁ou\t\t0.1545\n",
            "▁ou ▁riches\t\t0.1698\n",
            "▁riches ▁face\t\t0.1487\n",
            "▁face ▁au\t\t0.1012\n",
            "▁au ▁changement\t\t0.0971\n",
            "▁changement ▁climatique\t\t0.1288\n",
            "▁climatique ▁ou\t\t0.1099\n",
            "▁ou ▁enjeux\t\t0.0716\n",
            "▁enjeux ▁de\t\t0.1214\n",
            "▁de coup\t\t0.1920\n",
            "coup lage\t\t0.2935\n",
            "lage ▁croissance\t\t0.3665\n",
            "▁croissance -\t\t0.3553\n",
            "- co\t\t0.3527\n",
            "co </s>\t\t0.4303\n",
            "\n",
            "Trigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁de croissance\t\t-0.1327\n",
            "▁de croissance ▁n\t\t0.1719\n",
            "croissance ▁n '\t\t0.8490\n",
            "▁n ' est\t\t0.9912\n",
            "' est ▁pas\t\t1.1077\n",
            "est ▁pas ▁une\t\t1.0251\n",
            "▁pas ▁une ▁option\t\t0.6901\n",
            "▁une ▁option ▁pour\t\t0.2463\n",
            "▁option ▁pour ▁pays\t\t0.0934\n",
            "▁pour ▁pays ▁pauvres\t\t0.1400\n",
            "▁pays ▁pauvres ▁ou\t\t0.2350\n",
            "▁pauvres ▁ou ▁riches\t\t0.2521\n",
            "▁ou ▁riches ▁face\t\t0.2209\n",
            "▁riches ▁face ▁au\t\t0.1987\n",
            "▁face ▁au ▁changement\t\t0.1482\n",
            "▁au ▁changement ▁climatique\t\t0.1789\n",
            "▁changement ▁climatique ▁ou\t\t0.1570\n",
            "▁climatique ▁ou ▁enjeux\t\t0.1534\n",
            "▁ou ▁enjeux ▁de\t\t0.1495\n",
            "▁enjeux ▁de coup\t\t0.2354\n",
            "▁de coup lage\t\t0.3714\n",
            "coup lage ▁croissance\t\t0.4805\n",
            "lage ▁croissance -\t\t0.5348\n",
            "▁croissance - co\t\t0.5397\n",
            "- co </s>\t\t0.5986\n",
            "\n",
            "Predicted Class: décroissance\n",
            "True Class: décroissance\n",
            "Predicted Probability: 3.1471426486968994\n",
            "Target Attribution Score: 3.3171242917687653\n",
            "\n",
            "==================================================\n",
            "\n",
            "Target Class: décroissance\n",
            "Token\t\tAttribution Score\n",
            "--------------------------\n",
            "<s>\t\t0.0000\n",
            "▁de\t\t0.2794\n",
            "croissance\t\t0.1624\n",
            "▁n\t\t0.2546\n",
            "'\t\t0.2736\n",
            "est\t\t-0.0010\n",
            "▁pas\t\t0.1648\n",
            "▁une\t\t0.3246\n",
            "▁option\t\t0.0749\n",
            "▁pour\t\t0.1697\n",
            "▁pays\t\t0.0598\n",
            "▁pauvres\t\t0.1643\n",
            "▁ou\t\t0.1595\n",
            "▁riches\t\t0.1220\n",
            "▁face\t\t-0.1888\n",
            "▁au\t\t0.0382\n",
            "▁changement\t\t0.2255\n",
            "▁climatique\t\t0.1033\n",
            "▁ou\t\t0.0607\n",
            "▁enjeux\t\t0.1428\n",
            "▁de\t\t0.0793\n",
            "coup\t\t-0.0720\n",
            "lage\t\t0.0043\n",
            "▁croissance\t\t0.1593\n",
            "-\t\t0.3830\n",
            "co\t\t0.3871\n",
            "</s>\t\t-0.2489\n",
            "\n",
            "Bigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁de\t\t0.2794\n",
            "▁de croissance\t\t0.4418\n",
            "croissance ▁n\t\t0.4170\n",
            "▁n '\t\t0.5283\n",
            "' est\t\t0.2726\n",
            "est ▁pas\t\t0.1638\n",
            "▁pas ▁une\t\t0.4894\n",
            "▁une ▁option\t\t0.3996\n",
            "▁option ▁pour\t\t0.2446\n",
            "▁pour ▁pays\t\t0.2295\n",
            "▁pays ▁pauvres\t\t0.2241\n",
            "▁pauvres ▁ou\t\t0.3237\n",
            "▁ou ▁riches\t\t0.2815\n",
            "▁riches ▁face\t\t-0.0667\n",
            "▁face ▁au\t\t-0.1506\n",
            "▁au ▁changement\t\t0.2637\n",
            "▁changement ▁climatique\t\t0.3288\n",
            "▁climatique ▁ou\t\t0.1640\n",
            "▁ou ▁enjeux\t\t0.2036\n",
            "▁enjeux ▁de\t\t0.2221\n",
            "▁de coup\t\t0.0073\n",
            "coup lage\t\t-0.0677\n",
            "lage ▁croissance\t\t0.1635\n",
            "▁croissance -\t\t0.5422\n",
            "- co\t\t0.7701\n",
            "co </s>\t\t0.1382\n",
            "\n",
            "Trigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁de croissance\t\t0.4418\n",
            "▁de croissance ▁n\t\t0.6964\n",
            "croissance ▁n '\t\t0.6906\n",
            "▁n ' est\t\t0.5273\n",
            "' est ▁pas\t\t0.4374\n",
            "est ▁pas ▁une\t\t0.4884\n",
            "▁pas ▁une ▁option\t\t0.5643\n",
            "▁une ▁option ▁pour\t\t0.5692\n",
            "▁option ▁pour ▁pays\t\t0.3044\n",
            "▁pour ▁pays ▁pauvres\t\t0.3938\n",
            "▁pays ▁pauvres ▁ou\t\t0.3835\n",
            "▁pauvres ▁ou ▁riches\t\t0.4458\n",
            "▁ou ▁riches ▁face\t\t0.0927\n",
            "▁riches ▁face ▁au\t\t-0.0285\n",
            "▁face ▁au ▁changement\t\t0.0750\n",
            "▁au ▁changement ▁climatique\t\t0.3670\n",
            "▁changement ▁climatique ▁ou\t\t0.3895\n",
            "▁climatique ▁ou ▁enjeux\t\t0.3068\n",
            "▁ou ▁enjeux ▁de\t\t0.2828\n",
            "▁enjeux ▁de coup\t\t0.1501\n",
            "▁de coup lage\t\t0.0116\n",
            "coup lage ▁croissance\t\t0.0916\n",
            "lage ▁croissance -\t\t0.5465\n",
            "▁croissance - co\t\t0.9293\n",
            "- co </s>\t\t0.5212\n",
            "\n",
            "Predicted Class: décroissance\n",
            "True Class: décroissance\n",
            "Predicted Probability: 3.1471426486968994\n",
            "Target Attribution Score: 3.282468578263263\n",
            "\n",
            "==================================================\n",
            "\n",
            "Target Class: nucléaire\n",
            "Token\t\tAttribution Score\n",
            "--------------------------\n",
            "<s>\t\t0.0000\n",
            "▁de\t\t-0.6395\n",
            "croissance\t\t-0.5925\n",
            "▁n\t\t-0.0317\n",
            "'\t\t-0.0482\n",
            "est\t\t-0.0019\n",
            "▁pas\t\t0.0051\n",
            "▁une\t\t0.0240\n",
            "▁option\t\t-0.0373\n",
            "▁pour\t\t0.0163\n",
            "▁pays\t\t-0.0611\n",
            "▁pauvres\t\t-0.0507\n",
            "▁ou\t\t0.0221\n",
            "▁riches\t\t-0.1026\n",
            "▁face\t\t-0.1035\n",
            "▁au\t\t0.0222\n",
            "▁changement\t\t0.1233\n",
            "▁climatique\t\t0.0194\n",
            "▁ou\t\t0.0712\n",
            "▁enjeux\t\t0.0779\n",
            "▁de\t\t0.0119\n",
            "coup\t\t-0.1302\n",
            "lage\t\t-0.1894\n",
            "▁croissance\t\t-0.0495\n",
            "-\t\t-0.2373\n",
            "co\t\t-0.2359\n",
            "</s>\t\t-0.1086\n",
            "\n",
            "Bigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁de\t\t-0.6395\n",
            "▁de croissance\t\t-1.2320\n",
            "croissance ▁n\t\t-0.6242\n",
            "▁n '\t\t-0.0799\n",
            "' est\t\t-0.0501\n",
            "est ▁pas\t\t0.0032\n",
            "▁pas ▁une\t\t0.0290\n",
            "▁une ▁option\t\t-0.0134\n",
            "▁option ▁pour\t\t-0.0210\n",
            "▁pour ▁pays\t\t-0.0448\n",
            "▁pays ▁pauvres\t\t-0.1118\n",
            "▁pauvres ▁ou\t\t-0.0287\n",
            "▁ou ▁riches\t\t-0.0805\n",
            "▁riches ▁face\t\t-0.2061\n",
            "▁face ▁au\t\t-0.0813\n",
            "▁au ▁changement\t\t0.1455\n",
            "▁changement ▁climatique\t\t0.1426\n",
            "▁climatique ▁ou\t\t0.0905\n",
            "▁ou ▁enjeux\t\t0.1491\n",
            "▁enjeux ▁de\t\t0.0898\n",
            "▁de coup\t\t-0.1183\n",
            "coup lage\t\t-0.3196\n",
            "lage ▁croissance\t\t-0.2388\n",
            "▁croissance -\t\t-0.2868\n",
            "- co\t\t-0.4733\n",
            "co </s>\t\t-0.3445\n",
            "\n",
            "Trigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁de croissance\t\t-1.2320\n",
            "▁de croissance ▁n\t\t-1.2636\n",
            "croissance ▁n '\t\t-0.6724\n",
            "▁n ' est\t\t-0.0818\n",
            "' est ▁pas\t\t-0.0450\n",
            "est ▁pas ▁une\t\t0.0271\n",
            "▁pas ▁une ▁option\t\t-0.0083\n",
            "▁une ▁option ▁pour\t\t0.0029\n",
            "▁option ▁pour ▁pays\t\t-0.0822\n",
            "▁pour ▁pays ▁pauvres\t\t-0.0955\n",
            "▁pays ▁pauvres ▁ou\t\t-0.0898\n",
            "▁pauvres ▁ou ▁riches\t\t-0.1312\n",
            "▁ou ▁riches ▁face\t\t-0.1841\n",
            "▁riches ▁face ▁au\t\t-0.1839\n",
            "▁face ▁au ▁changement\t\t0.0419\n",
            "▁au ▁changement ▁climatique\t\t0.1648\n",
            "▁changement ▁climatique ▁ou\t\t0.2138\n",
            "▁climatique ▁ou ▁enjeux\t\t0.1684\n",
            "▁ou ▁enjeux ▁de\t\t0.1610\n",
            "▁enjeux ▁de coup\t\t-0.0404\n",
            "▁de coup lage\t\t-0.3077\n",
            "coup lage ▁croissance\t\t-0.3691\n",
            "lage ▁croissance -\t\t-0.4762\n",
            "▁croissance - co\t\t-0.5227\n",
            "- co </s>\t\t-0.5818\n",
            "\n",
            "Predicted Class: décroissance\n",
            "True Class: décroissance\n",
            "Predicted Probability: 3.1471426486968994\n",
            "Target Attribution Score: -2.2267039224090275\n",
            "\n",
            "==================================================\n",
            "\n",
            "Target Class: viande\n",
            "Token\t\tAttribution Score\n",
            "--------------------------\n",
            "<s>\t\t0.0000\n",
            "▁de\t\t0.5993\n",
            "croissance\t\t0.3299\n",
            "▁n\t\t0.1138\n",
            "'\t\t0.1667\n",
            "est\t\t0.2053\n",
            "▁pas\t\t0.1223\n",
            "▁une\t\t0.1112\n",
            "▁option\t\t0.1131\n",
            "▁pour\t\t0.0709\n",
            "▁pays\t\t0.1125\n",
            "▁pauvres\t\t0.0949\n",
            "▁ou\t\t0.0169\n",
            "▁riches\t\t0.0823\n",
            "▁face\t\t0.2285\n",
            "▁au\t\t-0.0014\n",
            "▁changement\t\t-0.0529\n",
            "▁climatique\t\t-0.0017\n",
            "▁ou\t\t-0.0413\n",
            "▁enjeux\t\t-0.0117\n",
            "▁de\t\t0.0442\n",
            "coup\t\t0.2275\n",
            "lage\t\t0.1034\n",
            "▁croissance\t\t-0.0382\n",
            "-\t\t0.3840\n",
            "co\t\t0.3197\n",
            "</s>\t\t-0.0524\n",
            "\n",
            "Bigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁de\t\t0.5993\n",
            "▁de croissance\t\t0.9293\n",
            "croissance ▁n\t\t0.4437\n",
            "▁n '\t\t0.2805\n",
            "' est\t\t0.3720\n",
            "est ▁pas\t\t0.3276\n",
            "▁pas ▁une\t\t0.2336\n",
            "▁une ▁option\t\t0.2244\n",
            "▁option ▁pour\t\t0.1840\n",
            "▁pour ▁pays\t\t0.1834\n",
            "▁pays ▁pauvres\t\t0.2074\n",
            "▁pauvres ▁ou\t\t0.1117\n",
            "▁ou ▁riches\t\t0.0991\n",
            "▁riches ▁face\t\t0.3108\n",
            "▁face ▁au\t\t0.2271\n",
            "▁au ▁changement\t\t-0.0543\n",
            "▁changement ▁climatique\t\t-0.0547\n",
            "▁climatique ▁ou\t\t-0.0430\n",
            "▁ou ▁enjeux\t\t-0.0531\n",
            "▁enjeux ▁de\t\t0.0325\n",
            "▁de coup\t\t0.2717\n",
            "coup lage\t\t0.3310\n",
            "lage ▁croissance\t\t0.0652\n",
            "▁croissance -\t\t0.3457\n",
            "- co\t\t0.7037\n",
            "co </s>\t\t0.2674\n",
            "\n",
            "Trigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁de croissance\t\t0.9293\n",
            "▁de croissance ▁n\t\t1.0430\n",
            "croissance ▁n '\t\t0.6104\n",
            "▁n ' est\t\t0.4858\n",
            "' est ▁pas\t\t0.4943\n",
            "est ▁pas ▁une\t\t0.4389\n",
            "▁pas ▁une ▁option\t\t0.3467\n",
            "▁une ▁option ▁pour\t\t0.2953\n",
            "▁option ▁pour ▁pays\t\t0.2965\n",
            "▁pour ▁pays ▁pauvres\t\t0.2783\n",
            "▁pays ▁pauvres ▁ou\t\t0.2242\n",
            "▁pauvres ▁ou ▁riches\t\t0.1940\n",
            "▁ou ▁riches ▁face\t\t0.3276\n",
            "▁riches ▁face ▁au\t\t0.3094\n",
            "▁face ▁au ▁changement\t\t0.1742\n",
            "▁au ▁changement ▁climatique\t\t-0.0560\n",
            "▁changement ▁climatique ▁ou\t\t-0.0960\n",
            "▁climatique ▁ou ▁enjeux\t\t-0.0548\n",
            "▁ou ▁enjeux ▁de\t\t-0.0089\n",
            "▁enjeux ▁de coup\t\t0.2600\n",
            "▁de coup lage\t\t0.3752\n",
            "coup lage ▁croissance\t\t0.2927\n",
            "lage ▁croissance -\t\t0.4492\n",
            "▁croissance - co\t\t0.6655\n",
            "- co </s>\t\t0.6514\n",
            "\n",
            "Predicted Class: décroissance\n",
            "True Class: décroissance\n",
            "Predicted Probability: 3.1471426486968994\n",
            "Target Attribution Score: 3.2468573953931448\n",
            "\n",
            "==================================================\n",
            "\n",
            "Sentence: Vous demandiez au début pourquoi cette évolution positive de l'opinion sur le nucléaire.\n",
            "Parce que le climat, la crise énergétique déjà.\n",
            "Et parce que les citoyens, après des décennies de désinformation antinuc, commencent à comprendre qu'un déchet nucléaire ne ressemble pas à ça.\n",
            "Target Class: avion\n",
            "Token\t\tAttribution Score\n",
            "--------------------------\n",
            "<s>\t\t0.0000\n",
            "▁de\t\t-0.1656\n",
            "mand\t\t-0.0402\n",
            "iez\t\t0.4711\n",
            "▁au\t\t0.0784\n",
            "▁de\t\t0.0474\n",
            "but\t\t-0.0243\n",
            "▁pourquoi\t\t0.0154\n",
            "▁cette\t\t-0.2838\n",
            "▁e\t\t-0.3389\n",
            "volution\t\t-0.1609\n",
            "▁positive\t\t-0.0268\n",
            "▁l\t\t-0.0499\n",
            "'\t\t-0.0054\n",
            "opinion\t\t-0.1125\n",
            "▁sur\t\t-0.0205\n",
            "▁nu\t\t-0.0445\n",
            "cle\t\t-0.0534\n",
            "aire\t\t-0.0313\n",
            "▁Parce\t\t0.0055\n",
            "▁que\t\t-0.0091\n",
            "▁climat\t\t-0.0317\n",
            "▁crise\t\t-0.0393\n",
            "▁en\t\t-0.0120\n",
            "er\t\t-0.0134\n",
            "ge\t\t0.0118\n",
            "tique\t\t-0.0139\n",
            "▁deja\t\t-0.0594\n",
            "▁Et\t\t0.0118\n",
            "▁parce\t\t0.0269\n",
            "▁que\t\t-0.0180\n",
            "▁citoyens\t\t-0.0277\n",
            "▁apres\t\t-0.1289\n",
            "▁de\t\t-0.0471\n",
            "ce\t\t0.0156\n",
            "nni\t\t0.0139\n",
            "es\t\t0.0199\n",
            "▁des\t\t-0.0231\n",
            "information\t\t-0.0068\n",
            "▁anti\t\t-0.0182\n",
            "nu\t\t0.0162\n",
            "c\t\t0.0170\n",
            "▁commencent\t\t0.0009\n",
            "▁a\t\t-0.1142\n",
            "▁comprendre\t\t-0.0527\n",
            "▁qu\t\t-0.1733\n",
            "'\t\t-0.0974\n",
            "un\t\t-0.1492\n",
            "▁de\t\t-0.1365\n",
            "chet\t\t-0.0103\n",
            "▁nu\t\t0.0036\n",
            "cle\t\t-0.0145\n",
            "aire\t\t-0.0337\n",
            "▁ne\t\t-0.2920\n",
            "▁ressemble\t\t-0.0142\n",
            "▁pas\t\t-0.4565\n",
            "▁a\t\t-0.1987\n",
            "▁ca\t\t-0.1686\n",
            "</s>\t\t0.0832\n",
            "\n",
            "Bigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁de\t\t-0.1656\n",
            "▁de mand\t\t-0.2058\n",
            "mand iez\t\t0.4309\n",
            "iez ▁au\t\t0.5495\n",
            "▁au ▁de\t\t0.1258\n",
            "▁de but\t\t0.0232\n",
            "but ▁pourquoi\t\t-0.0088\n",
            "▁pourquoi ▁cette\t\t-0.2684\n",
            "▁cette ▁e\t\t-0.6227\n",
            "▁e volution\t\t-0.4998\n",
            "volution ▁positive\t\t-0.1877\n",
            "▁positive ▁l\t\t-0.0767\n",
            "▁l '\t\t-0.0553\n",
            "' opinion\t\t-0.1179\n",
            "opinion ▁sur\t\t-0.1330\n",
            "▁sur ▁nu\t\t-0.0650\n",
            "▁nu cle\t\t-0.0979\n",
            "cle aire\t\t-0.0847\n",
            "aire ▁Parce\t\t-0.0258\n",
            "▁Parce ▁que\t\t-0.0036\n",
            "▁que ▁climat\t\t-0.0408\n",
            "▁climat ▁crise\t\t-0.0710\n",
            "▁crise ▁en\t\t-0.0513\n",
            "▁en er\t\t-0.0255\n",
            "er ge\t\t-0.0016\n",
            "ge tique\t\t-0.0021\n",
            "tique ▁deja\t\t-0.0733\n",
            "▁deja ▁Et\t\t-0.0476\n",
            "▁Et ▁parce\t\t0.0387\n",
            "▁parce ▁que\t\t0.0088\n",
            "▁que ▁citoyens\t\t-0.0457\n",
            "▁citoyens ▁apres\t\t-0.1566\n",
            "▁apres ▁de\t\t-0.1760\n",
            "▁de ce\t\t-0.0315\n",
            "ce nni\t\t0.0295\n",
            "nni es\t\t0.0339\n",
            "es ▁des\t\t-0.0032\n",
            "▁des information\t\t-0.0299\n",
            "information ▁anti\t\t-0.0250\n",
            "▁anti nu\t\t-0.0020\n",
            "nu c\t\t0.0332\n",
            "c ▁commencent\t\t0.0179\n",
            "▁commencent ▁a\t\t-0.1133\n",
            "▁a ▁comprendre\t\t-0.1669\n",
            "▁comprendre ▁qu\t\t-0.2261\n",
            "▁qu '\t\t-0.2707\n",
            "' un\t\t-0.2466\n",
            "un ▁de\t\t-0.2857\n",
            "▁de chet\t\t-0.1468\n",
            "chet ▁nu\t\t-0.0066\n",
            "▁nu cle\t\t-0.0109\n",
            "cle aire\t\t-0.0483\n",
            "aire ▁ne\t\t-0.3257\n",
            "▁ne ▁ressemble\t\t-0.3063\n",
            "▁ressemble ▁pas\t\t-0.4707\n",
            "▁pas ▁a\t\t-0.6552\n",
            "▁a ▁ca\t\t-0.3674\n",
            "▁ca </s>\t\t-0.0854\n",
            "\n",
            "Trigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁de mand\t\t-0.2058\n",
            "▁de mand iez\t\t0.2654\n",
            "mand iez ▁au\t\t0.5093\n",
            "iez ▁au ▁de\t\t0.5970\n",
            "▁au ▁de but\t\t0.1016\n",
            "▁de but ▁pourquoi\t\t0.0386\n",
            "but ▁pourquoi ▁cette\t\t-0.2927\n",
            "▁pourquoi ▁cette ▁e\t\t-0.6073\n",
            "▁cette ▁e volution\t\t-0.7836\n",
            "▁e volution ▁positive\t\t-0.5266\n",
            "volution ▁positive ▁l\t\t-0.2376\n",
            "▁positive ▁l '\t\t-0.0821\n",
            "▁l ' opinion\t\t-0.1678\n",
            "' opinion ▁sur\t\t-0.1384\n",
            "opinion ▁sur ▁nu\t\t-0.1775\n",
            "▁sur ▁nu cle\t\t-0.1184\n",
            "▁nu cle aire\t\t-0.1292\n",
            "cle aire ▁Parce\t\t-0.0792\n",
            "aire ▁Parce ▁que\t\t-0.0349\n",
            "▁Parce ▁que ▁climat\t\t-0.0353\n",
            "▁que ▁climat ▁crise\t\t-0.0801\n",
            "▁climat ▁crise ▁en\t\t-0.0831\n",
            "▁crise ▁en er\t\t-0.0648\n",
            "▁en er ge\t\t-0.0136\n",
            "er ge tique\t\t-0.0155\n",
            "ge tique ▁deja\t\t-0.0615\n",
            "tique ▁deja ▁Et\t\t-0.0615\n",
            "▁deja ▁Et ▁parce\t\t-0.0208\n",
            "▁Et ▁parce ▁que\t\t0.0206\n",
            "▁parce ▁que ▁citoyens\t\t-0.0188\n",
            "▁que ▁citoyens ▁apres\t\t-0.1746\n",
            "▁citoyens ▁apres ▁de\t\t-0.2036\n",
            "▁apres ▁de ce\t\t-0.1604\n",
            "▁de ce nni\t\t-0.0176\n",
            "ce nni es\t\t0.0495\n",
            "nni es ▁des\t\t0.0108\n",
            "es ▁des information\t\t-0.0100\n",
            "▁des information ▁anti\t\t-0.0481\n",
            "information ▁anti nu\t\t-0.0088\n",
            "▁anti nu c\t\t0.0150\n",
            "nu c ▁commencent\t\t0.0341\n",
            "c ▁commencent ▁a\t\t-0.0963\n",
            "▁commencent ▁a ▁comprendre\t\t-0.1660\n",
            "▁a ▁comprendre ▁qu\t\t-0.3403\n",
            "▁comprendre ▁qu '\t\t-0.3235\n",
            "▁qu ' un\t\t-0.4199\n",
            "' un ▁de\t\t-0.3831\n",
            "un ▁de chet\t\t-0.2960\n",
            "▁de chet ▁nu\t\t-0.1432\n",
            "chet ▁nu cle\t\t-0.0212\n",
            "▁nu cle aire\t\t-0.0446\n",
            "cle aire ▁ne\t\t-0.3403\n",
            "aire ▁ne ▁ressemble\t\t-0.3400\n",
            "▁ne ▁ressemble ▁pas\t\t-0.7628\n",
            "▁ressemble ▁pas ▁a\t\t-0.6694\n",
            "▁pas ▁a ▁ca\t\t-0.8238\n",
            "▁a ▁ca </s>\t\t-0.2841\n",
            "\n",
            "Predicted Class: nucléaire\n",
            "True Class: nucléaire\n",
            "Predicted Probability: 4.630938529968262\n",
            "Target Attribution Score: -2.8797582370724717\n",
            "\n",
            "==================================================\n",
            "\n",
            "Target Class: décroissance\n",
            "Token\t\tAttribution Score\n",
            "--------------------------\n",
            "<s>\t\t0.0000\n",
            "▁de\t\t-0.0139\n",
            "mand\t\t-0.0202\n",
            "iez\t\t-0.0343\n",
            "▁au\t\t-0.0156\n",
            "▁de\t\t-0.0498\n",
            "but\t\t-0.0354\n",
            "▁pourquoi\t\t-0.0113\n",
            "▁cette\t\t0.0271\n",
            "▁e\t\t0.0527\n",
            "volution\t\t0.0281\n",
            "▁positive\t\t0.0046\n",
            "▁l\t\t0.0187\n",
            "'\t\t-0.0041\n",
            "opinion\t\t0.0262\n",
            "▁sur\t\t-0.0301\n",
            "▁nu\t\t-0.1621\n",
            "cle\t\t-0.1728\n",
            "aire\t\t-0.1753\n",
            "▁Parce\t\t-0.0012\n",
            "▁que\t\t-0.0178\n",
            "▁climat\t\t-0.0109\n",
            "▁crise\t\t-0.0081\n",
            "▁en\t\t0.0327\n",
            "er\t\t0.0153\n",
            "ge\t\t-0.0043\n",
            "tique\t\t-0.0166\n",
            "▁deja\t\t-0.0010\n",
            "▁Et\t\t0.0058\n",
            "▁parce\t\t-0.0311\n",
            "▁que\t\t-0.0059\n",
            "▁citoyens\t\t-0.0064\n",
            "▁apres\t\t-0.0144\n",
            "▁de\t\t-0.0388\n",
            "ce\t\t-0.0040\n",
            "nni\t\t0.0268\n",
            "es\t\t-0.0316\n",
            "▁des\t\t-0.0307\n",
            "information\t\t-0.0247\n",
            "▁anti\t\t-0.0581\n",
            "nu\t\t-0.0571\n",
            "c\t\t-0.0195\n",
            "▁commencent\t\t0.0001\n",
            "▁a\t\t0.0032\n",
            "▁comprendre\t\t-0.0218\n",
            "▁qu\t\t-0.0126\n",
            "'\t\t-0.0154\n",
            "un\t\t0.0114\n",
            "▁de\t\t0.0041\n",
            "chet\t\t0.0718\n",
            "▁nu\t\t-0.5537\n",
            "cle\t\t-0.5193\n",
            "aire\t\t-0.5430\n",
            "▁ne\t\t-0.0726\n",
            "▁ressemble\t\t-0.0271\n",
            "▁pas\t\t-0.0125\n",
            "▁a\t\t0.0300\n",
            "▁ca\t\t-0.0136\n",
            "</s>\t\t-0.0348\n",
            "\n",
            "Bigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁de\t\t-0.0139\n",
            "▁de mand\t\t-0.0341\n",
            "mand iez\t\t-0.0545\n",
            "iez ▁au\t\t-0.0499\n",
            "▁au ▁de\t\t-0.0654\n",
            "▁de but\t\t-0.0852\n",
            "but ▁pourquoi\t\t-0.0467\n",
            "▁pourquoi ▁cette\t\t0.0158\n",
            "▁cette ▁e\t\t0.0798\n",
            "▁e volution\t\t0.0808\n",
            "volution ▁positive\t\t0.0327\n",
            "▁positive ▁l\t\t0.0233\n",
            "▁l '\t\t0.0146\n",
            "' opinion\t\t0.0221\n",
            "opinion ▁sur\t\t-0.0038\n",
            "▁sur ▁nu\t\t-0.1922\n",
            "▁nu cle\t\t-0.3349\n",
            "cle aire\t\t-0.3481\n",
            "aire ▁Parce\t\t-0.1765\n",
            "▁Parce ▁que\t\t-0.0189\n",
            "▁que ▁climat\t\t-0.0287\n",
            "▁climat ▁crise\t\t-0.0190\n",
            "▁crise ▁en\t\t0.0247\n",
            "▁en er\t\t0.0480\n",
            "er ge\t\t0.0110\n",
            "ge tique\t\t-0.0209\n",
            "tique ▁deja\t\t-0.0176\n",
            "▁deja ▁Et\t\t0.0048\n",
            "▁Et ▁parce\t\t-0.0253\n",
            "▁parce ▁que\t\t-0.0370\n",
            "▁que ▁citoyens\t\t-0.0123\n",
            "▁citoyens ▁apres\t\t-0.0208\n",
            "▁apres ▁de\t\t-0.0532\n",
            "▁de ce\t\t-0.0428\n",
            "ce nni\t\t0.0228\n",
            "nni es\t\t-0.0048\n",
            "es ▁des\t\t-0.0623\n",
            "▁des information\t\t-0.0554\n",
            "information ▁anti\t\t-0.0828\n",
            "▁anti nu\t\t-0.1152\n",
            "nu c\t\t-0.0766\n",
            "c ▁commencent\t\t-0.0194\n",
            "▁commencent ▁a\t\t0.0033\n",
            "▁a ▁comprendre\t\t-0.0186\n",
            "▁comprendre ▁qu\t\t-0.0344\n",
            "▁qu '\t\t-0.0280\n",
            "' un\t\t-0.0040\n",
            "un ▁de\t\t0.0155\n",
            "▁de chet\t\t0.0760\n",
            "chet ▁nu\t\t-0.4818\n",
            "▁nu cle\t\t-1.0730\n",
            "cle aire\t\t-1.0624\n",
            "aire ▁ne\t\t-0.6156\n",
            "▁ne ▁ressemble\t\t-0.0997\n",
            "▁ressemble ▁pas\t\t-0.0395\n",
            "▁pas ▁a\t\t0.0175\n",
            "▁a ▁ca\t\t0.0163\n",
            "▁ca </s>\t\t-0.0484\n",
            "\n",
            "Trigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁de mand\t\t-0.0341\n",
            "▁de mand iez\t\t-0.0685\n",
            "mand iez ▁au\t\t-0.0701\n",
            "iez ▁au ▁de\t\t-0.0997\n",
            "▁au ▁de but\t\t-0.1008\n",
            "▁de but ▁pourquoi\t\t-0.0965\n",
            "but ▁pourquoi ▁cette\t\t-0.0197\n",
            "▁pourquoi ▁cette ▁e\t\t0.0685\n",
            "▁cette ▁e volution\t\t0.1079\n",
            "▁e volution ▁positive\t\t0.0854\n",
            "volution ▁positive ▁l\t\t0.0514\n",
            "▁positive ▁l '\t\t0.0192\n",
            "▁l ' opinion\t\t0.0408\n",
            "' opinion ▁sur\t\t-0.0079\n",
            "opinion ▁sur ▁nu\t\t-0.1660\n",
            "▁sur ▁nu cle\t\t-0.3650\n",
            "▁nu cle aire\t\t-0.5102\n",
            "cle aire ▁Parce\t\t-0.3493\n",
            "aire ▁Parce ▁que\t\t-0.1942\n",
            "▁Parce ▁que ▁climat\t\t-0.0298\n",
            "▁que ▁climat ▁crise\t\t-0.0367\n",
            "▁climat ▁crise ▁en\t\t0.0138\n",
            "▁crise ▁en er\t\t0.0400\n",
            "▁en er ge\t\t0.0437\n",
            "er ge tique\t\t-0.0056\n",
            "ge tique ▁deja\t\t-0.0219\n",
            "tique ▁deja ▁Et\t\t-0.0118\n",
            "▁deja ▁Et ▁parce\t\t-0.0263\n",
            "▁Et ▁parce ▁que\t\t-0.0312\n",
            "▁parce ▁que ▁citoyens\t\t-0.0434\n",
            "▁que ▁citoyens ▁apres\t\t-0.0267\n",
            "▁citoyens ▁apres ▁de\t\t-0.0596\n",
            "▁apres ▁de ce\t\t-0.0572\n",
            "▁de ce nni\t\t-0.0160\n",
            "ce nni es\t\t-0.0088\n",
            "nni es ▁des\t\t-0.0355\n",
            "es ▁des information\t\t-0.0870\n",
            "▁des information ▁anti\t\t-0.1135\n",
            "information ▁anti nu\t\t-0.1399\n",
            "▁anti nu c\t\t-0.1347\n",
            "nu c ▁commencent\t\t-0.0765\n",
            "c ▁commencent ▁a\t\t-0.0162\n",
            "▁commencent ▁a ▁comprendre\t\t-0.0184\n",
            "▁a ▁comprendre ▁qu\t\t-0.0312\n",
            "▁comprendre ▁qu '\t\t-0.0498\n",
            "▁qu ' un\t\t-0.0166\n",
            "' un ▁de\t\t0.0001\n",
            "un ▁de chet\t\t0.0874\n",
            "▁de chet ▁nu\t\t-0.4777\n",
            "chet ▁nu cle\t\t-1.0012\n",
            "▁nu cle aire\t\t-1.6160\n",
            "cle aire ▁ne\t\t-1.1350\n",
            "aire ▁ne ▁ressemble\t\t-0.6427\n",
            "▁ne ▁ressemble ▁pas\t\t-0.1121\n",
            "▁ressemble ▁pas ▁a\t\t-0.0096\n",
            "▁pas ▁a ▁ca\t\t0.0039\n",
            "▁a ▁ca </s>\t\t-0.0185\n",
            "\n",
            "Predicted Class: nucléaire\n",
            "True Class: nucléaire\n",
            "Predicted Probability: 4.630938529968262\n",
            "Target Attribution Score: -2.5747456516732794\n",
            "\n",
            "==================================================\n",
            "\n",
            "Target Class: nucléaire\n",
            "Token\t\tAttribution Score\n",
            "--------------------------\n",
            "<s>\t\t0.0000\n",
            "▁de\t\t-0.0028\n",
            "mand\t\t-0.0111\n",
            "iez\t\t-0.0081\n",
            "▁au\t\t0.0113\n",
            "▁de\t\t0.0571\n",
            "but\t\t0.0409\n",
            "▁pourquoi\t\t0.0298\n",
            "▁cette\t\t0.0354\n",
            "▁e\t\t0.0495\n",
            "volution\t\t0.0024\n",
            "▁positive\t\t0.0059\n",
            "▁l\t\t0.0241\n",
            "'\t\t0.0244\n",
            "opinion\t\t0.0054\n",
            "▁sur\t\t0.0264\n",
            "▁nu\t\t0.1860\n",
            "cle\t\t0.1552\n",
            "aire\t\t0.1583\n",
            "▁Parce\t\t0.0089\n",
            "▁que\t\t0.0186\n",
            "▁climat\t\t0.0215\n",
            "▁crise\t\t0.0269\n",
            "▁en\t\t-0.0053\n",
            "er\t\t0.0133\n",
            "ge\t\t-0.0011\n",
            "tique\t\t0.0179\n",
            "▁deja\t\t0.0306\n",
            "▁Et\t\t0.0112\n",
            "▁parce\t\t0.0243\n",
            "▁que\t\t0.0218\n",
            "▁citoyens\t\t0.0278\n",
            "▁apres\t\t0.0411\n",
            "▁de\t\t0.0398\n",
            "ce\t\t0.0134\n",
            "nni\t\t0.0047\n",
            "es\t\t0.0254\n",
            "▁des\t\t0.0155\n",
            "information\t\t0.0240\n",
            "▁anti\t\t0.0705\n",
            "nu\t\t0.0481\n",
            "c\t\t0.0313\n",
            "▁commencent\t\t0.0183\n",
            "▁a\t\t0.0325\n",
            "▁comprendre\t\t0.0073\n",
            "▁qu\t\t0.0620\n",
            "'\t\t0.0612\n",
            "un\t\t0.0359\n",
            "▁de\t\t0.0850\n",
            "chet\t\t0.0017\n",
            "▁nu\t\t0.5699\n",
            "cle\t\t0.4819\n",
            "aire\t\t0.5272\n",
            "▁ne\t\t0.1476\n",
            "▁ressemble\t\t0.0435\n",
            "▁pas\t\t0.0985\n",
            "▁a\t\t0.0086\n",
            "▁ca\t\t0.0149\n",
            "</s>\t\t-0.0019\n",
            "\n",
            "Bigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁de\t\t-0.0028\n",
            "▁de mand\t\t-0.0139\n",
            "mand iez\t\t-0.0191\n",
            "iez ▁au\t\t0.0032\n",
            "▁au ▁de\t\t0.0684\n",
            "▁de but\t\t0.0981\n",
            "but ▁pourquoi\t\t0.0707\n",
            "▁pourquoi ▁cette\t\t0.0652\n",
            "▁cette ▁e\t\t0.0849\n",
            "▁e volution\t\t0.0519\n",
            "volution ▁positive\t\t0.0083\n",
            "▁positive ▁l\t\t0.0300\n",
            "▁l '\t\t0.0484\n",
            "' opinion\t\t0.0297\n",
            "opinion ▁sur\t\t0.0317\n",
            "▁sur ▁nu\t\t0.2123\n",
            "▁nu cle\t\t0.3412\n",
            "cle aire\t\t0.3135\n",
            "aire ▁Parce\t\t0.1672\n",
            "▁Parce ▁que\t\t0.0275\n",
            "▁que ▁climat\t\t0.0400\n",
            "▁climat ▁crise\t\t0.0483\n",
            "▁crise ▁en\t\t0.0216\n",
            "▁en er\t\t0.0079\n",
            "er ge\t\t0.0121\n",
            "ge tique\t\t0.0168\n",
            "tique ▁deja\t\t0.0486\n",
            "▁deja ▁Et\t\t0.0419\n",
            "▁Et ▁parce\t\t0.0355\n",
            "▁parce ▁que\t\t0.0461\n",
            "▁que ▁citoyens\t\t0.0496\n",
            "▁citoyens ▁apres\t\t0.0689\n",
            "▁apres ▁de\t\t0.0809\n",
            "▁de ce\t\t0.0532\n",
            "ce nni\t\t0.0181\n",
            "nni es\t\t0.0301\n",
            "es ▁des\t\t0.0409\n",
            "▁des information\t\t0.0395\n",
            "information ▁anti\t\t0.0945\n",
            "▁anti nu\t\t0.1186\n",
            "nu c\t\t0.0794\n",
            "c ▁commencent\t\t0.0496\n",
            "▁commencent ▁a\t\t0.0508\n",
            "▁a ▁comprendre\t\t0.0397\n",
            "▁comprendre ▁qu\t\t0.0693\n",
            "▁qu '\t\t0.1233\n",
            "' un\t\t0.0972\n",
            "un ▁de\t\t0.1209\n",
            "▁de chet\t\t0.0867\n",
            "chet ▁nu\t\t0.5717\n",
            "▁nu cle\t\t1.0518\n",
            "cle aire\t\t1.0091\n",
            "aire ▁ne\t\t0.6748\n",
            "▁ne ▁ressemble\t\t0.1910\n",
            "▁ressemble ▁pas\t\t0.1419\n",
            "▁pas ▁a\t\t0.1071\n",
            "▁a ▁ca\t\t0.0235\n",
            "▁ca </s>\t\t0.0130\n",
            "\n",
            "Trigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁de mand\t\t-0.0139\n",
            "▁de mand iez\t\t-0.0219\n",
            "mand iez ▁au\t\t-0.0079\n",
            "iez ▁au ▁de\t\t0.0603\n",
            "▁au ▁de but\t\t0.1093\n",
            "▁de but ▁pourquoi\t\t0.1278\n",
            "but ▁pourquoi ▁cette\t\t0.1061\n",
            "▁pourquoi ▁cette ▁e\t\t0.1147\n",
            "▁cette ▁e volution\t\t0.0873\n",
            "▁e volution ▁positive\t\t0.0579\n",
            "volution ▁positive ▁l\t\t0.0324\n",
            "▁positive ▁l '\t\t0.0544\n",
            "▁l ' opinion\t\t0.0538\n",
            "' opinion ▁sur\t\t0.0561\n",
            "opinion ▁sur ▁nu\t\t0.2177\n",
            "▁sur ▁nu cle\t\t0.3675\n",
            "▁nu cle aire\t\t0.4994\n",
            "cle aire ▁Parce\t\t0.3224\n",
            "aire ▁Parce ▁que\t\t0.1858\n",
            "▁Parce ▁que ▁climat\t\t0.0489\n",
            "▁que ▁climat ▁crise\t\t0.0669\n",
            "▁climat ▁crise ▁en\t\t0.0430\n",
            "▁crise ▁en er\t\t0.0348\n",
            "▁en er ge\t\t0.0068\n",
            "er ge tique\t\t0.0301\n",
            "ge tique ▁deja\t\t0.0474\n",
            "tique ▁deja ▁Et\t\t0.0598\n",
            "▁deja ▁Et ▁parce\t\t0.0661\n",
            "▁Et ▁parce ▁que\t\t0.0573\n",
            "▁parce ▁que ▁citoyens\t\t0.0739\n",
            "▁que ▁citoyens ▁apres\t\t0.0907\n",
            "▁citoyens ▁apres ▁de\t\t0.1087\n",
            "▁apres ▁de ce\t\t0.0943\n",
            "▁de ce nni\t\t0.0579\n",
            "ce nni es\t\t0.0435\n",
            "nni es ▁des\t\t0.0456\n",
            "es ▁des information\t\t0.0649\n",
            "▁des information ▁anti\t\t0.1100\n",
            "information ▁anti nu\t\t0.1426\n",
            "▁anti nu c\t\t0.1499\n",
            "nu c ▁commencent\t\t0.0977\n",
            "c ▁commencent ▁a\t\t0.0821\n",
            "▁commencent ▁a ▁comprendre\t\t0.0580\n",
            "▁a ▁comprendre ▁qu\t\t0.1018\n",
            "▁comprendre ▁qu '\t\t0.1305\n",
            "▁qu ' un\t\t0.1592\n",
            "' un ▁de\t\t0.1821\n",
            "un ▁de chet\t\t0.1226\n",
            "▁de chet ▁nu\t\t0.6566\n",
            "chet ▁nu cle\t\t1.0536\n",
            "▁nu cle aire\t\t1.5791\n",
            "cle aire ▁ne\t\t1.1567\n",
            "aire ▁ne ▁ressemble\t\t0.7183\n",
            "▁ne ▁ressemble ▁pas\t\t0.2895\n",
            "▁ressemble ▁pas ▁a\t\t0.1505\n",
            "▁pas ▁a ▁ca\t\t0.1220\n",
            "▁a ▁ca </s>\t\t0.0216\n",
            "\n",
            "Predicted Class: nucléaire\n",
            "True Class: nucléaire\n",
            "Predicted Probability: 4.630938529968262\n",
            "Target Attribution Score: 3.514322305487942\n",
            "\n",
            "==================================================\n",
            "\n",
            "Target Class: viande\n",
            "Token\t\tAttribution Score\n",
            "--------------------------\n",
            "<s>\t\t0.0000\n",
            "▁de\t\t0.0847\n",
            "mand\t\t0.0074\n",
            "iez\t\t0.0311\n",
            "▁au\t\t-0.0129\n",
            "▁de\t\t-0.0546\n",
            "but\t\t-0.0265\n",
            "▁pourquoi\t\t-0.0086\n",
            "▁cette\t\t-0.0987\n",
            "▁e\t\t-0.1373\n",
            "volution\t\t-0.0521\n",
            "▁positive\t\t-0.0150\n",
            "▁l\t\t-0.0548\n",
            "'\t\t-0.0315\n",
            "opinion\t\t-0.0199\n",
            "▁sur\t\t-0.0053\n",
            "▁nu\t\t-0.1739\n",
            "cle\t\t-0.1400\n",
            "aire\t\t-0.1319\n",
            "▁Parce\t\t0.0110\n",
            "▁que\t\t-0.0037\n",
            "▁climat\t\t-0.0047\n",
            "▁crise\t\t-0.0319\n",
            "▁en\t\t0.0077\n",
            "er\t\t-0.0214\n",
            "ge\t\t0.0239\n",
            "tique\t\t0.0060\n",
            "▁deja\t\t-0.0082\n",
            "▁Et\t\t0.0033\n",
            "▁parce\t\t0.0032\n",
            "▁que\t\t-0.0068\n",
            "▁citoyens\t\t-0.0078\n",
            "▁apres\t\t-0.0670\n",
            "▁de\t\t-0.0115\n",
            "ce\t\t-0.0214\n",
            "nni\t\t-0.0348\n",
            "es\t\t-0.0191\n",
            "▁des\t\t0.0134\n",
            "information\t\t0.0058\n",
            "▁anti\t\t-0.0458\n",
            "nu\t\t0.0384\n",
            "c\t\t-0.0144\n",
            "▁commencent\t\t0.0011\n",
            "▁a\t\t-0.0209\n",
            "▁comprendre\t\t-0.0068\n",
            "▁qu\t\t-0.0337\n",
            "'\t\t-0.0474\n",
            "un\t\t-0.0318\n",
            "▁de\t\t-0.1168\n",
            "chet\t\t-0.0534\n",
            "▁nu\t\t-0.5237\n",
            "cle\t\t-0.4579\n",
            "aire\t\t-0.5064\n",
            "▁ne\t\t-0.1677\n",
            "▁ressemble\t\t-0.0639\n",
            "▁pas\t\t-0.1584\n",
            "▁a\t\t-0.1023\n",
            "▁ca\t\t-0.1435\n",
            "</s>\t\t-0.1468\n",
            "\n",
            "Bigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁de\t\t0.0847\n",
            "▁de mand\t\t0.0921\n",
            "mand iez\t\t0.0385\n",
            "iez ▁au\t\t0.0182\n",
            "▁au ▁de\t\t-0.0675\n",
            "▁de but\t\t-0.0811\n",
            "but ▁pourquoi\t\t-0.0352\n",
            "▁pourquoi ▁cette\t\t-0.1073\n",
            "▁cette ▁e\t\t-0.2361\n",
            "▁e volution\t\t-0.1895\n",
            "volution ▁positive\t\t-0.0672\n",
            "▁positive ▁l\t\t-0.0699\n",
            "▁l '\t\t-0.0864\n",
            "' opinion\t\t-0.0514\n",
            "opinion ▁sur\t\t-0.0252\n",
            "▁sur ▁nu\t\t-0.1792\n",
            "▁nu cle\t\t-0.3139\n",
            "cle aire\t\t-0.2719\n",
            "aire ▁Parce\t\t-0.1208\n",
            "▁Parce ▁que\t\t0.0073\n",
            "▁que ▁climat\t\t-0.0084\n",
            "▁climat ▁crise\t\t-0.0366\n",
            "▁crise ▁en\t\t-0.0242\n",
            "▁en er\t\t-0.0137\n",
            "er ge\t\t0.0024\n",
            "ge tique\t\t0.0299\n",
            "tique ▁deja\t\t-0.0021\n",
            "▁deja ▁Et\t\t-0.0049\n",
            "▁Et ▁parce\t\t0.0064\n",
            "▁parce ▁que\t\t-0.0036\n",
            "▁que ▁citoyens\t\t-0.0146\n",
            "▁citoyens ▁apres\t\t-0.0748\n",
            "▁apres ▁de\t\t-0.0785\n",
            "▁de ce\t\t-0.0329\n",
            "ce nni\t\t-0.0562\n",
            "nni es\t\t-0.0539\n",
            "es ▁des\t\t-0.0057\n",
            "▁des information\t\t0.0192\n",
            "information ▁anti\t\t-0.0399\n",
            "▁anti nu\t\t-0.0074\n",
            "nu c\t\t0.0240\n",
            "c ▁commencent\t\t-0.0133\n",
            "▁commencent ▁a\t\t-0.0198\n",
            "▁a ▁comprendre\t\t-0.0277\n",
            "▁comprendre ▁qu\t\t-0.0405\n",
            "▁qu '\t\t-0.0810\n",
            "' un\t\t-0.0792\n",
            "un ▁de\t\t-0.1486\n",
            "▁de chet\t\t-0.1702\n",
            "chet ▁nu\t\t-0.5771\n",
            "▁nu cle\t\t-0.9815\n",
            "cle aire\t\t-0.9642\n",
            "aire ▁ne\t\t-0.6741\n",
            "▁ne ▁ressemble\t\t-0.2316\n",
            "▁ressemble ▁pas\t\t-0.2223\n",
            "▁pas ▁a\t\t-0.2607\n",
            "▁a ▁ca\t\t-0.2458\n",
            "▁ca </s>\t\t-0.2902\n",
            "\n",
            "Trigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁de mand\t\t0.0921\n",
            "▁de mand iez\t\t0.1232\n",
            "mand iez ▁au\t\t0.0256\n",
            "iez ▁au ▁de\t\t-0.0364\n",
            "▁au ▁de but\t\t-0.0940\n",
            "▁de but ▁pourquoi\t\t-0.0898\n",
            "but ▁pourquoi ▁cette\t\t-0.1339\n",
            "▁pourquoi ▁cette ▁e\t\t-0.2447\n",
            "▁cette ▁e volution\t\t-0.2882\n",
            "▁e volution ▁positive\t\t-0.2045\n",
            "volution ▁positive ▁l\t\t-0.1220\n",
            "▁positive ▁l '\t\t-0.1014\n",
            "▁l ' opinion\t\t-0.1062\n",
            "' opinion ▁sur\t\t-0.0567\n",
            "opinion ▁sur ▁nu\t\t-0.1991\n",
            "▁sur ▁nu cle\t\t-0.3193\n",
            "▁nu cle aire\t\t-0.4458\n",
            "cle aire ▁Parce\t\t-0.2609\n",
            "aire ▁Parce ▁que\t\t-0.1245\n",
            "▁Parce ▁que ▁climat\t\t0.0026\n",
            "▁que ▁climat ▁crise\t\t-0.0403\n",
            "▁climat ▁crise ▁en\t\t-0.0289\n",
            "▁crise ▁en er\t\t-0.0456\n",
            "▁en er ge\t\t0.0101\n",
            "er ge tique\t\t0.0085\n",
            "ge tique ▁deja\t\t0.0217\n",
            "tique ▁deja ▁Et\t\t0.0011\n",
            "▁deja ▁Et ▁parce\t\t-0.0018\n",
            "▁Et ▁parce ▁que\t\t-0.0004\n",
            "▁parce ▁que ▁citoyens\t\t-0.0114\n",
            "▁que ▁citoyens ▁apres\t\t-0.0816\n",
            "▁citoyens ▁apres ▁de\t\t-0.0863\n",
            "▁apres ▁de ce\t\t-0.0999\n",
            "▁de ce nni\t\t-0.0678\n",
            "ce nni es\t\t-0.0753\n",
            "nni es ▁des\t\t-0.0406\n",
            "es ▁des information\t\t0.0001\n",
            "▁des information ▁anti\t\t-0.0266\n",
            "information ▁anti nu\t\t-0.0016\n",
            "▁anti nu c\t\t-0.0218\n",
            "nu c ▁commencent\t\t0.0251\n",
            "c ▁commencent ▁a\t\t-0.0341\n",
            "▁commencent ▁a ▁comprendre\t\t-0.0266\n",
            "▁a ▁comprendre ▁qu\t\t-0.0613\n",
            "▁comprendre ▁qu '\t\t-0.0878\n",
            "▁qu ' un\t\t-0.1128\n",
            "' un ▁de\t\t-0.1960\n",
            "un ▁de chet\t\t-0.2020\n",
            "▁de chet ▁nu\t\t-0.6939\n",
            "chet ▁nu cle\t\t-1.0349\n",
            "▁nu cle aire\t\t-1.4879\n",
            "cle aire ▁ne\t\t-1.1319\n",
            "aire ▁ne ▁ressemble\t\t-0.7380\n",
            "▁ne ▁ressemble ▁pas\t\t-0.3900\n",
            "▁ressemble ▁pas ▁a\t\t-0.3246\n",
            "▁pas ▁a ▁ca\t\t-0.4042\n",
            "▁a ▁ca </s>\t\t-0.3925\n",
            "\n",
            "Predicted Class: nucléaire\n",
            "True Class: nucléaire\n",
            "Predicted Probability: 4.630938529968262\n",
            "Target Attribution Score: -3.605959430770701\n",
            "\n",
            "==================================================\n",
            "\n",
            "Sentence: @JphTanguy @TristanKamin De toute manière, renouvelables ou pas, la fermeture de centrales fossiles en Europe oblige à trouver de nouveaux leviers de flexibilité. Donc on ne coupera pas à la flexibilité de la demande. On ne va pas utiliser le nucléaire pour gérer les pointes de demande.\n",
            "Target Class: avion\n",
            "Token\t\tAttribution Score\n",
            "--------------------------\n",
            "<s>\t\t0.0000\n",
            "▁J\t\t-0.0553\n",
            "ph\t\t-0.0041\n",
            "T\t\t-0.0220\n",
            "an\t\t-0.0163\n",
            "guy\t\t0.0086\n",
            "▁Tristan\t\t0.0021\n",
            "K\t\t-0.0047\n",
            "a\t\t0.0023\n",
            "min\t\t0.0036\n",
            "▁toute\t\t0.0797\n",
            "▁manier\t\t-0.0040\n",
            "e\t\t-0.0030\n",
            "▁renouvelables\t\t-0.0011\n",
            "▁ou\t\t-0.0023\n",
            "▁pas\t\t-0.0048\n",
            "▁fermeture\t\t0.0049\n",
            "▁centrales\t\t0.0008\n",
            "▁fossiles\t\t0.0027\n",
            "▁en\t\t-0.0080\n",
            "▁Europe\t\t0.0051\n",
            "▁oblige\t\t-0.0087\n",
            "▁a\t\t0.0110\n",
            "▁trouver\t\t-0.0040\n",
            "▁nouveaux\t\t-0.0044\n",
            "▁levier\t\t0.0077\n",
            "s\t\t-0.0001\n",
            "▁\t\t-0.0015\n",
            "flex\t\t0.0105\n",
            "ibili\t\t0.0151\n",
            "te\t\t-0.0028\n",
            "▁Donc\t\t-0.0048\n",
            "▁on\t\t0.0313\n",
            "▁ne\t\t-0.0056\n",
            "▁couper\t\t-0.0032\n",
            "a\t\t-0.0210\n",
            "▁pas\t\t-0.0143\n",
            "▁a\t\t-0.0060\n",
            "▁\t\t-0.0038\n",
            "flex\t\t0.0129\n",
            "ibili\t\t0.0124\n",
            "te\t\t0.0042\n",
            "▁demande\t\t0.0003\n",
            "▁On\t\t0.0578\n",
            "▁ne\t\t0.0050\n",
            "▁va\t\t0.0499\n",
            "▁pas\t\t0.0121\n",
            "▁utiliser\t\t0.0199\n",
            "▁nu\t\t-0.0999\n",
            "cle\t\t0.0577\n",
            "aire\t\t0.0015\n",
            "▁pour\t\t-0.0058\n",
            "▁ger\t\t0.0236\n",
            "er\t\t0.0007\n",
            "▁pointes\t\t0.0032\n",
            "▁demande\t\t0.8928\n",
            "</s>\t\t0.4115\n",
            "\n",
            "Bigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁J\t\t-0.0553\n",
            "▁J ph\t\t-0.0594\n",
            "ph T\t\t-0.0261\n",
            "T an\t\t-0.0383\n",
            "an guy\t\t-0.0078\n",
            "guy ▁Tristan\t\t0.0107\n",
            "▁Tristan K\t\t-0.0026\n",
            "K a\t\t-0.0024\n",
            "a min\t\t0.0059\n",
            "min ▁toute\t\t0.0833\n",
            "▁toute ▁manier\t\t0.0757\n",
            "▁manier e\t\t-0.0071\n",
            "e ▁renouvelables\t\t-0.0042\n",
            "▁renouvelables ▁ou\t\t-0.0035\n",
            "▁ou ▁pas\t\t-0.0071\n",
            "▁pas ▁fermeture\t\t0.0001\n",
            "▁fermeture ▁centrales\t\t0.0057\n",
            "▁centrales ▁fossiles\t\t0.0035\n",
            "▁fossiles ▁en\t\t-0.0054\n",
            "▁en ▁Europe\t\t-0.0030\n",
            "▁Europe ▁oblige\t\t-0.0036\n",
            "▁oblige ▁a\t\t0.0023\n",
            "▁a ▁trouver\t\t0.0070\n",
            "▁trouver ▁nouveaux\t\t-0.0085\n",
            "▁nouveaux ▁levier\t\t0.0032\n",
            "▁levier s\t\t0.0075\n",
            "s ▁\t\t-0.0016\n",
            "▁ flex\t\t0.0091\n",
            "flex ibili\t\t0.0257\n",
            "ibili te\t\t0.0123\n",
            "te ▁Donc\t\t-0.0075\n",
            "▁Donc ▁on\t\t0.0265\n",
            "▁on ▁ne\t\t0.0257\n",
            "▁ne ▁couper\t\t-0.0088\n",
            "▁couper a\t\t-0.0242\n",
            "a ▁pas\t\t-0.0353\n",
            "▁pas ▁a\t\t-0.0203\n",
            "▁a ▁\t\t-0.0098\n",
            "▁ flex\t\t0.0091\n",
            "flex ibili\t\t0.0252\n",
            "ibili te\t\t0.0165\n",
            "te ▁demande\t\t0.0045\n",
            "▁demande ▁On\t\t0.0581\n",
            "▁On ▁ne\t\t0.0628\n",
            "▁ne ▁va\t\t0.0549\n",
            "▁va ▁pas\t\t0.0619\n",
            "▁pas ▁utiliser\t\t0.0320\n",
            "▁utiliser ▁nu\t\t-0.0800\n",
            "▁nu cle\t\t-0.0421\n",
            "cle aire\t\t0.0593\n",
            "aire ▁pour\t\t-0.0043\n",
            "▁pour ▁ger\t\t0.0178\n",
            "▁ger er\t\t0.0243\n",
            "er ▁pointes\t\t0.0039\n",
            "▁pointes ▁demande\t\t0.8960\n",
            "▁demande </s>\t\t1.3043\n",
            "\n",
            "Trigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁J ph\t\t-0.0594\n",
            "▁J ph T\t\t-0.0814\n",
            "ph T an\t\t-0.0424\n",
            "T an guy\t\t-0.0298\n",
            "an guy ▁Tristan\t\t-0.0057\n",
            "guy ▁Tristan K\t\t0.0059\n",
            "▁Tristan K a\t\t-0.0003\n",
            "K a min\t\t0.0012\n",
            "a min ▁toute\t\t0.0857\n",
            "min ▁toute ▁manier\t\t0.0793\n",
            "▁toute ▁manier e\t\t0.0727\n",
            "▁manier e ▁renouvelables\t\t-0.0082\n",
            "e ▁renouvelables ▁ou\t\t-0.0065\n",
            "▁renouvelables ▁ou ▁pas\t\t-0.0083\n",
            "▁ou ▁pas ▁fermeture\t\t-0.0022\n",
            "▁pas ▁fermeture ▁centrales\t\t0.0009\n",
            "▁fermeture ▁centrales ▁fossiles\t\t0.0084\n",
            "▁centrales ▁fossiles ▁en\t\t-0.0046\n",
            "▁fossiles ▁en ▁Europe\t\t-0.0003\n",
            "▁en ▁Europe ▁oblige\t\t-0.0116\n",
            "▁Europe ▁oblige ▁a\t\t0.0074\n",
            "▁oblige ▁a ▁trouver\t\t-0.0017\n",
            "▁a ▁trouver ▁nouveaux\t\t0.0025\n",
            "▁trouver ▁nouveaux ▁levier\t\t-0.0008\n",
            "▁nouveaux ▁levier s\t\t0.0031\n",
            "▁levier s ▁\t\t0.0061\n",
            "s ▁ flex\t\t0.0090\n",
            "▁ flex ibili\t\t0.0242\n",
            "flex ibili te\t\t0.0229\n",
            "ibili te ▁Donc\t\t0.0076\n",
            "te ▁Donc ▁on\t\t0.0238\n",
            "▁Donc ▁on ▁ne\t\t0.0209\n",
            "▁on ▁ne ▁couper\t\t0.0225\n",
            "▁ne ▁couper a\t\t-0.0298\n",
            "▁couper a ▁pas\t\t-0.0385\n",
            "a ▁pas ▁a\t\t-0.0413\n",
            "▁pas ▁a ▁\t\t-0.0241\n",
            "▁a ▁ flex\t\t0.0031\n",
            "▁ flex ibili\t\t0.0214\n",
            "flex ibili te\t\t0.0294\n",
            "ibili te ▁demande\t\t0.0169\n",
            "te ▁demande ▁On\t\t0.0623\n",
            "▁demande ▁On ▁ne\t\t0.0631\n",
            "▁On ▁ne ▁va\t\t0.1126\n",
            "▁ne ▁va ▁pas\t\t0.0669\n",
            "▁va ▁pas ▁utiliser\t\t0.0819\n",
            "▁pas ▁utiliser ▁nu\t\t-0.0679\n",
            "▁utiliser ▁nu cle\t\t-0.0222\n",
            "▁nu cle aire\t\t-0.0406\n",
            "cle aire ▁pour\t\t0.0535\n",
            "aire ▁pour ▁ger\t\t0.0194\n",
            "▁pour ▁ger er\t\t0.0185\n",
            "▁ger er ▁pointes\t\t0.0275\n",
            "er ▁pointes ▁demande\t\t0.8967\n",
            "▁pointes ▁demande </s>\t\t1.3076\n",
            "\n",
            "Predicted Class: nucléaire\n",
            "True Class: nucléaire\n",
            "Predicted Probability: 4.436479568481445\n",
            "Target Attribution Score: 1.439131202148341\n",
            "\n",
            "==================================================\n",
            "\n",
            "Target Class: décroissance\n",
            "Token\t\tAttribution Score\n",
            "--------------------------\n",
            "<s>\t\t0.0000\n",
            "▁J\t\t0.0063\n",
            "ph\t\t0.0056\n",
            "T\t\t-0.0099\n",
            "an\t\t0.0331\n",
            "guy\t\t-0.0056\n",
            "▁Tristan\t\t-0.0046\n",
            "K\t\t-0.0168\n",
            "a\t\t-0.0129\n",
            "min\t\t-0.0122\n",
            "▁toute\t\t-0.0111\n",
            "▁manier\t\t-0.0093\n",
            "e\t\t-0.0127\n",
            "▁renouvelables\t\t-0.0041\n",
            "▁ou\t\t-0.0297\n",
            "▁pas\t\t-0.0196\n",
            "▁fermeture\t\t-0.0027\n",
            "▁centrales\t\t-0.0039\n",
            "▁fossiles\t\t0.0384\n",
            "▁en\t\t0.0361\n",
            "▁Europe\t\t0.0032\n",
            "▁oblige\t\t-0.0024\n",
            "▁a\t\t0.0033\n",
            "▁trouver\t\t0.0203\n",
            "▁nouveaux\t\t0.0306\n",
            "▁levier\t\t0.0367\n",
            "s\t\t0.0587\n",
            "▁\t\t0.0319\n",
            "flex\t\t0.0321\n",
            "ibili\t\t0.0645\n",
            "te\t\t0.0317\n",
            "▁Donc\t\t0.0296\n",
            "▁on\t\t0.0382\n",
            "▁ne\t\t0.0248\n",
            "▁couper\t\t-0.0067\n",
            "a\t\t0.0290\n",
            "▁pas\t\t0.0151\n",
            "▁a\t\t0.0140\n",
            "▁\t\t0.0136\n",
            "flex\t\t0.0365\n",
            "ibili\t\t0.0830\n",
            "te\t\t0.0072\n",
            "▁demande\t\t-0.0036\n",
            "▁On\t\t-0.0185\n",
            "▁ne\t\t-0.0406\n",
            "▁va\t\t-0.0212\n",
            "▁pas\t\t-0.0531\n",
            "▁utiliser\t\t-0.0328\n",
            "▁nu\t\t-0.5540\n",
            "cle\t\t-0.5164\n",
            "aire\t\t-0.6206\n",
            "▁pour\t\t-0.0397\n",
            "▁ger\t\t0.0191\n",
            "er\t\t-0.0098\n",
            "▁pointes\t\t-0.0125\n",
            "▁demande\t\t-0.0178\n",
            "</s>\t\t0.0009\n",
            "\n",
            "Bigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁J\t\t0.0063\n",
            "▁J ph\t\t0.0118\n",
            "ph T\t\t-0.0044\n",
            "T an\t\t0.0232\n",
            "an guy\t\t0.0276\n",
            "guy ▁Tristan\t\t-0.0102\n",
            "▁Tristan K\t\t-0.0215\n",
            "K a\t\t-0.0298\n",
            "a min\t\t-0.0251\n",
            "min ▁toute\t\t-0.0233\n",
            "▁toute ▁manier\t\t-0.0203\n",
            "▁manier e\t\t-0.0220\n",
            "e ▁renouvelables\t\t-0.0168\n",
            "▁renouvelables ▁ou\t\t-0.0337\n",
            "▁ou ▁pas\t\t-0.0493\n",
            "▁pas ▁fermeture\t\t-0.0223\n",
            "▁fermeture ▁centrales\t\t-0.0066\n",
            "▁centrales ▁fossiles\t\t0.0344\n",
            "▁fossiles ▁en\t\t0.0744\n",
            "▁en ▁Europe\t\t0.0393\n",
            "▁Europe ▁oblige\t\t0.0008\n",
            "▁oblige ▁a\t\t0.0010\n",
            "▁a ▁trouver\t\t0.0236\n",
            "▁trouver ▁nouveaux\t\t0.0509\n",
            "▁nouveaux ▁levier\t\t0.0673\n",
            "▁levier s\t\t0.0954\n",
            "s ▁\t\t0.0907\n",
            "▁ flex\t\t0.0640\n",
            "flex ibili\t\t0.0966\n",
            "ibili te\t\t0.0962\n",
            "te ▁Donc\t\t0.0613\n",
            "▁Donc ▁on\t\t0.0678\n",
            "▁on ▁ne\t\t0.0631\n",
            "▁ne ▁couper\t\t0.0181\n",
            "▁couper a\t\t0.0223\n",
            "a ▁pas\t\t0.0441\n",
            "▁pas ▁a\t\t0.0291\n",
            "▁a ▁\t\t0.0276\n",
            "▁ flex\t\t0.0501\n",
            "flex ibili\t\t0.1195\n",
            "ibili te\t\t0.0902\n",
            "te ▁demande\t\t0.0036\n",
            "▁demande ▁On\t\t-0.0221\n",
            "▁On ▁ne\t\t-0.0591\n",
            "▁ne ▁va\t\t-0.0617\n",
            "▁va ▁pas\t\t-0.0742\n",
            "▁pas ▁utiliser\t\t-0.0858\n",
            "▁utiliser ▁nu\t\t-0.5867\n",
            "▁nu cle\t\t-1.0704\n",
            "cle aire\t\t-1.1370\n",
            "aire ▁pour\t\t-0.6603\n",
            "▁pour ▁ger\t\t-0.0207\n",
            "▁ger er\t\t0.0092\n",
            "er ▁pointes\t\t-0.0223\n",
            "▁pointes ▁demande\t\t-0.0302\n",
            "▁demande </s>\t\t-0.0168\n",
            "\n",
            "Trigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁J ph\t\t0.0118\n",
            "▁J ph T\t\t0.0019\n",
            "ph T an\t\t0.0287\n",
            "T an guy\t\t0.0176\n",
            "an guy ▁Tristan\t\t0.0229\n",
            "guy ▁Tristan K\t\t-0.0270\n",
            "▁Tristan K a\t\t-0.0344\n",
            "K a min\t\t-0.0420\n",
            "a min ▁toute\t\t-0.0362\n",
            "min ▁toute ▁manier\t\t-0.0325\n",
            "▁toute ▁manier e\t\t-0.0330\n",
            "▁manier e ▁renouvelables\t\t-0.0261\n",
            "e ▁renouvelables ▁ou\t\t-0.0465\n",
            "▁renouvelables ▁ou ▁pas\t\t-0.0533\n",
            "▁ou ▁pas ▁fermeture\t\t-0.0520\n",
            "▁pas ▁fermeture ▁centrales\t\t-0.0262\n",
            "▁fermeture ▁centrales ▁fossiles\t\t0.0318\n",
            "▁centrales ▁fossiles ▁en\t\t0.0705\n",
            "▁fossiles ▁en ▁Europe\t\t0.0776\n",
            "▁en ▁Europe ▁oblige\t\t0.0369\n",
            "▁Europe ▁oblige ▁a\t\t0.0042\n",
            "▁oblige ▁a ▁trouver\t\t0.0213\n",
            "▁a ▁trouver ▁nouveaux\t\t0.0542\n",
            "▁trouver ▁nouveaux ▁levier\t\t0.0876\n",
            "▁nouveaux ▁levier s\t\t0.1260\n",
            "▁levier s ▁\t\t0.1273\n",
            "s ▁ flex\t\t0.1227\n",
            "▁ flex ibili\t\t0.1285\n",
            "flex ibili te\t\t0.1283\n",
            "ibili te ▁Donc\t\t0.1258\n",
            "te ▁Donc ▁on\t\t0.0995\n",
            "▁Donc ▁on ▁ne\t\t0.0926\n",
            "▁on ▁ne ▁couper\t\t0.0563\n",
            "▁ne ▁couper a\t\t0.0471\n",
            "▁couper a ▁pas\t\t0.0374\n",
            "a ▁pas ▁a\t\t0.0581\n",
            "▁pas ▁a ▁\t\t0.0427\n",
            "▁a ▁ flex\t\t0.0641\n",
            "▁ flex ibili\t\t0.1331\n",
            "flex ibili te\t\t0.1267\n",
            "ibili te ▁demande\t\t0.0866\n",
            "te ▁demande ▁On\t\t-0.0149\n",
            "▁demande ▁On ▁ne\t\t-0.0627\n",
            "▁On ▁ne ▁va\t\t-0.0803\n",
            "▁ne ▁va ▁pas\t\t-0.1148\n",
            "▁va ▁pas ▁utiliser\t\t-0.1070\n",
            "▁pas ▁utiliser ▁nu\t\t-0.6398\n",
            "▁utiliser ▁nu cle\t\t-1.1031\n",
            "▁nu cle aire\t\t-1.6910\n",
            "cle aire ▁pour\t\t-1.1767\n",
            "aire ▁pour ▁ger\t\t-0.6413\n",
            "▁pour ▁ger er\t\t-0.0305\n",
            "▁ger er ▁pointes\t\t-0.0032\n",
            "er ▁pointes ▁demande\t\t-0.0400\n",
            "▁pointes ▁demande </s>\t\t-0.0293\n",
            "\n",
            "Predicted Class: nucléaire\n",
            "True Class: nucléaire\n",
            "Predicted Probability: 4.436479568481445\n",
            "Target Attribution Score: -1.361089070492369\n",
            "\n",
            "==================================================\n",
            "\n",
            "Target Class: nucléaire\n",
            "Token\t\tAttribution Score\n",
            "--------------------------\n",
            "<s>\t\t0.0000\n",
            "▁J\t\t-0.0171\n",
            "ph\t\t-0.0439\n",
            "T\t\t0.0093\n",
            "an\t\t0.0723\n",
            "guy\t\t0.0019\n",
            "▁Tristan\t\t0.0010\n",
            "K\t\t0.0128\n",
            "a\t\t-0.0015\n",
            "min\t\t0.0077\n",
            "▁toute\t\t-0.0467\n",
            "▁manier\t\t0.0031\n",
            "e\t\t0.0117\n",
            "▁renouvelables\t\t0.0025\n",
            "▁ou\t\t0.0139\n",
            "▁pas\t\t0.0185\n",
            "▁fermeture\t\t0.0062\n",
            "▁centrales\t\t0.0049\n",
            "▁fossiles\t\t-0.0084\n",
            "▁en\t\t-0.0078\n",
            "▁Europe\t\t0.0031\n",
            "▁oblige\t\t0.0015\n",
            "▁a\t\t-0.0125\n",
            "▁trouver\t\t-0.0020\n",
            "▁nouveaux\t\t-0.0174\n",
            "▁levier\t\t-0.0361\n",
            "s\t\t-0.0347\n",
            "▁\t\t-0.0114\n",
            "flex\t\t-0.0167\n",
            "ibili\t\t-0.0408\n",
            "te\t\t-0.0101\n",
            "▁Donc\t\t0.0002\n",
            "▁on\t\t-0.0259\n",
            "▁ne\t\t0.0111\n",
            "▁couper\t\t0.0215\n",
            "a\t\t0.0191\n",
            "▁pas\t\t0.0111\n",
            "▁a\t\t0.0049\n",
            "▁\t\t0.0059\n",
            "flex\t\t-0.0276\n",
            "ibili\t\t-0.0479\n",
            "te\t\t0.0012\n",
            "▁demande\t\t0.0044\n",
            "▁On\t\t-0.0061\n",
            "▁ne\t\t0.0519\n",
            "▁va\t\t0.0212\n",
            "▁pas\t\t0.0657\n",
            "▁utiliser\t\t0.0189\n",
            "▁nu\t\t0.5095\n",
            "cle\t\t0.3836\n",
            "aire\t\t0.4906\n",
            "▁pour\t\t0.0376\n",
            "▁ger\t\t-0.0412\n",
            "er\t\t0.0041\n",
            "▁pointes\t\t-0.0239\n",
            "▁demande\t\t-0.5164\n",
            "</s>\t\t-0.2314\n",
            "\n",
            "Bigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁J\t\t-0.0171\n",
            "▁J ph\t\t-0.0609\n",
            "ph T\t\t-0.0346\n",
            "T an\t\t0.0816\n",
            "an guy\t\t0.0742\n",
            "guy ▁Tristan\t\t0.0028\n",
            "▁Tristan K\t\t0.0137\n",
            "K a\t\t0.0113\n",
            "a min\t\t0.0061\n",
            "min ▁toute\t\t-0.0390\n",
            "▁toute ▁manier\t\t-0.0436\n",
            "▁manier e\t\t0.0149\n",
            "e ▁renouvelables\t\t0.0143\n",
            "▁renouvelables ▁ou\t\t0.0164\n",
            "▁ou ▁pas\t\t0.0324\n",
            "▁pas ▁fermeture\t\t0.0247\n",
            "▁fermeture ▁centrales\t\t0.0111\n",
            "▁centrales ▁fossiles\t\t-0.0035\n",
            "▁fossiles ▁en\t\t-0.0162\n",
            "▁en ▁Europe\t\t-0.0048\n",
            "▁Europe ▁oblige\t\t0.0046\n",
            "▁oblige ▁a\t\t-0.0110\n",
            "▁a ▁trouver\t\t-0.0145\n",
            "▁trouver ▁nouveaux\t\t-0.0194\n",
            "▁nouveaux ▁levier\t\t-0.0535\n",
            "▁levier s\t\t-0.0708\n",
            "s ▁\t\t-0.0461\n",
            "▁ flex\t\t-0.0281\n",
            "flex ibili\t\t-0.0575\n",
            "ibili te\t\t-0.0509\n",
            "te ▁Donc\t\t-0.0099\n",
            "▁Donc ▁on\t\t-0.0257\n",
            "▁on ▁ne\t\t-0.0148\n",
            "▁ne ▁couper\t\t0.0326\n",
            "▁couper a\t\t0.0405\n",
            "a ▁pas\t\t0.0301\n",
            "▁pas ▁a\t\t0.0159\n",
            "▁a ▁\t\t0.0108\n",
            "▁ flex\t\t-0.0217\n",
            "flex ibili\t\t-0.0755\n",
            "ibili te\t\t-0.0467\n",
            "te ▁demande\t\t0.0056\n",
            "▁demande ▁On\t\t-0.0017\n",
            "▁On ▁ne\t\t0.0458\n",
            "▁ne ▁va\t\t0.0731\n",
            "▁va ▁pas\t\t0.0869\n",
            "▁pas ▁utiliser\t\t0.0846\n",
            "▁utiliser ▁nu\t\t0.5283\n",
            "▁nu cle\t\t0.8931\n",
            "cle aire\t\t0.8742\n",
            "aire ▁pour\t\t0.5281\n",
            "▁pour ▁ger\t\t-0.0037\n",
            "▁ger er\t\t-0.0372\n",
            "er ▁pointes\t\t-0.0198\n",
            "▁pointes ▁demande\t\t-0.5403\n",
            "▁demande </s>\t\t-0.7478\n",
            "\n",
            "Trigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁J ph\t\t-0.0609\n",
            "▁J ph T\t\t-0.0516\n",
            "ph T an\t\t0.0378\n",
            "T an guy\t\t0.0835\n",
            "an guy ▁Tristan\t\t0.0752\n",
            "guy ▁Tristan K\t\t0.0156\n",
            "▁Tristan K a\t\t0.0122\n",
            "K a min\t\t0.0189\n",
            "a min ▁toute\t\t-0.0405\n",
            "min ▁toute ▁manier\t\t-0.0359\n",
            "▁toute ▁manier e\t\t-0.0318\n",
            "▁manier e ▁renouvelables\t\t0.0174\n",
            "e ▁renouvelables ▁ou\t\t0.0282\n",
            "▁renouvelables ▁ou ▁pas\t\t0.0350\n",
            "▁ou ▁pas ▁fermeture\t\t0.0386\n",
            "▁pas ▁fermeture ▁centrales\t\t0.0296\n",
            "▁fermeture ▁centrales ▁fossiles\t\t0.0027\n",
            "▁centrales ▁fossiles ▁en\t\t-0.0113\n",
            "▁fossiles ▁en ▁Europe\t\t-0.0132\n",
            "▁en ▁Europe ▁oblige\t\t-0.0033\n",
            "▁Europe ▁oblige ▁a\t\t-0.0079\n",
            "▁oblige ▁a ▁trouver\t\t-0.0130\n",
            "▁a ▁trouver ▁nouveaux\t\t-0.0319\n",
            "▁trouver ▁nouveaux ▁levier\t\t-0.0555\n",
            "▁nouveaux ▁levier s\t\t-0.0882\n",
            "▁levier s ▁\t\t-0.0822\n",
            "s ▁ flex\t\t-0.0628\n",
            "▁ flex ibili\t\t-0.0689\n",
            "flex ibili te\t\t-0.0676\n",
            "ibili te ▁Donc\t\t-0.0507\n",
            "te ▁Donc ▁on\t\t-0.0358\n",
            "▁Donc ▁on ▁ne\t\t-0.0146\n",
            "▁on ▁ne ▁couper\t\t0.0067\n",
            "▁ne ▁couper a\t\t0.0517\n",
            "▁couper a ▁pas\t\t0.0516\n",
            "a ▁pas ▁a\t\t0.0350\n",
            "▁pas ▁a ▁\t\t0.0219\n",
            "▁a ▁ flex\t\t-0.0168\n",
            "▁ flex ibili\t\t-0.0696\n",
            "flex ibili te\t\t-0.0743\n",
            "ibili te ▁demande\t\t-0.0423\n",
            "te ▁demande ▁On\t\t-0.0005\n",
            "▁demande ▁On ▁ne\t\t0.0502\n",
            "▁On ▁ne ▁va\t\t0.0670\n",
            "▁ne ▁va ▁pas\t\t0.1388\n",
            "▁va ▁pas ▁utiliser\t\t0.1057\n",
            "▁pas ▁utiliser ▁nu\t\t0.5940\n",
            "▁utiliser ▁nu cle\t\t0.9119\n",
            "▁nu cle aire\t\t1.3837\n",
            "cle aire ▁pour\t\t0.9117\n",
            "aire ▁pour ▁ger\t\t0.4869\n",
            "▁pour ▁ger er\t\t0.0004\n",
            "▁ger er ▁pointes\t\t-0.0611\n",
            "er ▁pointes ▁demande\t\t-0.5363\n",
            "▁pointes ▁demande </s>\t\t-0.7717\n",
            "\n",
            "Predicted Class: nucléaire\n",
            "True Class: nucléaire\n",
            "Predicted Probability: 4.436479568481445\n",
            "Target Attribution Score: 0.605201380720017\n",
            "\n",
            "==================================================\n",
            "\n",
            "Target Class: viande\n",
            "Token\t\tAttribution Score\n",
            "--------------------------\n",
            "<s>\t\t0.0000\n",
            "▁J\t\t0.3487\n",
            "ph\t\t0.1265\n",
            "T\t\t0.1110\n",
            "an\t\t-0.2550\n",
            "guy\t\t0.0852\n",
            "▁Tristan\t\t0.0294\n",
            "K\t\t0.0453\n",
            "a\t\t0.1134\n",
            "min\t\t0.0546\n",
            "▁toute\t\t-0.0103\n",
            "▁manier\t\t0.0226\n",
            "e\t\t0.0741\n",
            "▁renouvelables\t\t0.0144\n",
            "▁ou\t\t0.0151\n",
            "▁pas\t\t0.0265\n",
            "▁fermeture\t\t0.0621\n",
            "▁centrales\t\t0.0585\n",
            "▁fossiles\t\t0.0403\n",
            "▁en\t\t0.0442\n",
            "▁Europe\t\t0.0045\n",
            "▁oblige\t\t0.0236\n",
            "▁a\t\t0.0299\n",
            "▁trouver\t\t0.0143\n",
            "▁nouveaux\t\t0.0023\n",
            "▁levier\t\t0.0201\n",
            "s\t\t-0.0262\n",
            "▁\t\t-0.0454\n",
            "flex\t\t-0.0578\n",
            "ibili\t\t-0.1433\n",
            "te\t\t-0.0430\n",
            "▁Donc\t\t-0.0905\n",
            "▁on\t\t-0.2741\n",
            "▁ne\t\t-0.3101\n",
            "▁couper\t\t-0.1492\n",
            "a\t\t-0.2615\n",
            "▁pas\t\t-0.2247\n",
            "▁a\t\t-0.0850\n",
            "▁\t\t-0.0268\n",
            "flex\t\t-0.0064\n",
            "ibili\t\t-0.2084\n",
            "te\t\t-0.0300\n",
            "▁demande\t\t0.0946\n",
            "▁On\t\t-0.1342\n",
            "▁ne\t\t-0.2338\n",
            "▁va\t\t-0.1439\n",
            "▁pas\t\t-0.2424\n",
            "▁utiliser\t\t-0.0922\n",
            "▁nu\t\t0.2503\n",
            "cle\t\t0.0240\n",
            "aire\t\t-0.0801\n",
            "▁pour\t\t-0.0463\n",
            "▁ger\t\t-0.0108\n",
            "er\t\t-0.0241\n",
            "▁pointes\t\t0.0072\n",
            "▁demande\t\t-0.1094\n",
            "</s>\t\t-0.2886\n",
            "\n",
            "Bigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁J\t\t0.3487\n",
            "▁J ph\t\t0.4752\n",
            "ph T\t\t0.2375\n",
            "T an\t\t-0.1440\n",
            "an guy\t\t-0.1698\n",
            "guy ▁Tristan\t\t0.1145\n",
            "▁Tristan K\t\t0.0746\n",
            "K a\t\t0.1587\n",
            "a min\t\t0.1681\n",
            "min ▁toute\t\t0.0443\n",
            "▁toute ▁manier\t\t0.0123\n",
            "▁manier e\t\t0.0968\n",
            "e ▁renouvelables\t\t0.0885\n",
            "▁renouvelables ▁ou\t\t0.0295\n",
            "▁ou ▁pas\t\t0.0417\n",
            "▁pas ▁fermeture\t\t0.0887\n",
            "▁fermeture ▁centrales\t\t0.1206\n",
            "▁centrales ▁fossiles\t\t0.0988\n",
            "▁fossiles ▁en\t\t0.0845\n",
            "▁en ▁Europe\t\t0.0488\n",
            "▁Europe ▁oblige\t\t0.0282\n",
            "▁oblige ▁a\t\t0.0536\n",
            "▁a ▁trouver\t\t0.0443\n",
            "▁trouver ▁nouveaux\t\t0.0166\n",
            "▁nouveaux ▁levier\t\t0.0224\n",
            "▁levier s\t\t-0.0061\n",
            "s ▁\t\t-0.0716\n",
            "▁ flex\t\t-0.1031\n",
            "flex ibili\t\t-0.2011\n",
            "ibili te\t\t-0.1863\n",
            "te ▁Donc\t\t-0.1335\n",
            "▁Donc ▁on\t\t-0.3646\n",
            "▁on ▁ne\t\t-0.5842\n",
            "▁ne ▁couper\t\t-0.4593\n",
            "▁couper a\t\t-0.4107\n",
            "a ▁pas\t\t-0.4863\n",
            "▁pas ▁a\t\t-0.3097\n",
            "▁a ▁\t\t-0.1117\n",
            "▁ flex\t\t-0.0332\n",
            "flex ibili\t\t-0.2148\n",
            "ibili te\t\t-0.2384\n",
            "te ▁demande\t\t0.0647\n",
            "▁demande ▁On\t\t-0.0395\n",
            "▁On ▁ne\t\t-0.3680\n",
            "▁ne ▁va\t\t-0.3777\n",
            "▁va ▁pas\t\t-0.3863\n",
            "▁pas ▁utiliser\t\t-0.3346\n",
            "▁utiliser ▁nu\t\t0.1581\n",
            "▁nu cle\t\t0.2743\n",
            "cle aire\t\t-0.0560\n",
            "aire ▁pour\t\t-0.1264\n",
            "▁pour ▁ger\t\t-0.0572\n",
            "▁ger er\t\t-0.0349\n",
            "er ▁pointes\t\t-0.0169\n",
            "▁pointes ▁demande\t\t-0.1022\n",
            "▁demande </s>\t\t-0.3981\n",
            "\n",
            "Trigram\t\tAttribution Score\n",
            "--------------------------\n",
            "<s> ▁J ph\t\t0.4752\n",
            "▁J ph T\t\t0.5862\n",
            "ph T an\t\t-0.0174\n",
            "T an guy\t\t-0.0588\n",
            "an guy ▁Tristan\t\t-0.1404\n",
            "guy ▁Tristan K\t\t0.1598\n",
            "▁Tristan K a\t\t0.1881\n",
            "K a min\t\t0.2134\n",
            "a min ▁toute\t\t0.1577\n",
            "min ▁toute ▁manier\t\t0.0669\n",
            "▁toute ▁manier e\t\t0.0864\n",
            "▁manier e ▁renouvelables\t\t0.1111\n",
            "e ▁renouvelables ▁ou\t\t0.1036\n",
            "▁renouvelables ▁ou ▁pas\t\t0.0560\n",
            "▁ou ▁pas ▁fermeture\t\t0.1038\n",
            "▁pas ▁fermeture ▁centrales\t\t0.1472\n",
            "▁fermeture ▁centrales ▁fossiles\t\t0.1610\n",
            "▁centrales ▁fossiles ▁en\t\t0.1431\n",
            "▁fossiles ▁en ▁Europe\t\t0.0891\n",
            "▁en ▁Europe ▁oblige\t\t0.0724\n",
            "▁Europe ▁oblige ▁a\t\t0.0581\n",
            "▁oblige ▁a ▁trouver\t\t0.0679\n",
            "▁a ▁trouver ▁nouveaux\t\t0.0465\n",
            "▁trouver ▁nouveaux ▁levier\t\t0.0367\n",
            "▁nouveaux ▁levier s\t\t-0.0038\n",
            "▁levier s ▁\t\t-0.0515\n",
            "s ▁ flex\t\t-0.1294\n",
            "▁ flex ibili\t\t-0.2464\n",
            "flex ibili te\t\t-0.2440\n",
            "ibili te ▁Donc\t\t-0.2768\n",
            "te ▁Donc ▁on\t\t-0.4076\n",
            "▁Donc ▁on ▁ne\t\t-0.6748\n",
            "▁on ▁ne ▁couper\t\t-0.7334\n",
            "▁ne ▁couper a\t\t-0.7209\n",
            "▁couper a ▁pas\t\t-0.6354\n",
            "a ▁pas ▁a\t\t-0.5712\n",
            "▁pas ▁a ▁\t\t-0.3365\n",
            "▁a ▁ flex\t\t-0.1182\n",
            "▁ flex ibili\t\t-0.2416\n",
            "flex ibili te\t\t-0.2448\n",
            "ibili te ▁demande\t\t-0.1437\n",
            "te ▁demande ▁On\t\t-0.0695\n",
            "▁demande ▁On ▁ne\t\t-0.2733\n",
            "▁On ▁ne ▁va\t\t-0.5119\n",
            "▁ne ▁va ▁pas\t\t-0.6201\n",
            "▁va ▁pas ▁utiliser\t\t-0.4785\n",
            "▁pas ▁utiliser ▁nu\t\t-0.0843\n",
            "▁utiliser ▁nu cle\t\t0.1821\n",
            "▁nu cle aire\t\t0.1943\n",
            "cle aire ▁pour\t\t-0.1024\n",
            "aire ▁pour ▁ger\t\t-0.1372\n",
            "▁pour ▁ger er\t\t-0.0813\n",
            "▁ger er ▁pointes\t\t-0.0277\n",
            "er ▁pointes ▁demande\t\t-0.1263\n",
            "▁pointes ▁demande </s>\t\t-0.3909\n",
            "\n",
            "Predicted Class: nucléaire\n",
            "True Class: nucléaire\n",
            "Predicted Probability: 4.436479568481445\n",
            "Target Attribution Score: -1.9105548571550408\n",
            "\n",
            "==================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Exemple\n",
        "#sentences = [\"production de viande dans des abattoir\", \"l'avion pollue beaucoup l'air\", \"l'énergie nucléaire permet de produire électricité\"]\n",
        "sentences = df_test['Text'].tolist()\n",
        "\n",
        "attribution_scores = get_attribution_scores_for_all_targets(sentences)\n",
        "display_attribution_scores(attribution_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZajlGwVyMjo",
        "outputId": "fed7449d-95e3-4b2b-a240-cb157ce90674"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved Attribution Scores to file: /content/saved_attribution_scores.json\n"
          ]
        }
      ],
      "source": [
        "#Enregistrer les score d'attribution des différent unigral, bigram et trigram dans un fichier json pour les différents targets\n",
        "\n",
        "def convert_to_native_python_types(data):\n",
        "    if isinstance(data, dict):\n",
        "        return {key: convert_to_native_python_types(value) for key, value in data.items()}\n",
        "    elif isinstance(data, list):\n",
        "        return [convert_to_native_python_types(element) for element in data]\n",
        "    elif isinstance(data, tuple):\n",
        "        return tuple(convert_to_native_python_types(element) for element in data)\n",
        "    elif isinstance(data, set):\n",
        "        return {convert_to_native_python_types(element) for element in data}\n",
        "    elif isinstance(data, torch.Tensor):\n",
        "        return data.tolist()\n",
        "    else:\n",
        "        return data\n",
        "\n",
        "def save_attribution_scores_to_json(attribution_scores, file_path):\n",
        "    output_data = defaultdict(lambda: defaultdict(dict))\n",
        "\n",
        "    for sentence, target_scores in attribution_scores.items():\n",
        "        for target_class, scores_dict in target_scores.items():\n",
        "            output_data[sentence][target_class][\"tokens\"] = scores_dict[\"raw_input_ids\"]\n",
        "            output_data[sentence][target_class][\"word_attributions\"] = scores_dict[\"word_attributions\"]\n",
        "\n",
        "            bigram_tokens = [f\"{token} {scores_dict['raw_input_ids'][i+1]}\" for i, token in enumerate(scores_dict[\"raw_input_ids\"][:-1])]\n",
        "            bigram_scores = scores_dict.get(\"bigram_attributions\", [])\n",
        "            output_data[sentence][target_class][\"bigrams\"] = bigram_tokens\n",
        "            output_data[sentence][target_class][\"bigram_attributions\"] = bigram_scores\n",
        "\n",
        "            trigram_tokens = [f\"{token} {scores_dict['raw_input_ids'][i+1]} {scores_dict['raw_input_ids'][i+2]}\" for i, token in enumerate(scores_dict[\"raw_input_ids\"][:-2])]\n",
        "            trigram_scores = scores_dict.get(\"trigram_attributions\", [])\n",
        "            output_data[sentence][target_class][\"trigrams\"] = trigram_tokens\n",
        "            output_data[sentence][target_class][\"trigram_attributions\"] = trigram_scores\n",
        "\n",
        "            # Add other fields if needed, such as \"pred_prob\", \"pred_class\", etc.\n",
        "\n",
        "    with open(file_path, \"w\") as file:\n",
        "        json.dump(output_data, file)\n",
        "\n",
        "# Assuming you already have the following variables defined:\n",
        "# attribution_scores: The output of the get_attribution_scores_for_all_targets function\n",
        "\n",
        "# Define the file path for saving the attribution scores\n",
        "attribution_scores_file_path = \"/content/saved_attribution_scores.json\"\n",
        "\n",
        "# Save the attribution scores to a JSON file in the desired format\n",
        "save_attribution_scores_to_json(attribution_scores, attribution_scores_file_path)\n",
        "print(\"Saved Attribution Scores to file:\", attribution_scores_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taTMyeWU0u-5",
        "outputId": "08f19807-4c89-4b79-e534-9ddea9d15429"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Token: ▁\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.3367408766956855\n",
            "==================================================\n",
            "Token: ern\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.3441451163973267\n",
            "==================================================\n",
            "Token: est\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.38698257721523777\n",
            "==================================================\n",
            "Token: _\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.4405221841436491\n",
            "==================================================\n",
            "Token: pl\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.07137745013910402\n",
            "==================================================\n",
            "Token: on\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.4901638676481372\n",
            "==================================================\n",
            "Token: che\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.025881656949577496\n",
            "==================================================\n",
            "Token: ▁Cette\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.06883225755105471\n",
            "==================================================\n",
            "Token: ▁industrie\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.09619292587870283\n",
            "==================================================\n",
            "Token: ▁fonctionne\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.053586959316772036\n",
            "==================================================\n",
            "Token: ▁sur\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.7293678373662413\n",
            "==================================================\n",
            "Token: ▁l\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.35000416113231664\n",
            "==================================================\n",
            "Token: '\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.3656830074992501\n",
            "==================================================\n",
            "Token: imp\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.035840893400545935\n",
            "==================================================\n",
            "Token: ossi\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.27430782462470077\n",
            "==================================================\n",
            "Token: bili\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.09064176122565791\n",
            "==================================================\n",
            "Token: te\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.08826473172532884\n",
            "==================================================\n",
            "Token: ▁a\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.08694406028070448\n",
            "==================================================\n",
            "Token: ▁montrer\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.018632190509222036\n",
            "==================================================\n",
            "Token: ▁et\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.2731006922614433\n",
            "==================================================\n",
            "Token: ▁voir\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.0453205220249089\n",
            "==================================================\n",
            "Token: ▁aussi\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.16097155469635166\n",
            "==================================================\n",
            "Token: ▁perdent\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.026874853386511376\n",
            "==================================================\n",
            "Token: ▁leur\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.12109592984246134\n",
            "==================================================\n",
            "Token: ▁nerfs\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.040563003756161904\n",
            "==================================================\n",
            "Token: ▁moindre\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.018447519457942117\n",
            "==================================================\n",
            "Token: ▁video\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.05696127790140922\n",
            "==================================================\n",
            "Token: ▁Quand\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.037907798017976814\n",
            "==================================================\n",
            "Token: ▁CGT\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.23457096052128212\n",
            "==================================================\n",
            "Token: ▁on\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.11398083265358853\n",
            "==================================================\n",
            "Token: ▁ne\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.14757367903827018\n",
            "==================================================\n",
            "Token: entend\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.06307334768214207\n",
            "==================================================\n",
            "Token: ▁jamais\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.07181632699745336\n",
            "==================================================\n",
            "Token: ▁dam\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.173672303974973\n",
            "==================================================\n",
            "Token: nes\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.08779008136990961\n",
            "==================================================\n",
            "Token: ▁viande\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.3226492521662192\n",
            "==================================================\n",
            "Token: ▁tache\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.33091430369353014\n",
            "==================================================\n",
            "Token: rons\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.7302262954409051\n",
            "==================================================\n",
            "Token: ▁inter\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.1414593097224242\n",
            "==================================================\n",
            "Token: im\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.18965749403223842\n",
            "==================================================\n",
            "Token: aires\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.17177828528252087\n",
            "==================================================\n",
            "Token: ▁travailleurs\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.050297077413856105\n",
            "==================================================\n",
            "Token: ▁de\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.5993418736330562\n",
            "==================================================\n",
            "Token: tache\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.07797205046936781\n",
            "==================================================\n",
            "Token: s\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.45922253794343626\n",
            "==================================================\n",
            "Token: fen\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.0704347733155237\n",
            "==================================================\n",
            "Token: dent\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.04762495453006347\n",
            "==================================================\n",
            "Token: ▁que\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.11628192689095129\n",
            "==================================================\n",
            "Token: ▁bi\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.11444088669241834\n",
            "==================================================\n",
            "Token: ft\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.08839590808017861\n",
            "==================================================\n",
            "Token: e\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.4662529792399467\n",
            "==================================================\n",
            "Token: que\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.04265036890317402\n",
            "==================================================\n",
            "Token: </s>\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.5396869251855407\n",
            "==================================================\n",
            "Token: ▁Deux\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.29759305767744826\n",
            "==================================================\n",
            "Token: ▁Da\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.15761228516167458\n",
            "==================================================\n",
            "Token: ault\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.793172885681329\n",
            "==================================================\n",
            "Token: ▁Falcon\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.2021206260676947\n",
            "==================================================\n",
            "Token: ▁L\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.2255467227364542\n",
            "==================================================\n",
            "Token: X\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.21569536098849118\n",
            "==================================================\n",
            "Token: ▁pour\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.33022102763587224\n",
            "==================================================\n",
            "Token: ▁Royal\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.22692242298520204\n",
            "==================================================\n",
            "Token: ▁Air\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.6397076525821597\n",
            "==================================================\n",
            "Token: ▁Force\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.3456002736748095\n",
            "==================================================\n",
            "Token: ivre\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.17118573976609916\n",
            "==================================================\n",
            "Token: ▁sa\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.35178025183130407\n",
            "==================================================\n",
            "Token: ▁propre\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.3891448028162005\n",
            "==================================================\n",
            "Token: ▁log\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.17068018318416653\n",
            "==================================================\n",
            "Token: hor\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.2568652998750119\n",
            "==================================================\n",
            "Token: ▁compare\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.027187018148143605\n",
            "==================================================\n",
            "Token: f\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.28465633905141785\n",
            "==================================================\n",
            "Token: ense\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.1478847141549795\n",
            "==================================================\n",
            "Token: ▁steak\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.5884419007051255\n",
            "==================================================\n",
            "Token: ▁aux\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.26379154915015757\n",
            "==================================================\n",
            "Token: ▁heures\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.19012380355608013\n",
            "==================================================\n",
            "Token: ▁plus\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.1113800642420519\n",
            "==================================================\n",
            "Token: ▁sombres\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.043815518499535404\n",
            "==================================================\n",
            "Token: ▁notre\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.07415465180991808\n",
            "==================================================\n",
            "Token: ▁histoire\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.09694531804273875\n",
            "==================================================\n",
            "Token: ▁Bu\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.08181506620778657\n",
            "==================================================\n",
            "Token: vez\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.04307404016583673\n",
            "==================================================\n",
            "Token: ▁frais\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.07791346568933331\n",
            "==================================================\n",
            "Token: ▁gars\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.05893681750464721\n",
            "==================================================\n",
            "Token: ▁c\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.08194316831418984\n",
            "==================================================\n",
            "Token: ▁franchement\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.08504027481055108\n",
            "==================================================\n",
            "Token: ▁pa\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.06148349986122736\n",
            "==================================================\n",
            "Token: the\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.052678324059739844\n",
            "==================================================\n",
            "Token: tique\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.3637493038602273\n",
            "==================================================\n",
            "Token: ▁Spring\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.2678632181063859\n",
            "==================================================\n",
            "Token: ▁Alliance\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.09811836513870421\n",
            "==================================================\n",
            "Token: ▁nouvelle\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.28389921226004766\n",
            "==================================================\n",
            "Token: ▁alliance\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.06178950197777914\n",
            "==================================================\n",
            "Token: ▁compagnies\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.16432067606492243\n",
            "==================================================\n",
            "Token: ▁n\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.30462489765952433\n",
            "==================================================\n",
            "Token: iger\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.05486027789396032\n",
            "==================================================\n",
            "Token: iane\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.20593484151095212\n",
            "==================================================\n",
            "Token: ▁qui\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.2672418514551388\n",
            "==================================================\n",
            "Token: ▁vise\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.21455300175834055\n",
            "==================================================\n",
            "Token: ▁un\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.04280291728844187\n",
            "==================================================\n",
            "Token: ▁el\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.038264215832091115\n",
            "==================================================\n",
            "Token: arg\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.3759243239463359\n",
            "==================================================\n",
            "Token: issement\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.045166160086249296\n",
            "==================================================\n",
            "Token: ▁africain\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.053483089881716545\n",
            "==================================================\n",
            "Token: ▁A\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.45625158460972054\n",
            "==================================================\n",
            "Token: er\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.35684690875355574\n",
            "==================================================\n",
            "Token: au\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.47247978082866315\n",
            "==================================================\n",
            "Token: Aviation\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.1581918693694628\n",
            "==================================================\n",
            "Token: ▁Selon\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.08121159782828939\n",
            "==================================================\n",
            "Token: ▁PDG\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.04066692236876537\n",
            "==================================================\n",
            "Token: ▁Pi\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.984415388522172\n",
            "==================================================\n",
            "Token: one\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.1546356860452948\n",
            "==================================================\n",
            "Token: un\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.03907900138994373\n",
            "==================================================\n",
            "Token: ▁principaux\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.01737763484549418\n",
            "==================================================\n",
            "Token: exploitant\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.1442212651486488\n",
            "==================================================\n",
            "Token: ▁pe\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.43967735964030363\n",
            "==================================================\n",
            "Token: tro\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.4682227257771468\n",
            "==================================================\n",
            "Token: le\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.3584638774651852\n",
            "==================================================\n",
            "Token: ▁schiste\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.43625287946658314\n",
            "==================================================\n",
            "Token: ▁faudra\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.07750675226751073\n",
            "==================================================\n",
            "Token: ▁pas\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.4211286230168977\n",
            "==================================================\n",
            "Token: ▁compter\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.06869340291877216\n",
            "==================================================\n",
            "Token: industrie\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.09003209035384407\n",
            "==================================================\n",
            "Token: ▁repond\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.056691192231869865\n",
            "==================================================\n",
            "Token: re\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.06792975791838012\n",
            "==================================================\n",
            "Token: ▁croissance\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.7020711865573456\n",
            "==================================================\n",
            "Token: ▁demande\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.8928369788996585\n",
            "==================================================\n",
            "Token: ▁cross\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.22184376551701387\n",
            "==================================================\n",
            "Token: mark\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.6320039052910488\n",
            "==================================================\n",
            "Token: Le\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.05878708584045034\n",
            "==================================================\n",
            "Token: ▁mix\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.023865795466881612\n",
            "==================================================\n",
            "Token: ▁renouvelables\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.014355366474292395\n",
            "==================================================\n",
            "Token: ▁nu\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.5699277525555054\n",
            "==================================================\n",
            "Token: cle\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.5098030801479283\n",
            "==================================================\n",
            "Token: aire\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.6176532403843716\n",
            "==================================================\n",
            "Token: ▁est\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.11220694887051776\n",
            "==================================================\n",
            "Token: ▁seul\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.04089857849404522\n",
            "==================================================\n",
            "Token: ▁permet\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.01830794471737575\n",
            "==================================================\n",
            "Token: ▁re\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.1504424120288401\n",
            "==================================================\n",
            "Token: duire\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.04751765690073941\n",
            "==================================================\n",
            "Token: ▁manier\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.022625732485112012\n",
            "==================================================\n",
            "Token: ▁efficace\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.011968802384845451\n",
            "==================================================\n",
            "Token: ▁rapide\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.05287218191967521\n",
            "==================================================\n",
            "Token: ▁souverain\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.009644452993068214\n",
            "==================================================\n",
            "Token: ▁nos\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.04786275585554666\n",
            "==================================================\n",
            "Token: ▁e\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.11351277377599513\n",
            "==================================================\n",
            "Token: mission\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.08140611032894243\n",
            "==================================================\n",
            "Token: ▁CO\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.01320928128925576\n",
            "==================================================\n",
            "Token: ▁F\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.09861773589918282\n",
            "==================================================\n",
            "Token: AUX\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.033793553829801815\n",
            "==================================================\n",
            "Token: ▁C\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.11947672954718591\n",
            "==================================================\n",
            "Token: ▁ca\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.09888042924512831\n",
            "==================================================\n",
            "Token: ▁Projet\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.03905269876548915\n",
            "==================================================\n",
            "Token: Mac\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.036079116239316346\n",
            "==================================================\n",
            "Token: ron\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.021081242446920723\n",
            "==================================================\n",
            "Token: ▁Ba\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.02677241755397041\n",
            "==================================================\n",
            "Token: fou\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.045842210520434856\n",
            "==================================================\n",
            "Token: ▁travail\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.030506268237259087\n",
            "==================================================\n",
            "Token: ▁nombreux\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.04019129209999592\n",
            "==================================================\n",
            "Token: ▁expert\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.03142282076678814\n",
            "==================================================\n",
            "Token: -\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.3839845335538712\n",
            "==================================================\n",
            "Token: es\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.04062261664451431\n",
            "==================================================\n",
            "Token: ▁sujet\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.1050934909571161\n",
            "==================================================\n",
            "Token: ▁sc\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.5847707993447236\n",
            "==================================================\n",
            "Token: en\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.40330474045782116\n",
            "==================================================\n",
            "Token: ario\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.36769395639736\n",
            "==================================================\n",
            "Token: rte\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.12141441661073211\n",
            "==================================================\n",
            "Token: france\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.10452544184604944\n",
            "==================================================\n",
            "Token: W\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.020844187802208754\n",
            "==================================================\n",
            "Token: association\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.03206358456042072\n",
            "==================================================\n",
            "Token: ▁ad\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.05807002161558154\n",
            "==================================================\n",
            "Token: eme\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.06500019548939201\n",
            "==================================================\n",
            "Token: ▁s\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.28948973543683243\n",
            "==================================================\n",
            "Token: mier\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.12140081075573615\n",
            "==================================================\n",
            "Token: mont\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.07572671341032568\n",
            "==================================================\n",
            "Token: ▁Anne\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.10776287966838158\n",
            "==================================================\n",
            "Token: B\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.1502215310587666\n",
            "==================================================\n",
            "Token: ring\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.029507968108440728\n",
            "==================================================\n",
            "Token: ▁Et\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.017147675993392585\n",
            "==================================================\n",
            "Token: ▁tout\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.01300934116827809\n",
            "==================================================\n",
            "Token: ▁probleme\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.012751575482412597\n",
            "==================================================\n",
            "Token: ▁On\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.057769877824401156\n",
            "==================================================\n",
            "Token: arrive\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.08849533310829688\n",
            "==================================================\n",
            "Token: ▁toujours\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.009489904596359362\n",
            "==================================================\n",
            "Token: ▁sortir\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.13262848285864035\n",
            "==================================================\n",
            "Token: orn\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.5786554879388481\n",
            "==================================================\n",
            "Token: iere\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.5034091344019415\n",
            "==================================================\n",
            "Token: ▁En\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.12338038667770454\n",
            "==================================================\n",
            "Token: R\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.2496313021932664\n",
            "==================================================\n",
            "Token: ▁vs\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.11367889122746057\n",
            "==================================================\n",
            "Token: ▁alors\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.11827725549177286\n",
            "==================================================\n",
            "Token: bat\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.04977295178088228\n",
            "==================================================\n",
            "Token: ▁devrait\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.03819808702145536\n",
            "==================================================\n",
            "Token: ▁porter\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.06533712131142404\n",
            "==================================================\n",
            "Token: ▁sortie\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.02660349922773973\n",
            "==================================================\n",
            "Token: ▁certaine\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.030439957172685866\n",
            "==================================================\n",
            "Token: ie\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.11900372908333712\n",
            "==================================================\n",
            "Token: ▁qu\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.0876373727592547\n",
            "==================================================\n",
            "Token: ▁rater\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.08070159293545633\n",
            "==================================================\n",
            "Token: ait\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.08765181633025418\n",
            "==================================================\n",
            "Token: ▁combustible\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.057964693745861634\n",
            "==================================================\n",
            "Token: ▁fossiles\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.04837901946140133\n",
            "==================================================\n",
            "Token: ▁I\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.5400130779710037\n",
            "==================================================\n",
            "Token: OI\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.5778369538319422\n",
            "==================================================\n",
            "Token: OO\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.09468741265859089\n",
            "==================================================\n",
            "Token: ▁Fred\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.17327855651215224\n",
            "==================================================\n",
            "Token: Char\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.07772174780988471\n",
            "==================================================\n",
            "Token: don\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.18537424781637848\n",
            "==================================================\n",
            "Token: ▁So\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.182336719603396\n",
            "==================================================\n",
            "Token: bri\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.2665493610938637\n",
            "==================================================\n",
            "Token: ete\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.5321054516697026\n",
            "==================================================\n",
            "Token: ▁sans\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.331337987393905\n",
            "==================================================\n",
            "Token: ▁he\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.45291379249176317\n",
            "==================================================\n",
            "Token: itation\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.2937255727459643\n",
            "==================================================\n",
            "Token: ▁D\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.1980804375831241\n",
            "==================================================\n",
            "Token: ▁RT\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.7491955734354095\n",
            "==================================================\n",
            "Token: ▁N\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.21979110120501438\n",
            "==================================================\n",
            "Token: uke\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.28126021655542366\n",
            "==================================================\n",
            "Token: Info\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.13497266597969004\n",
            "==================================================\n",
            "Token: ▁Nouveau\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.18662515060379206\n",
            "==================================================\n",
            "Token: ▁retard\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.11446998604449972\n",
            "==================================================\n",
            "Token: EP\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.2830180962706778\n",
            "==================================================\n",
            "Token: ▁Flam\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.14053679312692105\n",
            "==================================================\n",
            "Token: an\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.07233189728366965\n",
            "==================================================\n",
            "Token: ville\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.1109033072812145\n",
            "==================================================\n",
            "Token: mar\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.12360411186525902\n",
            "==================================================\n",
            "Token: rage\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.10637768036100359\n",
            "==================================================\n",
            "Token: acteur\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.1102269105590041\n",
            "==================================================\n",
            "Token: ▁repousse\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.06925883754690611\n",
            "==================================================\n",
            "Token: cout\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.16756106706288454\n",
            "==================================================\n",
            "Token: ▁augmente\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.05339973993754915\n",
            "==================================================\n",
            "Token: ▁se\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.3855403423029331\n",
            "==================================================\n",
            "Token: rge\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.9318541408843573\n",
            "==================================================\n",
            "Token: r\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.2975913279502203\n",
            "==================================================\n",
            "Token: ▁Ah\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.019814892011779262\n",
            "==================================================\n",
            "Token: ▁mais\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.1270548945755596\n",
            "==================================================\n",
            "Token: ▁par\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.03194297534913784\n",
            "==================================================\n",
            "Token: ▁exemple\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.06427046870467956\n",
            "==================================================\n",
            "Token: quand\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.20013370624087992\n",
            "==================================================\n",
            "Token: ▁lit\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.09742083897735797\n",
            "==================================================\n",
            "Token: ▁rapport\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.031352302560802854\n",
            "==================================================\n",
            "Token: GIE\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.4886768371741019\n",
            "==================================================\n",
            "Token: C\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.3224368752562713\n",
            "==================================================\n",
            "Token: a\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.27449341541341316\n",
            "==================================================\n",
            "Token: per\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.07398523520939827\n",
            "==================================================\n",
            "Token: co\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.3870768849979652\n",
            "==================================================\n",
            "Token: it\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.047906508698766156\n",
            "==================================================\n",
            "Token: ▁fait\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.03805553293854247\n",
            "==================================================\n",
            "Token: ▁partie\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.09855164592375158\n",
            "==================================================\n",
            "Token: ▁solutions\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.04609385025179852\n",
            "==================================================\n",
            "Token: ▁Ou\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.07207170420970388\n",
            "==================================================\n",
            "Token: ▁sont\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.07916236010089753\n",
            "==================================================\n",
            "Token: ▁verts\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.07929447433976283\n",
            "==================================================\n",
            "Token: ▁ce\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.046856267982651724\n",
            "==================================================\n",
            "Token: ▁Ce\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.4182251863651918\n",
            "==================================================\n",
            "Token: ▁moi\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.06802596496699954\n",
            "==================================================\n",
            "Token: ▁militante\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.04991993973050657\n",
            "==================================================\n",
            "Token: ▁f\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.4295165944978915\n",
            "==================================================\n",
            "Token: mo\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.03361073413812519\n",
            "==================================================\n",
            "Token: mbo\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.03536660198816475\n",
            "==================================================\n",
            "Token: isse\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.2636798990408094\n",
            "==================================================\n",
            "Token: ▁Pour\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.02881941026276236\n",
            "==================================================\n",
            "Token: ▁pallier\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.029412808381761295\n",
            "==================================================\n",
            "Token: abandon\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.06954152995452856\n",
            "==================================================\n",
            "Token: ▁charbon\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.018374997331598048\n",
            "==================================================\n",
            "Token: Allemagne\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.10147020172645654\n",
            "==================================================\n",
            "Token: ▁veut\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.08900986780922461\n",
            "==================================================\n",
            "Token: ▁importe\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.13243446479768492\n",
            "==================================================\n",
            "Token: hydro\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.362204020342404\n",
            "==================================================\n",
            "Token: gene\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.14555807309081287\n",
            "==================================================\n",
            "Token: ▁car\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.651550784584209\n",
            "==================================================\n",
            "Token: go\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.5211446040382975\n",
            "==================================================\n",
            "Token: ▁pro\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.15755428127081386\n",
            "==================================================\n",
            "Token: pulse\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.0769716534101548\n",
            "==================================================\n",
            "Token: ▁au\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.10613184460883625\n",
            "==================================================\n",
            "Token: ▁fu\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.06550545385171871\n",
            "==================================================\n",
            "Token: ▁Al\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.14559471688534786\n",
            "==================================================\n",
            "Token: ter\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.030093701797937026\n",
            "==================================================\n",
            "Token: K\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.4249368716157058\n",
            "==================================================\n",
            "Token: ap\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.12548267781884906\n",
            "==================================================\n",
            "Token: ita\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.081999610569691\n",
            "==================================================\n",
            "Token: ▁Super\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.10807157812789732\n",
            "==================================================\n",
            "Token: ▁interview\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.07958206899423531\n",
            "==================================================\n",
            "Token: ▁Vin\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.10095677911196912\n",
            "==================================================\n",
            "Token: c\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.14195491630218635\n",
            "==================================================\n",
            "Token: ze\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.1711112973322741\n",
            "==================================================\n",
            "Token: De\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.10465403996137447\n",
            "==================================================\n",
            "Token: g\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.22838454003538286\n",
            "==================================================\n",
            "Token: row\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.2169568253938439\n",
            "==================================================\n",
            "Token: th\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.08492063457148705\n",
            "==================================================\n",
            "Token: ▁sommes\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.0836983266657936\n",
            "==================================================\n",
            "Token: ▁en\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.2877691605252897\n",
            "==================================================\n",
            "Token: ferme\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.16326924785402178\n",
            "==================================================\n",
            "Token: ▁dans\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.3727797319798287\n",
            "==================================================\n",
            "Token: ▁religion\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.16059983829626212\n",
            "==================================================\n",
            "Token: ▁E\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.048939476015845904\n",
            "==================================================\n",
            "Token: ons\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.0643786351004525\n",
            "==================================================\n",
            "Token: or\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.0381751651934162\n",
            "==================================================\n",
            "Token: ▁Entre\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.07344026711282564\n",
            "==================================================\n",
            "Token: ▁trans\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.12126428648097032\n",
            "==================================================\n",
            "Token: activiste\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.8740662152849973\n",
            "==================================================\n",
            "Token: ▁my\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.08136073148971337\n",
            "==================================================\n",
            "Token: ope\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.02545401704429939\n",
            "==================================================\n",
            "Token: bonne\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.3161695131596587\n",
            "==================================================\n",
            "Token: nt\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.38387633870694\n",
            "==================================================\n",
            "Token: ▁puis\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.06796732848855502\n",
            "==================================================\n",
            "Token: ▁des\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.0804313858606853\n",
            "==================================================\n",
            "Token: ▁troll\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.007805885853826794\n",
            "==================================================\n",
            "Token: ▁soutien\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.07584834218339033\n",
            "==================================================\n",
            "Token: lev\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.23220638748174893\n",
            "==================================================\n",
            "Token: eurs\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.40506930479693987\n",
            "==================================================\n",
            "Token: ▁intensif\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.08956628676936122\n",
            "==================================================\n",
            "Token: agriculture\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.31852865925429513\n",
            "==================================================\n",
            "Token: product\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.18383358755537318\n",
            "==================================================\n",
            "Token: iv\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.1682508349870194\n",
            "==================================================\n",
            "Token: iste\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.25958850225282365\n",
            "==================================================\n",
            "Token: ▁comment\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.03545608636173271\n",
            "==================================================\n",
            "Token: ent\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.052712282125197706\n",
            "==================================================\n",
            "Token: ▁cote\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.043594849190995405\n",
            "==================================================\n",
            "Token: ▁plaque\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.04866821858562426\n",
            "==================================================\n",
            "Token: ▁peux\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.1514929798779987\n",
            "==================================================\n",
            "Token: ▁Marc\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.05485449234133128\n",
            "==================================================\n",
            "Token: ▁Les\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.07933887932311023\n",
            "==================================================\n",
            "Token: ggy\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.03598031867536221\n",
            "==================================================\n",
            "Token: ▁met\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.1072088874538373\n",
            "==================================================\n",
            "Token: ▁favoris\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.027993982621828086\n",
            "==================================================\n",
            "Token: ▁b\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.010665818361802748\n",
            "==================================================\n",
            "Token: omb\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.1790605069033983\n",
            "==================================================\n",
            "Token: equipe\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.18989093413885993\n",
            "==================================================\n",
            "Token: ▁journal\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.17000050333011396\n",
            "==================================================\n",
            "Token: aviation\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.11181989808972802\n",
            "==================================================\n",
            "Token: read\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.21360148185131184\n",
            "==================================================\n",
            "Token: y\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.1443711408492329\n",
            "==================================================\n",
            "Token: ▁route\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.3472790351361145\n",
            "==================================================\n",
            "Token: ▁Dub\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.10467722096413781\n",
            "==================================================\n",
            "Token: ai\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.15954645468943723\n",
            "==================================================\n",
            "Token: Air\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.2241903051431998\n",
            "==================================================\n",
            "Token: show\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.09646319461749614\n",
            "==================================================\n",
            "Token: ▁Premier\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.03890056685891022\n",
            "==================================================\n",
            "Token: ▁segment\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.07166776277992323\n",
            "==================================================\n",
            "Token: ▁-\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.03993547337126255\n",
            "==================================================\n",
            "Token: ER\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.04826768960816607\n",
            "==================================================\n",
            "Token: ▁q\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.18503147261956174\n",
            "==================================================\n",
            "Token: tar\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.26892261789649075\n",
            "==================================================\n",
            "Token: air\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.34636950544864914\n",
            "==================================================\n",
            "Token: way\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.32549219709453825\n",
            "==================================================\n",
            "Token: ET\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.16842444216810204\n",
            "==================================================\n",
            "Token: ▁R\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.029683259273348105\n",
            "==================================================\n",
            "Token: MC\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.05053720358717621\n",
            "==================================================\n",
            "Token: St\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.07464061916560902\n",
            "==================================================\n",
            "Token: ory\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.07646007899905749\n",
            "==================================================\n",
            "Token: ▁poulet\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.5637003541739142\n",
            "==================================================\n",
            "Token: ▁consomme\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.07407397652066008\n",
            "==================================================\n",
            "Token: ▁France\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.04992853558286637\n",
            "==================================================\n",
            "Token: ▁scandale\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.06190081519579054\n",
            "==================================================\n",
            "Token: ux\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.9390636837835316\n",
            "==================================================\n",
            "Token: peak\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.01667787737728898\n",
            "==================================================\n",
            "Token: ing\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.02618783649350497\n",
            "==================================================\n",
            "Token: head\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.040242000974616214\n",
            "==================================================\n",
            "Token: Je\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.08110690861187002\n",
            "==================================================\n",
            "Token: ▁trouve\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.09214963709123522\n",
            "==================================================\n",
            "Token: ▁consommateurs\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.20726750262891097\n",
            "==================================================\n",
            "Token: ▁d\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.09335706738879551\n",
            "==================================================\n",
            "Token: ▁Hel\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.13733046330206372\n",
            "==================================================\n",
            "Token: T\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.11101990350979046\n",
            "==================================================\n",
            "Token: hou\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.14088631397964477\n",
            "==================================================\n",
            "Token: ▁Parti\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.054222123685844\n",
            "==================================================\n",
            "Token: Anim\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.14157396600478092\n",
            "==================================================\n",
            "Token: aliste\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.14077331825733344\n",
            "==================================================\n",
            "Token: ▁TF\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.14447861471321014\n",
            "==================================================\n",
            "Token: ▁Terr\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.10850688924979736\n",
            "==================================================\n",
            "Token: ine\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.18974100859353493\n",
            "==================================================\n",
            "Token: ▁Pat\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.4140370089647672\n",
            "==================================================\n",
            "Token: ▁man\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.03586946372397595\n",
            "==================================================\n",
            "Token: sh\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.137053038077154\n",
            "==================================================\n",
            "Token: ru\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.15784424239865552\n",
            "==================================================\n",
            "Token: gging\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.7193486612970815\n",
            "==================================================\n",
            "Token: lia\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.807171431922697\n",
            "==================================================\n",
            "Token: G\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.16539092553014276\n",
            "==================================================\n",
            "Token: tier\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.26679269591040083\n",
            "==================================================\n",
            "Token: ▁Ka\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.06228026202748635\n",
            "==================================================\n",
            "Token: ko\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.09588835738239829\n",
            "==================================================\n",
            "Token: line\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.11398718039034912\n",
            "==================================================\n",
            "Token: ▁reste\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.07395851367222883\n",
            "==================================================\n",
            "Token: ▁entre\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.1798211446305738\n",
            "==================================================\n",
            "Token: ra\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.14654894339919733\n",
            "==================================================\n",
            "Token: ▁service\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.0311312296647331\n",
            "==================================================\n",
            "Token: ▁avant\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.06557372314200743\n",
            "==================================================\n",
            "Token: ▁confirme\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.0657640759626665\n",
            "==================================================\n",
            "Token: ▁bien\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.06680426279786433\n",
            "==================================================\n",
            "Token: ▁mon\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.12901976157220715\n",
            "==================================================\n",
            "Token: ▁point\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.05384026430917166\n",
            "==================================================\n",
            "Token: anticipation\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.06432910612146614\n",
            "==================================================\n",
            "Token: ▁om\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.045873236979672175\n",
            "==================================================\n",
            "Token: ette\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.063113419836146\n",
            "==================================================\n",
            "Token: z\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.08351517283284689\n",
            "==================================================\n",
            "Token: ▁role\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.052524282640291235\n",
            "==================================================\n",
            "Token: aste\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.12736345764166357\n",
            "==================================================\n",
            "Token: information\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.10986309527453886\n",
            "==================================================\n",
            "Token: ▁anti\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.159238613962707\n",
            "==================================================\n",
            "Token: nu\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.06457894656899082\n",
            "==================================================\n",
            "Token: ▁citoyens\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.3148444792973715\n",
            "==================================================\n",
            "Token: croissance\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.32994434237232384\n",
            "==================================================\n",
            "Token: ▁une\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.3246493252584137\n",
            "==================================================\n",
            "Token: ▁option\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.11312765202697182\n",
            "==================================================\n",
            "Token: ▁pays\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.11249428298173356\n",
            "==================================================\n",
            "Token: ▁pauvres\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.16427566574124766\n",
            "==================================================\n",
            "Token: ▁ou\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.1594616878552052\n",
            "==================================================\n",
            "Token: ▁riches\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.12202989620967387\n",
            "==================================================\n",
            "Token: ▁face\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.22849214645331073\n",
            "==================================================\n",
            "Token: ▁changement\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.22553336639609553\n",
            "==================================================\n",
            "Token: ▁climatique\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.10326951426801335\n",
            "==================================================\n",
            "Token: ▁enjeux\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.14282868587043096\n",
            "==================================================\n",
            "Token: coup\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.22752861138017333\n",
            "==================================================\n",
            "Token: lage\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.1794503704063201\n",
            "==================================================\n",
            "Token: mand\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.007435925045358553\n",
            "==================================================\n",
            "Token: iez\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.4711412322754204\n",
            "==================================================\n",
            "Token: but\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.040945527038412956\n",
            "==================================================\n",
            "Token: ▁pourquoi\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.029757438203354834\n",
            "==================================================\n",
            "Token: ▁cette\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.035402376204624636\n",
            "==================================================\n",
            "Token: volution\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.02814037136958235\n",
            "==================================================\n",
            "Token: ▁positive\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.00593467960459405\n",
            "==================================================\n",
            "Token: opinion\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.026222102735262983\n",
            "==================================================\n",
            "Token: ▁Parce\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.011026966395668445\n",
            "==================================================\n",
            "Token: ▁climat\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.02146877651506864\n",
            "==================================================\n",
            "Token: ▁crise\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.02687958728840322\n",
            "==================================================\n",
            "Token: ge\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.02386549444071745\n",
            "==================================================\n",
            "Token: ▁deja\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.030611220096538404\n",
            "==================================================\n",
            "Token: ▁parce\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.026858616923454308\n",
            "==================================================\n",
            "Token: ▁apres\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.041126390970284664\n",
            "==================================================\n",
            "Token: ce\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.015563452246594167\n",
            "==================================================\n",
            "Token: nni\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.026791469414893295\n",
            "==================================================\n",
            "Token: ▁commencent\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.018305149993603147\n",
            "==================================================\n",
            "Token: ▁comprendre\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.007251392850224428\n",
            "==================================================\n",
            "Token: chet\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.07183108859247317\n",
            "==================================================\n",
            "Token: ▁ressemble\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.04346813424552314\n",
            "==================================================\n",
            "Token: ▁J\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.34866621780941864\n",
            "==================================================\n",
            "Token: ph\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.12652213150455416\n",
            "==================================================\n",
            "Token: guy\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.08517419888523843\n",
            "==================================================\n",
            "Token: ▁Tristan\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.029352689957830976\n",
            "==================================================\n",
            "Token: min\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.05464159087737277\n",
            "==================================================\n",
            "Token: ▁toute\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.07974379809602175\n",
            "==================================================\n",
            "Token: ▁fermeture\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.062146533448344116\n",
            "==================================================\n",
            "Token: ▁centrales\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.05850313491396672\n",
            "==================================================\n",
            "Token: ▁Europe\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.00506611877600972\n",
            "==================================================\n",
            "Token: ▁oblige\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.02364114316961115\n",
            "==================================================\n",
            "Token: ▁trouver\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.02028872284419171\n",
            "==================================================\n",
            "Token: ▁nouveaux\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.030612939620615554\n",
            "==================================================\n",
            "Token: ▁levier\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.03668721282107568\n",
            "==================================================\n",
            "Token: flex\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.03651173286382043\n",
            "==================================================\n",
            "Token: ibili\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.08302786852931343\n",
            "==================================================\n",
            "Token: ▁Donc\n",
            "Best Target Class: décroissance\n",
            "Attribution Score: 0.029554386592635727\n",
            "==================================================\n",
            "Token: ▁couper\n",
            "Best Target Class: nucléaire\n",
            "Attribution Score: 0.021459251392832196\n",
            "==================================================\n",
            "Token: ▁va\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.04986091303346024\n",
            "==================================================\n",
            "Token: ▁utiliser\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.019931774451674874\n",
            "==================================================\n",
            "Token: ▁ger\n",
            "Best Target Class: avion\n",
            "Attribution Score: 0.02363918038399604\n",
            "==================================================\n",
            "Token: ▁pointes\n",
            "Best Target Class: viande\n",
            "Attribution Score: 0.007199999016411133\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "#La fonction retourne pour chaque token le meilleur score d'attribution avec le target correspondent\n",
        "def create_clusters(scores):\n",
        "    class_labels = ['avion', 'décroissance', 'nucléaire', 'viande']\n",
        "    clusters = {token: {\"target_class\": None, \"token_score\": -float(\"inf\")} for _, target_scores in scores.items() for _, scores_dict in target_scores.items() for token in scores_dict[\"raw_input_ids\"]}\n",
        "\n",
        "    for sentence, target_scores in scores.items():\n",
        "        for target_class, scores_dict in target_scores.items():\n",
        "            word_attributions = scores_dict[\"word_attributions\"]\n",
        "\n",
        "            for i, token in enumerate(scores_dict[\"raw_input_ids\"]):\n",
        "                token_score = word_attributions[i]\n",
        "\n",
        "                if token_score > clusters[token][\"token_score\"]:\n",
        "                    clusters[token][\"token_score\"] = token_score\n",
        "                    clusters[token][\"target_class\"] = target_class\n",
        "\n",
        "    return clusters\n",
        "def display_clusters(clusters):\n",
        "    for token, info in clusters.items():\n",
        "        if info[\"token_score\"] > 0:\n",
        "            print(f\"Token: {token}\")\n",
        "            print(\"Best Target Class:\", info[\"target_class\"])\n",
        "            print(\"Attribution Score:\", info[\"token_score\"])\n",
        "            print(\"=\"*50)\n",
        "\n",
        "clusters = create_clusters(attribution_scores)\n",
        "\n",
        "display_clusters(clusters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUCu00z71rOV",
        "outputId": "fbc3dfc1-f3b9-49be-f9bd-7b178d98025f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cluster for Target Class: avion\n",
            "Token: ▁Pi\n",
            "Attribution Score: 0.984415388522172\n",
            "==================================================\n",
            "Token: ux\n",
            "Attribution Score: 0.9390636837835316\n",
            "==================================================\n",
            "Token: rge\n",
            "Attribution Score: 0.9318541408843573\n",
            "==================================================\n",
            "Token: ▁demande\n",
            "Attribution Score: 0.8928369788996585\n",
            "==================================================\n",
            "Token: activiste\n",
            "Attribution Score: 0.8740662152849973\n",
            "==================================================\n",
            "Token: lia\n",
            "Attribution Score: 0.807171431922697\n",
            "==================================================\n",
            "Token: ▁car\n",
            "Attribution Score: 0.651550784584209\n",
            "==================================================\n",
            "Token: ▁Air\n",
            "Attribution Score: 0.6397076525821597\n",
            "==================================================\n",
            "Token: OI\n",
            "Attribution Score: 0.5778369538319422\n",
            "==================================================\n",
            "Token: ▁I\n",
            "Attribution Score: 0.5400130779710037\n",
            "==================================================\n",
            "Token: go\n",
            "Attribution Score: 0.5211446040382975\n",
            "==================================================\n",
            "Token: iere\n",
            "Attribution Score: 0.5034091344019415\n",
            "==================================================\n",
            "Token: on\n",
            "Attribution Score: 0.4901638676481372\n",
            "==================================================\n",
            "Token: au\n",
            "Attribution Score: 0.47247978082866315\n",
            "==================================================\n",
            "Token: iez\n",
            "Attribution Score: 0.4711412322754204\n",
            "==================================================\n",
            "Token: ▁A\n",
            "Attribution Score: 0.45625158460972054\n",
            "==================================================\n",
            "Token: ▁pas\n",
            "Attribution Score: 0.4211286230168977\n",
            "==================================================\n",
            "Token: est\n",
            "Attribution Score: 0.38698257721523777\n",
            "==================================================\n",
            "Token: tique\n",
            "Attribution Score: 0.3637493038602273\n",
            "==================================================\n",
            "Token: er\n",
            "Attribution Score: 0.35684690875355574\n",
            "==================================================\n",
            "Token: ▁route\n",
            "Attribution Score: 0.3472790351361145\n",
            "==================================================\n",
            "Token: air\n",
            "Attribution Score: 0.34636950544864914\n",
            "==================================================\n",
            "Token: ▁pour\n",
            "Attribution Score: 0.33022102763587224\n",
            "==================================================\n",
            "Token: way\n",
            "Attribution Score: 0.32549219709453825\n",
            "==================================================\n",
            "Token: ▁n\n",
            "Attribution Score: 0.30462489765952433\n",
            "==================================================\n",
            "Token: ▁en\n",
            "Attribution Score: 0.2877691605252897\n",
            "==================================================\n",
            "Token: ossi\n",
            "Attribution Score: 0.27430782462470077\n",
            "==================================================\n",
            "Token: tar\n",
            "Attribution Score: 0.26892261789649075\n",
            "==================================================\n",
            "Token: bri\n",
            "Attribution Score: 0.2665493610938637\n",
            "==================================================\n",
            "Token: ▁Royal\n",
            "Attribution Score: 0.22692242298520204\n",
            "==================================================\n",
            "Token: ▁L\n",
            "Attribution Score: 0.2255467227364542\n",
            "==================================================\n",
            "Token: Air\n",
            "Attribution Score: 0.2241903051431998\n",
            "==================================================\n",
            "Token: X\n",
            "Attribution Score: 0.21569536098849118\n",
            "==================================================\n",
            "Token: don\n",
            "Attribution Score: 0.18537424781637848\n",
            "==================================================\n",
            "Token: lage\n",
            "Attribution Score: 0.1794503704063201\n",
            "==================================================\n",
            "Token: omb\n",
            "Attribution Score: 0.1790605069033983\n",
            "==================================================\n",
            "Token: ai\n",
            "Attribution Score: 0.15954645468943723\n",
            "==================================================\n",
            "Token: Aviation\n",
            "Attribution Score: 0.1581918693694628\n",
            "==================================================\n",
            "Token: ▁Da\n",
            "Attribution Score: 0.15761228516167458\n",
            "==================================================\n",
            "Token: B\n",
            "Attribution Score: 0.1502215310587666\n",
            "==================================================\n",
            "Token: ▁leur\n",
            "Attribution Score: 0.12109592984246134\n",
            "==================================================\n",
            "Token: ▁que\n",
            "Attribution Score: 0.11628192689095129\n",
            "==================================================\n",
            "Token: aviation\n",
            "Attribution Score: 0.11181989808972802\n",
            "==================================================\n",
            "Token: information\n",
            "Attribution Score: 0.10986309527453886\n",
            "==================================================\n",
            "Token: ▁Dub\n",
            "Attribution Score: 0.10467722096413781\n",
            "==================================================\n",
            "Token: ▁F\n",
            "Attribution Score: 0.09861773589918282\n",
            "==================================================\n",
            "Token: show\n",
            "Attribution Score: 0.09646319461749614\n",
            "==================================================\n",
            "Token: ft\n",
            "Attribution Score: 0.08839590808017861\n",
            "==================================================\n",
            "Token: ait\n",
            "Attribution Score: 0.08765181633025418\n",
            "==================================================\n",
            "Token: ▁a\n",
            "Attribution Score: 0.08694406028070448\n",
            "==================================================\n",
            "Token: ▁toute\n",
            "Attribution Score: 0.07974379809602175\n",
            "==================================================\n",
            "Token: ▁frais\n",
            "Attribution Score: 0.07791346568933331\n",
            "==================================================\n",
            "Token: Char\n",
            "Attribution Score: 0.07772174780988471\n",
            "==================================================\n",
            "Token: ▁reste\n",
            "Attribution Score: 0.07395851367222883\n",
            "==================================================\n",
            "Token: fen\n",
            "Attribution Score: 0.0704347733155237\n",
            "==================================================\n",
            "Token: ▁porter\n",
            "Attribution Score: 0.06533712131142404\n",
            "==================================================\n",
            "Token: eme\n",
            "Attribution Score: 0.06500019548939201\n",
            "==================================================\n",
            "Token: nu\n",
            "Attribution Score: 0.06457894656899082\n",
            "==================================================\n",
            "Token: ▁ad\n",
            "Attribution Score: 0.05807002161558154\n",
            "==================================================\n",
            "Token: ▁combustible\n",
            "Attribution Score: 0.057964693745861634\n",
            "==================================================\n",
            "Token: ▁On\n",
            "Attribution Score: 0.057769877824401156\n",
            "==================================================\n",
            "Token: ▁Parti\n",
            "Attribution Score: 0.054222123685844\n",
            "==================================================\n",
            "Token: ▁point\n",
            "Attribution Score: 0.05384026430917166\n",
            "==================================================\n",
            "Token: ▁fonctionne\n",
            "Attribution Score: 0.053586959316772036\n",
            "==================================================\n",
            "Token: ▁rapide\n",
            "Attribution Score: 0.05287218191967521\n",
            "==================================================\n",
            "Token: ▁va\n",
            "Attribution Score: 0.04986091303346024\n",
            "==================================================\n",
            "Token: ▁plaque\n",
            "Attribution Score: 0.04866821858562426\n",
            "==================================================\n",
            "Token: ▁fossiles\n",
            "Attribution Score: 0.04837901946140133\n",
            "==================================================\n",
            "Token: ER\n",
            "Attribution Score: 0.04826768960816607\n",
            "==================================================\n",
            "Token: dent\n",
            "Attribution Score: 0.04762495453006347\n",
            "==================================================\n",
            "Token: issement\n",
            "Attribution Score: 0.045166160086249296\n",
            "==================================================\n",
            "Token: vez\n",
            "Attribution Score: 0.04307404016583673\n",
            "==================================================\n",
            "Token: ▁un\n",
            "Attribution Score: 0.04280291728844187\n",
            "==================================================\n",
            "Token: ▁-\n",
            "Attribution Score: 0.03993547337126255\n",
            "==================================================\n",
            "Token: ▁el\n",
            "Attribution Score: 0.038264215832091115\n",
            "==================================================\n",
            "Token: ▁devrait\n",
            "Attribution Score: 0.03819808702145536\n",
            "==================================================\n",
            "Token: or\n",
            "Attribution Score: 0.0381751651934162\n",
            "==================================================\n",
            "Token: ▁Quand\n",
            "Attribution Score: 0.037907798017976814\n",
            "==================================================\n",
            "Token: ▁man\n",
            "Attribution Score: 0.03586946372397595\n",
            "==================================================\n",
            "Token: mbo\n",
            "Attribution Score: 0.03536660198816475\n",
            "==================================================\n",
            "Token: association\n",
            "Attribution Score: 0.03206358456042072\n",
            "==================================================\n",
            "Token: ▁expert\n",
            "Attribution Score: 0.03142282076678814\n",
            "==================================================\n",
            "Token: ▁certaine\n",
            "Attribution Score: 0.030439957172685866\n",
            "==================================================\n",
            "Token: ▁favoris\n",
            "Attribution Score: 0.027993982621828086\n",
            "==================================================\n",
            "Token: ▁parce\n",
            "Attribution Score: 0.026858616923454308\n",
            "==================================================\n",
            "Token: ▁ger\n",
            "Attribution Score: 0.02363918038399604\n",
            "==================================================\n",
            "Token: ▁utiliser\n",
            "Attribution Score: 0.019931774451674874\n",
            "==================================================\n",
            "Token: ▁Ah\n",
            "Attribution Score: 0.019814892011779262\n",
            "==================================================\n",
            "Token: ce\n",
            "Attribution Score: 0.015563452246594167\n",
            "==================================================\n",
            "Token: ▁Europe\n",
            "Attribution Score: 0.00506611877600972\n",
            "==================================================\n",
            "Cluster for Target Class: décroissance\n",
            "Token: ▁croissance\n",
            "Attribution Score: 0.7020711865573456\n",
            "==================================================\n",
            "Token: ▁sc\n",
            "Attribution Score: 0.5847707993447236\n",
            "==================================================\n",
            "Token: ete\n",
            "Attribution Score: 0.5321054516697026\n",
            "==================================================\n",
            "Token: GIE\n",
            "Attribution Score: 0.4886768371741019\n",
            "==================================================\n",
            "Token: e\n",
            "Attribution Score: 0.4662529792399467\n",
            "==================================================\n",
            "Token: s\n",
            "Attribution Score: 0.45922253794343626\n",
            "==================================================\n",
            "Token: ▁he\n",
            "Attribution Score: 0.45291379249176317\n",
            "==================================================\n",
            "Token: _\n",
            "Attribution Score: 0.4405221841436491\n",
            "==================================================\n",
            "Token: ▁schiste\n",
            "Attribution Score: 0.43625287946658314\n",
            "==================================================\n",
            "Token: en\n",
            "Attribution Score: 0.40330474045782116\n",
            "==================================================\n",
            "Token: ▁propre\n",
            "Attribution Score: 0.3891448028162005\n",
            "==================================================\n",
            "Token: co\n",
            "Attribution Score: 0.3870768849979652\n",
            "==================================================\n",
            "Token: ▁se\n",
            "Attribution Score: 0.3855403423029331\n",
            "==================================================\n",
            "Token: nt\n",
            "Attribution Score: 0.38387633870694\n",
            "==================================================\n",
            "Token: ▁dans\n",
            "Attribution Score: 0.3727797319798287\n",
            "==================================================\n",
            "Token: ario\n",
            "Attribution Score: 0.36769395639736\n",
            "==================================================\n",
            "Token: hydro\n",
            "Attribution Score: 0.362204020342404\n",
            "==================================================\n",
            "Token: ▁sa\n",
            "Attribution Score: 0.35178025183130407\n",
            "==================================================\n",
            "Token: ▁Force\n",
            "Attribution Score: 0.3456002736748095\n",
            "==================================================\n",
            "Token: ▁sans\n",
            "Attribution Score: 0.331337987393905\n",
            "==================================================\n",
            "Token: ▁une\n",
            "Attribution Score: 0.3246493252584137\n",
            "==================================================\n",
            "Token: C\n",
            "Attribution Score: 0.3224368752562713\n",
            "==================================================\n",
            "Token: bonne\n",
            "Attribution Score: 0.3161695131596587\n",
            "==================================================\n",
            "Token: ▁Deux\n",
            "Attribution Score: 0.29759305767744826\n",
            "==================================================\n",
            "Token: itation\n",
            "Attribution Score: 0.2937255727459643\n",
            "==================================================\n",
            "Token: ▁s\n",
            "Attribution Score: 0.28948973543683243\n",
            "==================================================\n",
            "Token: a\n",
            "Attribution Score: 0.27449341541341316\n",
            "==================================================\n",
            "Token: iste\n",
            "Attribution Score: 0.25958850225282365\n",
            "==================================================\n",
            "Token: hor\n",
            "Attribution Score: 0.2568652998750119\n",
            "==================================================\n",
            "Token: ▁CGT\n",
            "Attribution Score: 0.23457096052128212\n",
            "==================================================\n",
            "Token: g\n",
            "Attribution Score: 0.22838454003538286\n",
            "==================================================\n",
            "Token: ▁changement\n",
            "Attribution Score: 0.22553336639609553\n",
            "==================================================\n",
            "Token: row\n",
            "Attribution Score: 0.2169568253938439\n",
            "==================================================\n",
            "Token: read\n",
            "Attribution Score: 0.21360148185131184\n",
            "==================================================\n",
            "Token: ▁Falcon\n",
            "Attribution Score: 0.2021206260676947\n",
            "==================================================\n",
            "Token: im\n",
            "Attribution Score: 0.18965749403223842\n",
            "==================================================\n",
            "Token: ▁q\n",
            "Attribution Score: 0.18503147261956174\n",
            "==================================================\n",
            "Token: product\n",
            "Attribution Score: 0.18383358755537318\n",
            "==================================================\n",
            "Token: ▁So\n",
            "Attribution Score: 0.182336719603396\n",
            "==================================================\n",
            "Token: ▁log\n",
            "Attribution Score: 0.17068018318416653\n",
            "==================================================\n",
            "Token: ▁journal\n",
            "Attribution Score: 0.17000050333011396\n",
            "==================================================\n",
            "Token: ET\n",
            "Attribution Score: 0.16842444216810204\n",
            "==================================================\n",
            "Token: iv\n",
            "Attribution Score: 0.1682508349870194\n",
            "==================================================\n",
            "Token: ▁pauvres\n",
            "Attribution Score: 0.16427566574124766\n",
            "==================================================\n",
            "Token: ▁aussi\n",
            "Attribution Score: 0.16097155469635166\n",
            "==================================================\n",
            "Token: ▁religion\n",
            "Attribution Score: 0.16059983829626212\n",
            "==================================================\n",
            "Token: ▁ou\n",
            "Attribution Score: 0.1594616878552052\n",
            "==================================================\n",
            "Token: ▁anti\n",
            "Attribution Score: 0.159238613962707\n",
            "==================================================\n",
            "Token: ▁pro\n",
            "Attribution Score: 0.15755428127081386\n",
            "==================================================\n",
            "Token: y\n",
            "Attribution Score: 0.1443711408492329\n",
            "==================================================\n",
            "Token: ▁enjeux\n",
            "Attribution Score: 0.14282868587043096\n",
            "==================================================\n",
            "Token: ▁importe\n",
            "Attribution Score: 0.13243446479768492\n",
            "==================================================\n",
            "Token: ▁mon\n",
            "Attribution Score: 0.12901976157220715\n",
            "==================================================\n",
            "Token: aste\n",
            "Attribution Score: 0.12736345764166357\n",
            "==================================================\n",
            "Token: ▁mais\n",
            "Attribution Score: 0.1270548945755596\n",
            "==================================================\n",
            "Token: ▁riches\n",
            "Attribution Score: 0.12202989620967387\n",
            "==================================================\n",
            "Token: rte\n",
            "Attribution Score: 0.12141441661073211\n",
            "==================================================\n",
            "Token: ▁C\n",
            "Attribution Score: 0.11947672954718591\n",
            "==================================================\n",
            "Token: ▁plus\n",
            "Attribution Score: 0.1113800642420519\n",
            "==================================================\n",
            "Token: ▁au\n",
            "Attribution Score: 0.10613184460883625\n",
            "==================================================\n",
            "Token: france\n",
            "Attribution Score: 0.10452544184604944\n",
            "==================================================\n",
            "Token: ▁climatique\n",
            "Attribution Score: 0.10326951426801335\n",
            "==================================================\n",
            "Token: Allemagne\n",
            "Attribution Score: 0.10147020172645654\n",
            "==================================================\n",
            "Token: ▁Alliance\n",
            "Attribution Score: 0.09811836513870421\n",
            "==================================================\n",
            "Token: ▁lit\n",
            "Attribution Score: 0.09742083897735797\n",
            "==================================================\n",
            "Token: ▁histoire\n",
            "Attribution Score: 0.09694531804273875\n",
            "==================================================\n",
            "Token: bili\n",
            "Attribution Score: 0.09064176122565791\n",
            "==================================================\n",
            "Token: industrie\n",
            "Attribution Score: 0.09003209035384407\n",
            "==================================================\n",
            "Token: ▁veut\n",
            "Attribution Score: 0.08900986780922461\n",
            "==================================================\n",
            "Token: te\n",
            "Attribution Score: 0.08826473172532884\n",
            "==================================================\n",
            "Token: nes\n",
            "Attribution Score: 0.08779008136990961\n",
            "==================================================\n",
            "Token: th\n",
            "Attribution Score: 0.08492063457148705\n",
            "==================================================\n",
            "Token: ▁sommes\n",
            "Attribution Score: 0.0836983266657936\n",
            "==================================================\n",
            "Token: z\n",
            "Attribution Score: 0.08351517283284689\n",
            "==================================================\n",
            "Token: ibili\n",
            "Attribution Score: 0.08302786852931343\n",
            "==================================================\n",
            "Token: ▁Bu\n",
            "Attribution Score: 0.08181506620778657\n",
            "==================================================\n",
            "Token: ▁my\n",
            "Attribution Score: 0.08136073148971337\n",
            "==================================================\n",
            "Token: tache\n",
            "Attribution Score: 0.07797205046936781\n",
            "==================================================\n",
            "Token: pulse\n",
            "Attribution Score: 0.0769716534101548\n",
            "==================================================\n",
            "Token: ory\n",
            "Attribution Score: 0.07646007899905749\n",
            "==================================================\n",
            "Token: ▁soutien\n",
            "Attribution Score: 0.07584834218339033\n",
            "==================================================\n",
            "Token: ▁notre\n",
            "Attribution Score: 0.07415465180991808\n",
            "==================================================\n",
            "Token: ▁consomme\n",
            "Attribution Score: 0.07407397652066008\n",
            "==================================================\n",
            "Token: chet\n",
            "Attribution Score: 0.07183108859247317\n",
            "==================================================\n",
            "Token: pl\n",
            "Attribution Score: 0.07137745013910402\n",
            "==================================================\n",
            "Token: ▁puis\n",
            "Attribution Score: 0.06796732848855502\n",
            "==================================================\n",
            "Token: re\n",
            "Attribution Score: 0.06792975791838012\n",
            "==================================================\n",
            "Token: ▁fu\n",
            "Attribution Score: 0.06550545385171871\n",
            "==================================================\n",
            "Token: ons\n",
            "Attribution Score: 0.0643786351004525\n",
            "==================================================\n",
            "Token: ette\n",
            "Attribution Score: 0.063113419836146\n",
            "==================================================\n",
            "Token: ▁scandale\n",
            "Attribution Score: 0.06190081519579054\n",
            "==================================================\n",
            "Token: ▁repond\n",
            "Attribution Score: 0.056691192231869865\n",
            "==================================================\n",
            "Token: the\n",
            "Attribution Score: 0.052678324059739844\n",
            "==================================================\n",
            "Token: MC\n",
            "Attribution Score: 0.05053720358717621\n",
            "==================================================\n",
            "Token: ▁travailleurs\n",
            "Attribution Score: 0.050297077413856105\n",
            "==================================================\n",
            "Token: ▁E\n",
            "Attribution Score: 0.048939476015845904\n",
            "==================================================\n",
            "Token: it\n",
            "Attribution Score: 0.047906508698766156\n",
            "==================================================\n",
            "Token: duire\n",
            "Attribution Score: 0.04751765690073941\n",
            "==================================================\n",
            "Token: ▁solutions\n",
            "Attribution Score: 0.04609385025179852\n",
            "==================================================\n",
            "Token: ▁sombres\n",
            "Attribution Score: 0.043815518499535404\n",
            "==================================================\n",
            "Token: ▁seul\n",
            "Attribution Score: 0.04089857849404522\n",
            "==================================================\n",
            "Token: es\n",
            "Attribution Score: 0.04062261664451431\n",
            "==================================================\n",
            "Token: head\n",
            "Attribution Score: 0.040242000974616214\n",
            "==================================================\n",
            "Token: ▁nombreux\n",
            "Attribution Score: 0.04019129209999592\n",
            "==================================================\n",
            "Token: ▁Projet\n",
            "Attribution Score: 0.03905269876548915\n",
            "==================================================\n",
            "Token: ▁levier\n",
            "Attribution Score: 0.03668721282107568\n",
            "==================================================\n",
            "Token: flex\n",
            "Attribution Score: 0.03651173286382043\n",
            "==================================================\n",
            "Token: ▁par\n",
            "Attribution Score: 0.03194297534913784\n",
            "==================================================\n",
            "Token: ▁nouveaux\n",
            "Attribution Score: 0.030612939620615554\n",
            "==================================================\n",
            "Token: ▁R\n",
            "Attribution Score: 0.029683259273348105\n",
            "==================================================\n",
            "Token: ▁Donc\n",
            "Attribution Score: 0.029554386592635727\n",
            "==================================================\n",
            "Token: volution\n",
            "Attribution Score: 0.02814037136958235\n",
            "==================================================\n",
            "Token: ▁compare\n",
            "Attribution Score: 0.027187018148143605\n",
            "==================================================\n",
            "Token: ▁perdent\n",
            "Attribution Score: 0.026874853386511376\n",
            "==================================================\n",
            "Token: nni\n",
            "Attribution Score: 0.026791469414893295\n",
            "==================================================\n",
            "Token: ▁Ba\n",
            "Attribution Score: 0.02677241755397041\n",
            "==================================================\n",
            "Token: opinion\n",
            "Attribution Score: 0.026222102735262983\n",
            "==================================================\n",
            "Token: ing\n",
            "Attribution Score: 0.02618783649350497\n",
            "==================================================\n",
            "Token: ▁mix\n",
            "Attribution Score: 0.023865795466881612\n",
            "==================================================\n",
            "Token: ron\n",
            "Attribution Score: 0.021081242446920723\n",
            "==================================================\n",
            "Token: W\n",
            "Attribution Score: 0.020844187802208754\n",
            "==================================================\n",
            "Token: ▁trouver\n",
            "Attribution Score: 0.02028872284419171\n",
            "==================================================\n",
            "Token: ▁moindre\n",
            "Attribution Score: 0.018447519457942117\n",
            "==================================================\n",
            "Token: ▁charbon\n",
            "Attribution Score: 0.018374997331598048\n",
            "==================================================\n",
            "Token: ▁Et\n",
            "Attribution Score: 0.017147675993392585\n",
            "==================================================\n",
            "Token: peak\n",
            "Attribution Score: 0.01667787737728898\n",
            "==================================================\n",
            "Token: ▁efficace\n",
            "Attribution Score: 0.011968802384845451\n",
            "==================================================\n",
            "Token: ▁b\n",
            "Attribution Score: 0.010665818361802748\n",
            "==================================================\n",
            "Token: ▁souverain\n",
            "Attribution Score: 0.009644452993068214\n",
            "==================================================\n",
            "Token: ▁virgule\n",
            "Attribution Score: -0.008918696988323887\n",
            "==================================================\n",
            "Cluster for Target Class: nucléaire\n",
            "Token: ault\n",
            "Attribution Score: 0.793172885681329\n",
            "==================================================\n",
            "Token: gging\n",
            "Attribution Score: 0.7193486612970815\n",
            "==================================================\n",
            "Token: mark\n",
            "Attribution Score: 0.6320039052910488\n",
            "==================================================\n",
            "Token: aire\n",
            "Attribution Score: 0.6176532403843716\n",
            "==================================================\n",
            "Token: ▁nu\n",
            "Attribution Score: 0.5699277525555054\n",
            "==================================================\n",
            "Token: cle\n",
            "Attribution Score: 0.5098030801479283\n",
            "==================================================\n",
            "Token: tro\n",
            "Attribution Score: 0.4682227257771468\n",
            "==================================================\n",
            "Token: K\n",
            "Attribution Score: 0.4249368716157058\n",
            "==================================================\n",
            "Token: le\n",
            "Attribution Score: 0.3584638774651852\n",
            "==================================================\n",
            "Token: ern\n",
            "Attribution Score: 0.3441451163973267\n",
            "==================================================\n",
            "Token: ▁citoyens\n",
            "Attribution Score: 0.3148444792973715\n",
            "==================================================\n",
            "Token: EP\n",
            "Attribution Score: 0.2830180962706778\n",
            "==================================================\n",
            "Token: R\n",
            "Attribution Score: 0.2496313021932664\n",
            "==================================================\n",
            "Token: ▁consommateurs\n",
            "Attribution Score: 0.20726750262891097\n",
            "==================================================\n",
            "Token: quand\n",
            "Attribution Score: 0.20013370624087992\n",
            "==================================================\n",
            "Token: ▁D\n",
            "Attribution Score: 0.1980804375831241\n",
            "==================================================\n",
            "Token: ▁Nouveau\n",
            "Attribution Score: 0.18662515060379206\n",
            "==================================================\n",
            "Token: ▁entre\n",
            "Attribution Score: 0.1798211446305738\n",
            "==================================================\n",
            "Token: one\n",
            "Attribution Score: 0.1546356860452948\n",
            "==================================================\n",
            "Token: ▁re\n",
            "Attribution Score: 0.1504424120288401\n",
            "==================================================\n",
            "Token: ▁ne\n",
            "Attribution Score: 0.14757367903827018\n",
            "==================================================\n",
            "Token: ra\n",
            "Attribution Score: 0.14654894339919733\n",
            "==================================================\n",
            "Token: gene\n",
            "Attribution Score: 0.14555807309081287\n",
            "==================================================\n",
            "Token: exploitant\n",
            "Attribution Score: 0.1442212651486488\n",
            "==================================================\n",
            "Token: Anim\n",
            "Attribution Score: 0.14157396600478092\n",
            "==================================================\n",
            "Token: Info\n",
            "Attribution Score: 0.13497266597969004\n",
            "==================================================\n",
            "Token: mar\n",
            "Attribution Score: 0.12360411186525902\n",
            "==================================================\n",
            "Token: ▁alors\n",
            "Attribution Score: 0.11827725549177286\n",
            "==================================================\n",
            "Token: ▁retard\n",
            "Attribution Score: 0.11446998604449972\n",
            "==================================================\n",
            "Token: ▁on\n",
            "Attribution Score: 0.11398083265358853\n",
            "==================================================\n",
            "Token: ▁e\n",
            "Attribution Score: 0.11351277377599513\n",
            "==================================================\n",
            "Token: ville\n",
            "Attribution Score: 0.1109033072812145\n",
            "==================================================\n",
            "Token: acteur\n",
            "Attribution Score: 0.1102269105590041\n",
            "==================================================\n",
            "Token: ▁met\n",
            "Attribution Score: 0.1072088874538373\n",
            "==================================================\n",
            "Token: rage\n",
            "Attribution Score: 0.10637768036100359\n",
            "==================================================\n",
            "Token: ▁sujet\n",
            "Attribution Score: 0.1050934909571161\n",
            "==================================================\n",
            "Token: ▁partie\n",
            "Attribution Score: 0.09855164592375158\n",
            "==================================================\n",
            "Token: ▁d\n",
            "Attribution Score: 0.09335706738879551\n",
            "==================================================\n",
            "Token: ▁franchement\n",
            "Attribution Score: 0.08504027481055108\n",
            "==================================================\n",
            "Token: ▁c\n",
            "Attribution Score: 0.08194316831418984\n",
            "==================================================\n",
            "Token: mission\n",
            "Attribution Score: 0.08140611032894243\n",
            "==================================================\n",
            "Token: ▁Selon\n",
            "Attribution Score: 0.08121159782828939\n",
            "==================================================\n",
            "Token: ▁des\n",
            "Attribution Score: 0.0804313858606853\n",
            "==================================================\n",
            "Token: ▁Les\n",
            "Attribution Score: 0.07933887932311023\n",
            "==================================================\n",
            "Token: ▁verts\n",
            "Attribution Score: 0.07929447433976283\n",
            "==================================================\n",
            "Token: ▁sont\n",
            "Attribution Score: 0.07916236010089753\n",
            "==================================================\n",
            "Token: ▁faudra\n",
            "Attribution Score: 0.07750675226751073\n",
            "==================================================\n",
            "Token: per\n",
            "Attribution Score: 0.07398523520939827\n",
            "==================================================\n",
            "Token: ▁Entre\n",
            "Attribution Score: 0.07344026711282564\n",
            "==================================================\n",
            "Token: an\n",
            "Attribution Score: 0.07233189728366965\n",
            "==================================================\n",
            "Token: abandon\n",
            "Attribution Score: 0.06954152995452856\n",
            "==================================================\n",
            "Token: ▁repousse\n",
            "Attribution Score: 0.06925883754690611\n",
            "==================================================\n",
            "Token: ▁compter\n",
            "Attribution Score: 0.06869340291877216\n",
            "==================================================\n",
            "Token: ▁bien\n",
            "Attribution Score: 0.06680426279786433\n",
            "==================================================\n",
            "Token: ▁confirme\n",
            "Attribution Score: 0.0657640759626665\n",
            "==================================================\n",
            "Token: ▁avant\n",
            "Attribution Score: 0.06557372314200743\n",
            "==================================================\n",
            "Token: ▁alliance\n",
            "Attribution Score: 0.06178950197777914\n",
            "==================================================\n",
            "Token: ▁pa\n",
            "Attribution Score: 0.06148349986122736\n",
            "==================================================\n",
            "Token: ▁Marc\n",
            "Attribution Score: 0.05485449234133128\n",
            "==================================================\n",
            "Token: ▁africain\n",
            "Attribution Score: 0.053483089881716545\n",
            "==================================================\n",
            "Token: ▁augmente\n",
            "Attribution Score: 0.05339973993754915\n",
            "==================================================\n",
            "Token: ent\n",
            "Attribution Score: 0.052712282125197706\n",
            "==================================================\n",
            "Token: ▁role\n",
            "Attribution Score: 0.052524282640291235\n",
            "==================================================\n",
            "Token: ▁militante\n",
            "Attribution Score: 0.04991993973050657\n",
            "==================================================\n",
            "Token: bat\n",
            "Attribution Score: 0.04977295178088228\n",
            "==================================================\n",
            "Token: ▁nos\n",
            "Attribution Score: 0.04786275585554666\n",
            "==================================================\n",
            "Token: ▁ce\n",
            "Attribution Score: 0.046856267982651724\n",
            "==================================================\n",
            "Token: ▁om\n",
            "Attribution Score: 0.045873236979672175\n",
            "==================================================\n",
            "Token: ▁cote\n",
            "Attribution Score: 0.043594849190995405\n",
            "==================================================\n",
            "Token: ▁ressemble\n",
            "Attribution Score: 0.04346813424552314\n",
            "==================================================\n",
            "Token: ▁apres\n",
            "Attribution Score: 0.041126390970284664\n",
            "==================================================\n",
            "Token: but\n",
            "Attribution Score: 0.040945527038412956\n",
            "==================================================\n",
            "Token: ▁PDG\n",
            "Attribution Score: 0.04066692236876537\n",
            "==================================================\n",
            "Token: ▁fait\n",
            "Attribution Score: 0.03805553293854247\n",
            "==================================================\n",
            "Token: ggy\n",
            "Attribution Score: 0.03598031867536221\n",
            "==================================================\n",
            "Token: imp\n",
            "Attribution Score: 0.035840893400545935\n",
            "==================================================\n",
            "Token: ▁comment\n",
            "Attribution Score: 0.03545608636173271\n",
            "==================================================\n",
            "Token: ▁cette\n",
            "Attribution Score: 0.035402376204624636\n",
            "==================================================\n",
            "Token: ▁rapport\n",
            "Attribution Score: 0.031352302560802854\n",
            "==================================================\n",
            "Token: ▁service\n",
            "Attribution Score: 0.0311312296647331\n",
            "==================================================\n",
            "Token: ▁deja\n",
            "Attribution Score: 0.030611220096538404\n",
            "==================================================\n",
            "Token: ▁pourquoi\n",
            "Attribution Score: 0.029757438203354834\n",
            "==================================================\n",
            "Token: ▁pallier\n",
            "Attribution Score: 0.029412808381761295\n",
            "==================================================\n",
            "Token: ▁Pour\n",
            "Attribution Score: 0.02881941026276236\n",
            "==================================================\n",
            "Token: ▁crise\n",
            "Attribution Score: 0.02687958728840322\n",
            "==================================================\n",
            "Token: ▁climat\n",
            "Attribution Score: 0.02146877651506864\n",
            "==================================================\n",
            "Token: ▁couper\n",
            "Attribution Score: 0.021459251392832196\n",
            "==================================================\n",
            "Token: ▁commencent\n",
            "Attribution Score: 0.018305149993603147\n",
            "==================================================\n",
            "Token: ▁principaux\n",
            "Attribution Score: 0.01737763484549418\n",
            "==================================================\n",
            "Token: ▁tout\n",
            "Attribution Score: 0.01300934116827809\n",
            "==================================================\n",
            "Token: ▁probleme\n",
            "Attribution Score: 0.012751575482412597\n",
            "==================================================\n",
            "Token: ▁toujours\n",
            "Attribution Score: 0.009489904596359362\n",
            "==================================================\n",
            "Token: ▁troll\n",
            "Attribution Score: 0.007805885853826794\n",
            "==================================================\n",
            "Token: ▁comprendre\n",
            "Attribution Score: 0.007251392850224428\n",
            "==================================================\n",
            "Token: ▁positive\n",
            "Attribution Score: 0.00593467960459405\n",
            "==================================================\n",
            "Cluster for Target Class: viande\n",
            "Token: ▁RT\n",
            "Attribution Score: 0.7491955734354095\n",
            "==================================================\n",
            "Token: rons\n",
            "Attribution Score: 0.7302262954409051\n",
            "==================================================\n",
            "Token: ▁sur\n",
            "Attribution Score: 0.7293678373662413\n",
            "==================================================\n",
            "Token: ▁de\n",
            "Attribution Score: 0.5993418736330562\n",
            "==================================================\n",
            "Token: ▁steak\n",
            "Attribution Score: 0.5884419007051255\n",
            "==================================================\n",
            "Token: orn\n",
            "Attribution Score: 0.5786554879388481\n",
            "==================================================\n",
            "Token: ▁poulet\n",
            "Attribution Score: 0.5637003541739142\n",
            "==================================================\n",
            "Token: ▁pe\n",
            "Attribution Score: 0.43967735964030363\n",
            "==================================================\n",
            "Token: ▁f\n",
            "Attribution Score: 0.4295165944978915\n",
            "==================================================\n",
            "Token: ▁Ce\n",
            "Attribution Score: 0.4182251863651918\n",
            "==================================================\n",
            "Token: ▁Pat\n",
            "Attribution Score: 0.4140370089647672\n",
            "==================================================\n",
            "Token: eurs\n",
            "Attribution Score: 0.40506930479693987\n",
            "==================================================\n",
            "Token: -\n",
            "Attribution Score: 0.3839845335538712\n",
            "==================================================\n",
            "Token: arg\n",
            "Attribution Score: 0.3759243239463359\n",
            "==================================================\n",
            "Token: '\n",
            "Attribution Score: 0.3656830074992501\n",
            "==================================================\n",
            "Token: ▁l\n",
            "Attribution Score: 0.35000416113231664\n",
            "==================================================\n",
            "Token: ▁J\n",
            "Attribution Score: 0.34866621780941864\n",
            "==================================================\n",
            "Token: ▁\n",
            "Attribution Score: 0.3367408766956855\n",
            "==================================================\n",
            "Token: ▁tache\n",
            "Attribution Score: 0.33091430369353014\n",
            "==================================================\n",
            "Token: croissance\n",
            "Attribution Score: 0.32994434237232384\n",
            "==================================================\n",
            "Token: ▁viande\n",
            "Attribution Score: 0.3226492521662192\n",
            "==================================================\n",
            "Token: agriculture\n",
            "Attribution Score: 0.31852865925429513\n",
            "==================================================\n",
            "Token: r\n",
            "Attribution Score: 0.2975913279502203\n",
            "==================================================\n",
            "Token: f\n",
            "Attribution Score: 0.28465633905141785\n",
            "==================================================\n",
            "Token: ▁nouvelle\n",
            "Attribution Score: 0.28389921226004766\n",
            "==================================================\n",
            "Token: uke\n",
            "Attribution Score: 0.28126021655542366\n",
            "==================================================\n",
            "Token: ▁et\n",
            "Attribution Score: 0.2731006922614433\n",
            "==================================================\n",
            "Token: ▁Spring\n",
            "Attribution Score: 0.2678632181063859\n",
            "==================================================\n",
            "Token: ▁qui\n",
            "Attribution Score: 0.2672418514551388\n",
            "==================================================\n",
            "Token: tier\n",
            "Attribution Score: 0.26679269591040083\n",
            "==================================================\n",
            "Token: ▁aux\n",
            "Attribution Score: 0.26379154915015757\n",
            "==================================================\n",
            "Token: isse\n",
            "Attribution Score: 0.2636798990408094\n",
            "==================================================\n",
            "Token: lev\n",
            "Attribution Score: 0.23220638748174893\n",
            "==================================================\n",
            "Token: ▁face\n",
            "Attribution Score: 0.22849214645331073\n",
            "==================================================\n",
            "Token: coup\n",
            "Attribution Score: 0.22752861138017333\n",
            "==================================================\n",
            "Token: ▁cross\n",
            "Attribution Score: 0.22184376551701387\n",
            "==================================================\n",
            "Token: ▁N\n",
            "Attribution Score: 0.21979110120501438\n",
            "==================================================\n",
            "Token: ▁vise\n",
            "Attribution Score: 0.21455300175834055\n",
            "==================================================\n",
            "Token: iane\n",
            "Attribution Score: 0.20593484151095212\n",
            "==================================================\n",
            "Token: ▁heures\n",
            "Attribution Score: 0.19012380355608013\n",
            "==================================================\n",
            "Token: equipe\n",
            "Attribution Score: 0.18989093413885993\n",
            "==================================================\n",
            "Token: ine\n",
            "Attribution Score: 0.18974100859353493\n",
            "==================================================\n",
            "Token: ▁dam\n",
            "Attribution Score: 0.173672303974973\n",
            "==================================================\n",
            "Token: ▁Fred\n",
            "Attribution Score: 0.17327855651215224\n",
            "==================================================\n",
            "Token: aires\n",
            "Attribution Score: 0.17177828528252087\n",
            "==================================================\n",
            "Token: ivre\n",
            "Attribution Score: 0.17118573976609916\n",
            "==================================================\n",
            "Token: ze\n",
            "Attribution Score: 0.1711112973322741\n",
            "==================================================\n",
            "Token: cout\n",
            "Attribution Score: 0.16756106706288454\n",
            "==================================================\n",
            "Token: G\n",
            "Attribution Score: 0.16539092553014276\n",
            "==================================================\n",
            "Token: ▁compagnies\n",
            "Attribution Score: 0.16432067606492243\n",
            "==================================================\n",
            "Token: ferme\n",
            "Attribution Score: 0.16326924785402178\n",
            "==================================================\n",
            "Token: ru\n",
            "Attribution Score: 0.15784424239865552\n",
            "==================================================\n",
            "Token: ▁peux\n",
            "Attribution Score: 0.1514929798779987\n",
            "==================================================\n",
            "Token: ense\n",
            "Attribution Score: 0.1478847141549795\n",
            "==================================================\n",
            "Token: ▁Al\n",
            "Attribution Score: 0.14559471688534786\n",
            "==================================================\n",
            "Token: ▁TF\n",
            "Attribution Score: 0.14447861471321014\n",
            "==================================================\n",
            "Token: c\n",
            "Attribution Score: 0.14195491630218635\n",
            "==================================================\n",
            "Token: ▁inter\n",
            "Attribution Score: 0.1414593097224242\n",
            "==================================================\n",
            "Token: hou\n",
            "Attribution Score: 0.14088631397964477\n",
            "==================================================\n",
            "Token: aliste\n",
            "Attribution Score: 0.14077331825733344\n",
            "==================================================\n",
            "Token: ▁Flam\n",
            "Attribution Score: 0.14053679312692105\n",
            "==================================================\n",
            "Token: ▁Hel\n",
            "Attribution Score: 0.13733046330206372\n",
            "==================================================\n",
            "Token: sh\n",
            "Attribution Score: 0.137053038077154\n",
            "==================================================\n",
            "Token: ▁sortir\n",
            "Attribution Score: 0.13262848285864035\n",
            "==================================================\n",
            "Token: ph\n",
            "Attribution Score: 0.12652213150455416\n",
            "==================================================\n",
            "Token: ap\n",
            "Attribution Score: 0.12548267781884906\n",
            "==================================================\n",
            "Token: ▁En\n",
            "Attribution Score: 0.12338038667770454\n",
            "==================================================\n",
            "Token: mier\n",
            "Attribution Score: 0.12140081075573615\n",
            "==================================================\n",
            "Token: ▁trans\n",
            "Attribution Score: 0.12126428648097032\n",
            "==================================================\n",
            "Token: ie\n",
            "Attribution Score: 0.11900372908333712\n",
            "==================================================\n",
            "Token: ▁bi\n",
            "Attribution Score: 0.11444088669241834\n",
            "==================================================\n",
            "Token: line\n",
            "Attribution Score: 0.11398718039034912\n",
            "==================================================\n",
            "Token: ▁vs\n",
            "Attribution Score: 0.11367889122746057\n",
            "==================================================\n",
            "Token: ▁option\n",
            "Attribution Score: 0.11312765202697182\n",
            "==================================================\n",
            "Token: ▁pays\n",
            "Attribution Score: 0.11249428298173356\n",
            "==================================================\n",
            "Token: ▁est\n",
            "Attribution Score: 0.11220694887051776\n",
            "==================================================\n",
            "Token: T\n",
            "Attribution Score: 0.11101990350979046\n",
            "==================================================\n",
            "Token: ▁Terr\n",
            "Attribution Score: 0.10850688924979736\n",
            "==================================================\n",
            "Token: ▁Super\n",
            "Attribution Score: 0.10807157812789732\n",
            "==================================================\n",
            "Token: ▁Anne\n",
            "Attribution Score: 0.10776287966838158\n",
            "==================================================\n",
            "Token: De\n",
            "Attribution Score: 0.10465403996137447\n",
            "==================================================\n",
            "Token: ▁Vin\n",
            "Attribution Score: 0.10095677911196912\n",
            "==================================================\n",
            "Token: ▁ca\n",
            "Attribution Score: 0.09888042924512831\n",
            "==================================================\n",
            "Token: ▁industrie\n",
            "Attribution Score: 0.09619292587870283\n",
            "==================================================\n",
            "Token: ko\n",
            "Attribution Score: 0.09588835738239829\n",
            "==================================================\n",
            "Token: OO\n",
            "Attribution Score: 0.09468741265859089\n",
            "==================================================\n",
            "Token: ▁trouve\n",
            "Attribution Score: 0.09214963709123522\n",
            "==================================================\n",
            "Token: ▁intensif\n",
            "Attribution Score: 0.08956628676936122\n",
            "==================================================\n",
            "Token: arrive\n",
            "Attribution Score: 0.08849533310829688\n",
            "==================================================\n",
            "Token: ▁qu\n",
            "Attribution Score: 0.0876373727592547\n",
            "==================================================\n",
            "Token: guy\n",
            "Attribution Score: 0.08517419888523843\n",
            "==================================================\n",
            "Token: ita\n",
            "Attribution Score: 0.081999610569691\n",
            "==================================================\n",
            "Token: Je\n",
            "Attribution Score: 0.08110690861187002\n",
            "==================================================\n",
            "Token: ▁rater\n",
            "Attribution Score: 0.08070159293545633\n",
            "==================================================\n",
            "Token: ▁interview\n",
            "Attribution Score: 0.07958206899423531\n",
            "==================================================\n",
            "Token: mont\n",
            "Attribution Score: 0.07572671341032568\n",
            "==================================================\n",
            "Token: St\n",
            "Attribution Score: 0.07464061916560902\n",
            "==================================================\n",
            "Token: ▁Ou\n",
            "Attribution Score: 0.07207170420970388\n",
            "==================================================\n",
            "Token: ▁jamais\n",
            "Attribution Score: 0.07181632699745336\n",
            "==================================================\n",
            "Token: ▁segment\n",
            "Attribution Score: 0.07166776277992323\n",
            "==================================================\n",
            "Token: ▁Cette\n",
            "Attribution Score: 0.06883225755105471\n",
            "==================================================\n",
            "Token: ▁moi\n",
            "Attribution Score: 0.06802596496699954\n",
            "==================================================\n",
            "Token: anticipation\n",
            "Attribution Score: 0.06432910612146614\n",
            "==================================================\n",
            "Token: ▁exemple\n",
            "Attribution Score: 0.06427046870467956\n",
            "==================================================\n",
            "Token: entend\n",
            "Attribution Score: 0.06307334768214207\n",
            "==================================================\n",
            "Token: ▁Ka\n",
            "Attribution Score: 0.06228026202748635\n",
            "==================================================\n",
            "Token: ▁fermeture\n",
            "Attribution Score: 0.062146533448344116\n",
            "==================================================\n",
            "Token: ▁gars\n",
            "Attribution Score: 0.05893681750464721\n",
            "==================================================\n",
            "Token: Le\n",
            "Attribution Score: 0.05878708584045034\n",
            "==================================================\n",
            "Token: ▁centrales\n",
            "Attribution Score: 0.05850313491396672\n",
            "==================================================\n",
            "Token: ▁video\n",
            "Attribution Score: 0.05696127790140922\n",
            "==================================================\n",
            "Token: iger\n",
            "Attribution Score: 0.05486027789396032\n",
            "==================================================\n",
            "Token: min\n",
            "Attribution Score: 0.05464159087737277\n",
            "==================================================\n",
            "Token: ▁France\n",
            "Attribution Score: 0.04992853558286637\n",
            "==================================================\n",
            "Token: fou\n",
            "Attribution Score: 0.045842210520434856\n",
            "==================================================\n",
            "Token: ▁voir\n",
            "Attribution Score: 0.0453205220249089\n",
            "==================================================\n",
            "Token: que\n",
            "Attribution Score: 0.04265036890317402\n",
            "==================================================\n",
            "Token: ▁nerfs\n",
            "Attribution Score: 0.040563003756161904\n",
            "==================================================\n",
            "Token: un\n",
            "Attribution Score: 0.03907900138994373\n",
            "==================================================\n",
            "Token: ▁Premier\n",
            "Attribution Score: 0.03890056685891022\n",
            "==================================================\n",
            "Token: Mac\n",
            "Attribution Score: 0.036079116239316346\n",
            "==================================================\n",
            "Token: AUX\n",
            "Attribution Score: 0.033793553829801815\n",
            "==================================================\n",
            "Token: mo\n",
            "Attribution Score: 0.03361073413812519\n",
            "==================================================\n",
            "Token: ▁travail\n",
            "Attribution Score: 0.030506268237259087\n",
            "==================================================\n",
            "Token: ter\n",
            "Attribution Score: 0.030093701797937026\n",
            "==================================================\n",
            "Token: ring\n",
            "Attribution Score: 0.029507968108440728\n",
            "==================================================\n",
            "Token: ▁Tristan\n",
            "Attribution Score: 0.029352689957830976\n",
            "==================================================\n",
            "Token: ▁sortie\n",
            "Attribution Score: 0.02660349922773973\n",
            "==================================================\n",
            "Token: che\n",
            "Attribution Score: 0.025881656949577496\n",
            "==================================================\n",
            "Token: ope\n",
            "Attribution Score: 0.02545401704429939\n",
            "==================================================\n",
            "Token: ge\n",
            "Attribution Score: 0.02386549444071745\n",
            "==================================================\n",
            "Token: ▁oblige\n",
            "Attribution Score: 0.02364114316961115\n",
            "==================================================\n",
            "Token: ▁manier\n",
            "Attribution Score: 0.022625732485112012\n",
            "==================================================\n",
            "Token: ▁montrer\n",
            "Attribution Score: 0.018632190509222036\n",
            "==================================================\n",
            "Token: ▁permet\n",
            "Attribution Score: 0.01830794471737575\n",
            "==================================================\n",
            "Token: ▁renouvelables\n",
            "Attribution Score: 0.014355366474292395\n",
            "==================================================\n",
            "Token: ▁CO\n",
            "Attribution Score: 0.01320928128925576\n",
            "==================================================\n",
            "Token: ▁Parce\n",
            "Attribution Score: 0.011026966395668445\n",
            "==================================================\n",
            "Token: mand\n",
            "Attribution Score: 0.007435925045358553\n",
            "==================================================\n",
            "Token: ▁pointes\n",
            "Attribution Score: 0.007199999016411133\n",
            "==================================================\n",
            "Saved Clusters:\n",
            "{'avion': {'tokens': ['▁Pi', 'ux', 'rge', '▁demande', 'activiste', 'lia', '▁car', '▁Air', 'OI', '▁I', 'go', 'iere', 'on', 'au', 'iez', '▁A', '▁pas', 'est', 'tique', 'er', '▁route', 'air', '▁pour', 'way', '▁n', '▁en', 'ossi', 'tar', 'bri', '▁Royal', '▁L', 'Air', 'X', 'don', 'lage', 'omb', 'ai', 'Aviation', '▁Da', 'B', '▁leur', '▁que', 'aviation', 'information', '▁Dub', '▁F', 'show', 'ft', 'ait', '▁a', '▁toute', '▁frais', 'Char', '▁reste', 'fen', '▁porter', 'eme', 'nu', '▁ad', '▁combustible', '▁On', '▁Parti', '▁point', '▁fonctionne', '▁rapide', '▁va', '▁plaque', '▁fossiles', 'ER', 'dent', 'issement', 'vez', '▁un', '▁-', '▁el', '▁devrait', 'or', '▁Quand', '▁man', 'mbo', 'association', '▁expert', '▁certaine', '▁favoris', '▁parce', '▁ger', '▁utiliser', '▁Ah', 'ce', '▁Europe'], 'scores': [0.984415388522172, 0.9390636837835316, 0.9318541408843573, 0.8928369788996585, 0.8740662152849973, 0.807171431922697, 0.651550784584209, 0.6397076525821597, 0.5778369538319422, 0.5400130779710037, 0.5211446040382975, 0.5034091344019415, 0.4901638676481372, 0.47247978082866315, 0.4711412322754204, 0.45625158460972054, 0.4211286230168977, 0.38698257721523777, 0.3637493038602273, 0.35684690875355574, 0.3472790351361145, 0.34636950544864914, 0.33022102763587224, 0.32549219709453825, 0.30462489765952433, 0.2877691605252897, 0.27430782462470077, 0.26892261789649075, 0.2665493610938637, 0.22692242298520204, 0.2255467227364542, 0.2241903051431998, 0.21569536098849118, 0.18537424781637848, 0.1794503704063201, 0.1790605069033983, 0.15954645468943723, 0.1581918693694628, 0.15761228516167458, 0.1502215310587666, 0.12109592984246134, 0.11628192689095129, 0.11181989808972802, 0.10986309527453886, 0.10467722096413781, 0.09861773589918282, 0.09646319461749614, 0.08839590808017861, 0.08765181633025418, 0.08694406028070448, 0.07974379809602175, 0.07791346568933331, 0.07772174780988471, 0.07395851367222883, 0.0704347733155237, 0.06533712131142404, 0.06500019548939201, 0.06457894656899082, 0.05807002161558154, 0.057964693745861634, 0.057769877824401156, 0.054222123685844, 0.05384026430917166, 0.053586959316772036, 0.05287218191967521, 0.04986091303346024, 0.04866821858562426, 0.04837901946140133, 0.04826768960816607, 0.04762495453006347, 0.045166160086249296, 0.04307404016583673, 0.04280291728844187, 0.03993547337126255, 0.038264215832091115, 0.03819808702145536, 0.0381751651934162, 0.037907798017976814, 0.03586946372397595, 0.03536660198816475, 0.03206358456042072, 0.03142282076678814, 0.030439957172685866, 0.027993982621828086, 0.026858616923454308, 0.02363918038399604, 0.019931774451674874, 0.019814892011779262, 0.015563452246594167, 0.00506611877600972]}, 'décroissance': {'tokens': ['▁croissance', '▁sc', 'ete', 'GIE', 'e', 's', '▁he', '_', '▁schiste', 'en', '▁propre', 'co', '▁se', 'nt', '▁dans', 'ario', 'hydro', '▁sa', '▁Force', '▁sans', '▁une', 'C', 'bonne', '▁Deux', 'itation', '▁s', 'a', 'iste', 'hor', '▁CGT', 'g', '▁changement', 'row', 'read', '▁Falcon', 'im', '▁q', 'product', '▁So', '▁log', '▁journal', 'ET', 'iv', '▁pauvres', '▁aussi', '▁religion', '▁ou', '▁anti', '▁pro', 'y', '▁enjeux', '▁importe', '▁mon', 'aste', '▁mais', '▁riches', 'rte', '▁C', '▁plus', '▁au', 'france', '▁climatique', 'Allemagne', '▁Alliance', '▁lit', '▁histoire', 'bili', 'industrie', '▁veut', 'te', 'nes', 'th', '▁sommes', 'z', 'ibili', '▁Bu', '▁my', 'tache', 'pulse', 'ory', '▁soutien', '▁notre', '▁consomme', 'chet', 'pl', '▁puis', 're', '▁fu', 'ons', 'ette', '▁scandale', '▁repond', 'the', 'MC', '▁travailleurs', '▁E', 'it', 'duire', '▁solutions', '▁sombres', '▁seul', 'es', 'head', '▁nombreux', '▁Projet', '▁levier', 'flex', '▁par', '▁nouveaux', '▁R', '▁Donc', 'volution', '▁compare', '▁perdent', 'nni', '▁Ba', 'opinion', 'ing', '▁mix', 'ron', 'W', '▁trouver', '▁moindre', '▁charbon', '▁Et', 'peak', '▁efficace', '▁b', '▁souverain', '▁virgule'], 'scores': [0.7020711865573456, 0.5847707993447236, 0.5321054516697026, 0.4886768371741019, 0.4662529792399467, 0.45922253794343626, 0.45291379249176317, 0.4405221841436491, 0.43625287946658314, 0.40330474045782116, 0.3891448028162005, 0.3870768849979652, 0.3855403423029331, 0.38387633870694, 0.3727797319798287, 0.36769395639736, 0.362204020342404, 0.35178025183130407, 0.3456002736748095, 0.331337987393905, 0.3246493252584137, 0.3224368752562713, 0.3161695131596587, 0.29759305767744826, 0.2937255727459643, 0.28948973543683243, 0.27449341541341316, 0.25958850225282365, 0.2568652998750119, 0.23457096052128212, 0.22838454003538286, 0.22553336639609553, 0.2169568253938439, 0.21360148185131184, 0.2021206260676947, 0.18965749403223842, 0.18503147261956174, 0.18383358755537318, 0.182336719603396, 0.17068018318416653, 0.17000050333011396, 0.16842444216810204, 0.1682508349870194, 0.16427566574124766, 0.16097155469635166, 0.16059983829626212, 0.1594616878552052, 0.159238613962707, 0.15755428127081386, 0.1443711408492329, 0.14282868587043096, 0.13243446479768492, 0.12901976157220715, 0.12736345764166357, 0.1270548945755596, 0.12202989620967387, 0.12141441661073211, 0.11947672954718591, 0.1113800642420519, 0.10613184460883625, 0.10452544184604944, 0.10326951426801335, 0.10147020172645654, 0.09811836513870421, 0.09742083897735797, 0.09694531804273875, 0.09064176122565791, 0.09003209035384407, 0.08900986780922461, 0.08826473172532884, 0.08779008136990961, 0.08492063457148705, 0.0836983266657936, 0.08351517283284689, 0.08302786852931343, 0.08181506620778657, 0.08136073148971337, 0.07797205046936781, 0.0769716534101548, 0.07646007899905749, 0.07584834218339033, 0.07415465180991808, 0.07407397652066008, 0.07183108859247317, 0.07137745013910402, 0.06796732848855502, 0.06792975791838012, 0.06550545385171871, 0.0643786351004525, 0.063113419836146, 0.06190081519579054, 0.056691192231869865, 0.052678324059739844, 0.05053720358717621, 0.050297077413856105, 0.048939476015845904, 0.047906508698766156, 0.04751765690073941, 0.04609385025179852, 0.043815518499535404, 0.04089857849404522, 0.04062261664451431, 0.040242000974616214, 0.04019129209999592, 0.03905269876548915, 0.03668721282107568, 0.03651173286382043, 0.03194297534913784, 0.030612939620615554, 0.029683259273348105, 0.029554386592635727, 0.02814037136958235, 0.027187018148143605, 0.026874853386511376, 0.026791469414893295, 0.02677241755397041, 0.026222102735262983, 0.02618783649350497, 0.023865795466881612, 0.021081242446920723, 0.020844187802208754, 0.02028872284419171, 0.018447519457942117, 0.018374997331598048, 0.017147675993392585, 0.01667787737728898, 0.011968802384845451, 0.010665818361802748, 0.009644452993068214, -0.008918696988323887]}, 'nucléaire': {'tokens': ['ault', 'gging', 'mark', 'aire', '▁nu', 'cle', 'tro', 'K', 'le', 'ern', '▁citoyens', 'EP', 'R', '▁consommateurs', 'quand', '▁D', '▁Nouveau', '▁entre', 'one', '▁re', '▁ne', 'ra', 'gene', 'exploitant', 'Anim', 'Info', 'mar', '▁alors', '▁retard', '▁on', '▁e', 'ville', 'acteur', '▁met', 'rage', '▁sujet', '▁partie', '▁d', '▁franchement', '▁c', 'mission', '▁Selon', '▁des', '▁Les', '▁verts', '▁sont', '▁faudra', 'per', '▁Entre', 'an', 'abandon', '▁repousse', '▁compter', '▁bien', '▁confirme', '▁avant', '▁alliance', '▁pa', '▁Marc', '▁africain', '▁augmente', 'ent', '▁role', '▁militante', 'bat', '▁nos', '▁ce', '▁om', '▁cote', '▁ressemble', '▁apres', 'but', '▁PDG', '▁fait', 'ggy', 'imp', '▁comment', '▁cette', '▁rapport', '▁service', '▁deja', '▁pourquoi', '▁pallier', '▁Pour', '▁crise', '▁climat', '▁couper', '▁commencent', '▁principaux', '▁tout', '▁probleme', '▁toujours', '▁troll', '▁comprendre', '▁positive'], 'scores': [0.793172885681329, 0.7193486612970815, 0.6320039052910488, 0.6176532403843716, 0.5699277525555054, 0.5098030801479283, 0.4682227257771468, 0.4249368716157058, 0.3584638774651852, 0.3441451163973267, 0.3148444792973715, 0.2830180962706778, 0.2496313021932664, 0.20726750262891097, 0.20013370624087992, 0.1980804375831241, 0.18662515060379206, 0.1798211446305738, 0.1546356860452948, 0.1504424120288401, 0.14757367903827018, 0.14654894339919733, 0.14555807309081287, 0.1442212651486488, 0.14157396600478092, 0.13497266597969004, 0.12360411186525902, 0.11827725549177286, 0.11446998604449972, 0.11398083265358853, 0.11351277377599513, 0.1109033072812145, 0.1102269105590041, 0.1072088874538373, 0.10637768036100359, 0.1050934909571161, 0.09855164592375158, 0.09335706738879551, 0.08504027481055108, 0.08194316831418984, 0.08140611032894243, 0.08121159782828939, 0.0804313858606853, 0.07933887932311023, 0.07929447433976283, 0.07916236010089753, 0.07750675226751073, 0.07398523520939827, 0.07344026711282564, 0.07233189728366965, 0.06954152995452856, 0.06925883754690611, 0.06869340291877216, 0.06680426279786433, 0.0657640759626665, 0.06557372314200743, 0.06178950197777914, 0.06148349986122736, 0.05485449234133128, 0.053483089881716545, 0.05339973993754915, 0.052712282125197706, 0.052524282640291235, 0.04991993973050657, 0.04977295178088228, 0.04786275585554666, 0.046856267982651724, 0.045873236979672175, 0.043594849190995405, 0.04346813424552314, 0.041126390970284664, 0.040945527038412956, 0.04066692236876537, 0.03805553293854247, 0.03598031867536221, 0.035840893400545935, 0.03545608636173271, 0.035402376204624636, 0.031352302560802854, 0.0311312296647331, 0.030611220096538404, 0.029757438203354834, 0.029412808381761295, 0.02881941026276236, 0.02687958728840322, 0.02146877651506864, 0.021459251392832196, 0.018305149993603147, 0.01737763484549418, 0.01300934116827809, 0.012751575482412597, 0.009489904596359362, 0.007805885853826794, 0.007251392850224428, 0.00593467960459405]}, 'viande': {'tokens': ['▁RT', 'rons', '▁sur', '▁de', '▁steak', 'orn', '▁poulet', '▁pe', '▁f', '▁Ce', '▁Pat', 'eurs', '-', 'arg', \"'\", '▁l', '▁J', '▁', '▁tache', 'croissance', '▁viande', 'agriculture', 'r', 'f', '▁nouvelle', 'uke', '▁et', '▁Spring', '▁qui', 'tier', '▁aux', 'isse', 'lev', '▁face', 'coup', '▁cross', '▁N', '▁vise', 'iane', '▁heures', 'equipe', 'ine', '▁dam', '▁Fred', 'aires', 'ivre', 'ze', 'cout', 'G', '▁compagnies', 'ferme', 'ru', '▁peux', 'ense', '▁Al', '▁TF', 'c', '▁inter', 'hou', 'aliste', '▁Flam', '▁Hel', 'sh', '▁sortir', 'ph', 'ap', '▁En', 'mier', '▁trans', 'ie', '▁bi', 'line', '▁vs', '▁option', '▁pays', '▁est', 'T', '▁Terr', '▁Super', '▁Anne', 'De', '▁Vin', '▁ca', '▁industrie', 'ko', 'OO', '▁trouve', '▁intensif', 'arrive', '▁qu', 'guy', 'ita', 'Je', '▁rater', '▁interview', 'mont', 'St', '▁Ou', '▁jamais', '▁segment', '▁Cette', '▁moi', 'anticipation', '▁exemple', 'entend', '▁Ka', '▁fermeture', '▁gars', 'Le', '▁centrales', '▁video', 'iger', 'min', '▁France', 'fou', '▁voir', 'que', '▁nerfs', 'un', '▁Premier', 'Mac', 'AUX', 'mo', '▁travail', 'ter', 'ring', '▁Tristan', '▁sortie', 'che', 'ope', 'ge', '▁oblige', '▁manier', '▁montrer', '▁permet', '▁renouvelables', '▁CO', '▁Parce', 'mand', '▁pointes'], 'scores': [0.7491955734354095, 0.7302262954409051, 0.7293678373662413, 0.5993418736330562, 0.5884419007051255, 0.5786554879388481, 0.5637003541739142, 0.43967735964030363, 0.4295165944978915, 0.4182251863651918, 0.4140370089647672, 0.40506930479693987, 0.3839845335538712, 0.3759243239463359, 0.3656830074992501, 0.35000416113231664, 0.34866621780941864, 0.3367408766956855, 0.33091430369353014, 0.32994434237232384, 0.3226492521662192, 0.31852865925429513, 0.2975913279502203, 0.28465633905141785, 0.28389921226004766, 0.28126021655542366, 0.2731006922614433, 0.2678632181063859, 0.2672418514551388, 0.26679269591040083, 0.26379154915015757, 0.2636798990408094, 0.23220638748174893, 0.22849214645331073, 0.22752861138017333, 0.22184376551701387, 0.21979110120501438, 0.21455300175834055, 0.20593484151095212, 0.19012380355608013, 0.18989093413885993, 0.18974100859353493, 0.173672303974973, 0.17327855651215224, 0.17177828528252087, 0.17118573976609916, 0.1711112973322741, 0.16756106706288454, 0.16539092553014276, 0.16432067606492243, 0.16326924785402178, 0.15784424239865552, 0.1514929798779987, 0.1478847141549795, 0.14559471688534786, 0.14447861471321014, 0.14195491630218635, 0.1414593097224242, 0.14088631397964477, 0.14077331825733344, 0.14053679312692105, 0.13733046330206372, 0.137053038077154, 0.13262848285864035, 0.12652213150455416, 0.12548267781884906, 0.12338038667770454, 0.12140081075573615, 0.12126428648097032, 0.11900372908333712, 0.11444088669241834, 0.11398718039034912, 0.11367889122746057, 0.11312765202697182, 0.11249428298173356, 0.11220694887051776, 0.11101990350979046, 0.10850688924979736, 0.10807157812789732, 0.10776287966838158, 0.10465403996137447, 0.10095677911196912, 0.09888042924512831, 0.09619292587870283, 0.09588835738239829, 0.09468741265859089, 0.09214963709123522, 0.08956628676936122, 0.08849533310829688, 0.0876373727592547, 0.08517419888523843, 0.081999610569691, 0.08110690861187002, 0.08070159293545633, 0.07958206899423531, 0.07572671341032568, 0.07464061916560902, 0.07207170420970388, 0.07181632699745336, 0.07166776277992323, 0.06883225755105471, 0.06802596496699954, 0.06432910612146614, 0.06427046870467956, 0.06307334768214207, 0.06228026202748635, 0.062146533448344116, 0.05893681750464721, 0.05878708584045034, 0.05850313491396672, 0.05696127790140922, 0.05486027789396032, 0.05464159087737277, 0.04992853558286637, 0.045842210520434856, 0.0453205220249089, 0.04265036890317402, 0.040563003756161904, 0.03907900138994373, 0.03890056685891022, 0.036079116239316346, 0.033793553829801815, 0.03361073413812519, 0.030506268237259087, 0.030093701797937026, 0.029507968108440728, 0.029352689957830976, 0.02660349922773973, 0.025881656949577496, 0.02545401704429939, 0.02386549444071745, 0.02364114316961115, 0.022625732485112012, 0.018632190509222036, 0.01830794471737575, 0.014355366474292395, 0.01320928128925576, 0.011026966395668445, 0.007435925045358553, 0.007199999016411133]}}\n"
          ]
        }
      ],
      "source": [
        "# Regrouper les tokens de la fonction précédente qui appartient au meme target dans un meme cluster correspendant à ce target\n",
        "def create_target_clusters(clusters):\n",
        "    class_labels = ['avion', 'décroissance', 'nucléaire', 'viande']\n",
        "    target_clusters = {target: {\"tokens\": [], \"scores\": []} for target in class_labels}\n",
        "\n",
        "    for token, info in clusters.items():\n",
        "        if token not in [\"<s>\", \"</s>\"]:\n",
        "            target_class = info[\"target_class\"]\n",
        "            if target_class:\n",
        "                target_clusters[target_class][\"tokens\"].append(token)\n",
        "                target_clusters[target_class][\"scores\"].append(info[\"token_score\"])\n",
        "\n",
        "    for target, scores_info in target_clusters.items():\n",
        "        tokens_scores = zip(scores_info[\"tokens\"], scores_info[\"scores\"])\n",
        "        sorted_tokens_scores = sorted(tokens_scores, key=lambda x: x[1], reverse=True)\n",
        "        target_clusters[target] = dict(sorted_tokens_scores)\n",
        "\n",
        "    return target_clusters\n",
        "\n",
        "def display_target_clusters(target_clusters):\n",
        "    for target, tokens_scores_dict in target_clusters.items():\n",
        "        print(f\"Cluster for Target Class: {target}\")\n",
        "        for token, score in tokens_scores_dict.items():\n",
        "            print(f\"Token: {token}\")\n",
        "            print(\"Attribution Score:\", score)\n",
        "            print(\"=\"*50)\n",
        "#Chaque cluster est représenté sous la forme d'un dictionnaire avec deux listes tokens et scores\n",
        "def save_clusters_to_dict(target_clusters):\n",
        "    saved_clusters = {}\n",
        "    for target, tokens_scores_dict in target_clusters.items():\n",
        "        cluster_dict = {\n",
        "            \"tokens\": list(tokens_scores_dict.keys()),\n",
        "            \"scores\": list(tokens_scores_dict.values())\n",
        "        }\n",
        "        saved_clusters[target] = cluster_dict\n",
        "    return saved_clusters\n",
        "\n",
        "\n",
        "# Create target clusters\n",
        "target_clusters = create_target_clusters(clusters)\n",
        "\n",
        "# Display target clusters\n",
        "display_target_clusters(target_clusters)\n",
        "\n",
        "# Save clusters to a dictionary\n",
        "saved_clusters_dict = save_clusters_to_dict(target_clusters)\n",
        "print(\"Saved Clusters:\")\n",
        "print(saved_clusters_dict)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVQDVLUP4pSI",
        "outputId": "9929b5de-4d42-4de8-cce5-54eee34d3801"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved Clusters to file: /content/saved_clusters.json\n"
          ]
        }
      ],
      "source": [
        "saved_clusters_dict = save_clusters_to_dict(target_clusters)\n",
        "file_path = \"/content/saved_clusters.json\"\n",
        "with open(file_path, \"w\") as file:\n",
        "    json.dump(saved_clusters_dict, file)\n",
        "print(\"Saved Clusters to file:\", file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRGtvBZy8sjd",
        "outputId": "1d46527e-43ad-4248-84e5-66ea6d856633"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence: croissance production de viande\n",
            "Target Class: avion\n",
            "Token\t\tToken Score\n",
            "--------------------------\n",
            "<s>\t\tnan\n",
            "▁croissance\t\tnan\n",
            "▁production\t\tnan\n",
            "▁viande\t\tnan\n",
            "</s>\t\tnan\n",
            "\n",
            "Bigram\t\tBigram Score\n",
            "--------------------------\n",
            "<s> ▁croissance\t\tnan\n",
            "▁croissance ▁production\t\tnan\n",
            "▁production ▁viande\t\tnan\n",
            "▁viande </s>\t\tnan\n",
            "\n",
            "Trigram\t\tTrigram Score\n",
            "--------------------------\n",
            "<s> ▁croissance ▁production\t\tnan\n",
            "▁croissance ▁production ▁viande\t\tnan\n",
            "▁production ▁viande </s>\t\tnan\n",
            "\n",
            "Predicted Class: viande\n",
            "True Class: viande\n",
            "Predicted Probability: 4.413150787353516\n",
            "Target Attribution Score: nan\n",
            "\n",
            "==================================================\n",
            "\n",
            "Target Class: décroissance\n",
            "Token\t\tToken Score\n",
            "--------------------------\n",
            "<s>\t\t0.0000\n",
            "▁croissance\t\t0.8801\n",
            "▁production\t\t0.3766\n",
            "▁viande\t\t-0.1096\n",
            "</s>\t\t-0.2676\n",
            "\n",
            "Bigram\t\tBigram Score\n",
            "--------------------------\n",
            "<s> ▁croissance\t\t0.8801\n",
            "▁croissance ▁production\t\t1.2567\n",
            "▁production ▁viande\t\t0.2670\n",
            "▁viande </s>\t\t-0.3771\n",
            "\n",
            "Trigram\t\tTrigram Score\n",
            "--------------------------\n",
            "<s> ▁croissance ▁production\t\t1.2567\n",
            "▁croissance ▁production ▁viande\t\t1.1471\n",
            "▁production ▁viande </s>\t\t-0.0006\n",
            "\n",
            "Predicted Class: viande\n",
            "True Class: viande\n",
            "Predicted Probability: 4.413150787353516\n",
            "Target Attribution Score: 0.8795520059679474\n",
            "\n",
            "==================================================\n",
            "\n",
            "Target Class: nucléaire\n",
            "Token\t\tToken Score\n",
            "--------------------------\n",
            "<s>\t\t0.0000\n",
            "▁croissance\t\t0.4750\n",
            "▁production\t\t-0.4461\n",
            "▁viande\t\t0.2076\n",
            "</s>\t\t-0.7295\n",
            "\n",
            "Bigram\t\tBigram Score\n",
            "--------------------------\n",
            "<s> ▁croissance\t\t0.4750\n",
            "▁croissance ▁production\t\t0.0288\n",
            "▁production ▁viande\t\t-0.2385\n",
            "▁viande </s>\t\t-0.5219\n",
            "\n",
            "Trigram\t\tTrigram Score\n",
            "--------------------------\n",
            "<s> ▁croissance ▁production\t\t0.0288\n",
            "▁croissance ▁production ▁viande\t\t0.2365\n",
            "▁production ▁viande </s>\t\t-0.9681\n",
            "\n",
            "Predicted Class: viande\n",
            "True Class: viande\n",
            "Predicted Probability: 4.413150787353516\n",
            "Target Attribution Score: -0.4930778679850477\n",
            "\n",
            "==================================================\n",
            "\n",
            "Target Class: viande\n",
            "Token\t\tToken Score\n",
            "--------------------------\n",
            "<s>\t\t0.0000\n",
            "▁croissance\t\t-0.5437\n",
            "▁production\t\t0.2456\n",
            "▁viande\t\t0.7332\n",
            "</s>\t\t0.3264\n",
            "\n",
            "Bigram\t\tBigram Score\n",
            "--------------------------\n",
            "<s> ▁croissance\t\t-0.5437\n",
            "▁croissance ▁production\t\t-0.2981\n",
            "▁production ▁viande\t\t0.9788\n",
            "▁viande </s>\t\t1.0596\n",
            "\n",
            "Trigram\t\tTrigram Score\n",
            "--------------------------\n",
            "<s> ▁croissance ▁production\t\t-0.2981\n",
            "▁croissance ▁production ▁viande\t\t0.4351\n",
            "▁production ▁viande </s>\t\t1.3052\n",
            "\n",
            "Predicted Class: viande\n",
            "True Class: viande\n",
            "Predicted Probability: 4.413150787353516\n",
            "Target Attribution Score: 0.7615339072079683\n",
            "\n",
            "==================================================\n",
            "\n",
            "Sentence: l'avion pollue beaucoup\n",
            "Target Class: avion\n",
            "Token\t\tToken Score\n",
            "--------------------------\n",
            "<s>\t\t0.0000\n",
            "▁l\t\t0.4955\n",
            "'\t\t0.7273\n",
            "avion\t\t0.4715\n",
            "▁pollue\t\t0.0371\n",
            "▁beaucoup\t\t0.0401\n",
            "</s>\t\t0.0135\n",
            "\n",
            "Bigram\t\tBigram Score\n",
            "--------------------------\n",
            "<s> ▁l\t\t0.4955\n",
            "▁l '\t\t1.2228\n",
            "' avion\t\t1.1988\n",
            "avion ▁pollue\t\t0.5086\n",
            "▁pollue ▁beaucoup\t\t0.0772\n",
            "▁beaucoup </s>\t\t0.0536\n",
            "\n",
            "Trigram\t\tTrigram Score\n",
            "--------------------------\n",
            "<s> ▁l '\t\t1.2228\n",
            "▁l ' avion\t\t1.6943\n",
            "' avion ▁pollue\t\t1.2360\n",
            "avion ▁pollue ▁beaucoup\t\t0.5487\n",
            "▁pollue ▁beaucoup </s>\t\t0.0907\n",
            "\n",
            "Predicted Class: avion\n",
            "True Class: avion\n",
            "Predicted Probability: 3.7738828659057617\n",
            "Target Attribution Score: 1.7850163585287044\n",
            "\n",
            "==================================================\n",
            "\n",
            "Target Class: décroissance\n",
            "Token\t\tToken Score\n",
            "--------------------------\n",
            "<s>\t\t0.0000\n",
            "▁l\t\t-0.1436\n",
            "'\t\t-0.8397\n",
            "avion\t\t-0.4299\n",
            "▁pollue\t\t-0.1214\n",
            "▁beaucoup\t\t0.0018\n",
            "</s>\t\t-0.2733\n",
            "\n",
            "Bigram\t\tBigram Score\n",
            "--------------------------\n",
            "<s> ▁l\t\t-0.1436\n",
            "▁l '\t\t-0.9833\n",
            "' avion\t\t-1.2696\n",
            "avion ▁pollue\t\t-0.5513\n",
            "▁pollue ▁beaucoup\t\t-0.1196\n",
            "▁beaucoup </s>\t\t-0.2715\n",
            "\n",
            "Trigram\t\tTrigram Score\n",
            "--------------------------\n",
            "<s> ▁l '\t\t-0.9833\n",
            "▁l ' avion\t\t-1.4132\n",
            "' avion ▁pollue\t\t-1.3911\n",
            "avion ▁pollue ▁beaucoup\t\t-0.5495\n",
            "▁pollue ▁beaucoup </s>\t\t-0.3929\n",
            "\n",
            "Predicted Class: avion\n",
            "True Class: avion\n",
            "Predicted Probability: 3.7738828659057617\n",
            "Target Attribution Score: -1.8061362964596688\n",
            "\n",
            "==================================================\n",
            "\n",
            "Target Class: nucléaire\n",
            "Token\t\tToken Score\n",
            "--------------------------\n",
            "<s>\t\t0.0000\n",
            "▁l\t\t-0.3505\n",
            "'\t\t-0.7894\n",
            "avion\t\t-0.5013\n",
            "▁pollue\t\t0.0354\n",
            "▁beaucoup\t\t0.0089\n",
            "</s>\t\t-0.0364\n",
            "\n",
            "Bigram\t\tBigram Score\n",
            "--------------------------\n",
            "<s> ▁l\t\t-0.3505\n",
            "▁l '\t\t-1.1399\n",
            "' avion\t\t-1.2907\n",
            "avion ▁pollue\t\t-0.4659\n",
            "▁pollue ▁beaucoup\t\t0.0443\n",
            "▁beaucoup </s>\t\t-0.0275\n",
            "\n",
            "Trigram\t\tTrigram Score\n",
            "--------------------------\n",
            "<s> ▁l '\t\t-1.1399\n",
            "▁l ' avion\t\t-1.6412\n",
            "' avion ▁pollue\t\t-1.2553\n",
            "avion ▁pollue ▁beaucoup\t\t-0.4570\n",
            "▁pollue ▁beaucoup </s>\t\t0.0080\n",
            "\n",
            "Predicted Class: avion\n",
            "True Class: avion\n",
            "Predicted Probability: 3.7738828659057617\n",
            "Target Attribution Score: -1.6332499958641158\n",
            "\n",
            "==================================================\n",
            "\n",
            "Target Class: viande\n",
            "Token\t\tToken Score\n",
            "--------------------------\n",
            "<s>\t\t0.0000\n",
            "▁l\t\t-0.5814\n",
            "'\t\t-0.6637\n",
            "avion\t\t-0.4491\n",
            "▁pollue\t\t0.0247\n",
            "▁beaucoup\t\t-0.0155\n",
            "</s>\t\t0.1379\n",
            "\n",
            "Bigram\t\tBigram Score\n",
            "--------------------------\n",
            "<s> ▁l\t\t-0.5814\n",
            "▁l '\t\t-1.2451\n",
            "' avion\t\t-1.1128\n",
            "avion ▁pollue\t\t-0.4243\n",
            "▁pollue ▁beaucoup\t\t0.0092\n",
            "▁beaucoup </s>\t\t0.1224\n",
            "\n",
            "Trigram\t\tTrigram Score\n",
            "--------------------------\n",
            "<s> ▁l '\t\t-1.2451\n",
            "▁l ' avion\t\t-1.6941\n",
            "' avion ▁pollue\t\t-1.0880\n",
            "avion ▁pollue ▁beaucoup\t\t-0.4398\n",
            "▁pollue ▁beaucoup </s>\t\t0.1471\n",
            "\n",
            "Predicted Class: avion\n",
            "True Class: avion\n",
            "Predicted Probability: 3.7738828659057617\n",
            "Target Attribution Score: -1.5469892123840754\n",
            "\n",
            "==================================================\n",
            "\n",
            "Sentence: l'énergie nucléaire\n",
            "Target Class: avion\n",
            "Token\t\tToken Score\n",
            "--------------------------\n",
            "<s>\t\t0.0000\n",
            "▁l\t\t-0.1293\n",
            "'\t\t-0.1945\n",
            "energie\t\t-0.2297\n",
            "▁nu\t\t-0.5342\n",
            "cle\t\t-0.5593\n",
            "aire\t\t-0.5366\n",
            "</s>\t\t0.0807\n",
            "\n",
            "Bigram\t\tBigram Score\n",
            "--------------------------\n",
            "<s> ▁l\t\t-0.1293\n",
            "▁l '\t\t-0.3238\n",
            "' energie\t\t-0.4241\n",
            "energie ▁nu\t\t-0.7639\n",
            "▁nu cle\t\t-1.0936\n",
            "cle aire\t\t-1.0959\n",
            "aire </s>\t\t-0.4559\n",
            "\n",
            "Trigram\t\tTrigram Score\n",
            "--------------------------\n",
            "<s> ▁l '\t\t-0.3238\n",
            "▁l ' energie\t\t-0.5535\n",
            "' energie ▁nu\t\t-0.9584\n",
            "energie ▁nu cle\t\t-1.3232\n",
            "▁nu cle aire\t\t-1.6302\n",
            "cle aire </s>\t\t-1.0153\n",
            "\n",
            "Predicted Class: nucléaire\n",
            "True Class: nucléaire\n",
            "Predicted Probability: 4.732454776763916\n",
            "Target Attribution Score: -2.1029491925933343\n",
            "\n",
            "==================================================\n",
            "\n",
            "Target Class: décroissance\n",
            "Token\t\tToken Score\n",
            "--------------------------\n",
            "<s>\t\t0.0000\n",
            "▁l\t\t-0.0023\n",
            "'\t\t0.0338\n",
            "energie\t\t-0.3313\n",
            "▁nu\t\t0.5013\n",
            "cle\t\t0.0088\n",
            "aire\t\t-0.0481\n",
            "</s>\t\t-0.7971\n",
            "\n",
            "Bigram\t\tBigram Score\n",
            "--------------------------\n",
            "<s> ▁l\t\t-0.0023\n",
            "▁l '\t\t0.0316\n",
            "' energie\t\t-0.2975\n",
            "energie ▁nu\t\t0.1700\n",
            "▁nu cle\t\t0.5101\n",
            "cle aire\t\t-0.0393\n",
            "aire </s>\t\t-0.8452\n",
            "\n",
            "Trigram\t\tTrigram Score\n",
            "--------------------------\n",
            "<s> ▁l '\t\t0.0316\n",
            "▁l ' energie\t\t-0.2997\n",
            "' energie ▁nu\t\t0.2038\n",
            "energie ▁nu cle\t\t0.1788\n",
            "▁nu cle aire\t\t0.4621\n",
            "cle aire </s>\t\t-0.8364\n",
            "\n",
            "Predicted Class: nucléaire\n",
            "True Class: nucléaire\n",
            "Predicted Probability: 4.732454776763916\n",
            "Target Attribution Score: -0.6347683268624232\n",
            "\n",
            "==================================================\n",
            "\n",
            "Target Class: nucléaire\n",
            "Token\t\tToken Score\n",
            "--------------------------\n",
            "<s>\t\t0.0000\n",
            "▁l\t\t0.5266\n",
            "'\t\t0.4788\n",
            "energie\t\t0.2261\n",
            "▁nu\t\t0.4319\n",
            "cle\t\t0.2926\n",
            "aire\t\t0.2751\n",
            "</s>\t\t-0.3074\n",
            "\n",
            "Bigram\t\tBigram Score\n",
            "--------------------------\n",
            "<s> ▁l\t\t0.5266\n",
            "▁l '\t\t1.0054\n",
            "' energie\t\t0.7049\n",
            "energie ▁nu\t\t0.6580\n",
            "▁nu cle\t\t0.7244\n",
            "cle aire\t\t0.5677\n",
            "aire </s>\t\t-0.0323\n",
            "\n",
            "Trigram\t\tTrigram Score\n",
            "--------------------------\n",
            "<s> ▁l '\t\t1.0054\n",
            "▁l ' energie\t\t1.2315\n",
            "' energie ▁nu\t\t1.1368\n",
            "energie ▁nu cle\t\t0.9506\n",
            "▁nu cle aire\t\t0.9996\n",
            "cle aire </s>\t\t0.2603\n",
            "\n",
            "Predicted Class: nucléaire\n",
            "True Class: nucléaire\n",
            "Predicted Probability: 4.732454776763916\n",
            "Target Attribution Score: 1.9236930487775865\n",
            "\n",
            "==================================================\n",
            "\n",
            "Target Class: viande\n",
            "Token\t\tToken Score\n",
            "--------------------------\n",
            "<s>\t\t0.0000\n",
            "▁l\t\t-0.5314\n",
            "'\t\t-0.5377\n",
            "energie\t\t-0.2633\n",
            "▁nu\t\t-0.3390\n",
            "cle\t\t-0.0688\n",
            "aire\t\t-0.1186\n",
            "</s>\t\t0.4748\n",
            "\n",
            "Bigram\t\tBigram Score\n",
            "--------------------------\n",
            "<s> ▁l\t\t-0.5314\n",
            "▁l '\t\t-1.0691\n",
            "' energie\t\t-0.8010\n",
            "energie ▁nu\t\t-0.6022\n",
            "▁nu cle\t\t-0.4078\n",
            "cle aire\t\t-0.1874\n",
            "aire </s>\t\t0.3562\n",
            "\n",
            "Trigram\t\tTrigram Score\n",
            "--------------------------\n",
            "<s> ▁l '\t\t-1.0691\n",
            "▁l ' energie\t\t-1.3324\n",
            "' energie ▁nu\t\t-1.1400\n",
            "energie ▁nu cle\t\t-0.6711\n",
            "▁nu cle aire\t\t-0.5264\n",
            "cle aire </s>\t\t0.2874\n",
            "\n",
            "Predicted Class: nucléaire\n",
            "True Class: nucléaire\n",
            "Predicted Probability: 4.732454776763916\n",
            "Target Attribution Score: -1.384021753278472\n",
            "\n",
            "==================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Le calcul des scores d'attribution pour chaque unigram, bigram et trigram par rapport à chaque target\n",
        "#La fonction retourne un dictionnaire qui contient les phrases comme clé et valeur un autre dictionnaire qui contient les score d'attribution\n",
        "#des tokens de la phrase en question pour chaque target\n",
        "def get_attribution_scores_for_all_targets(sentences):\n",
        "    class_labels = ['avion', 'décroissance', 'nucléaire', 'viande']\n",
        "\n",
        "    # Initialize a dictionary to store attribution scores for each target class and sentence\n",
        "    attribution_scores_by_sentence = {}\n",
        "\n",
        "    for text in sentences:\n",
        "        # Construct input and baseline for the given text\n",
        "        input_ids, baseline_input_ids, all_tokens = construct_input_and_baseline(text)\n",
        "\n",
        "        # Get model predictions for the given text\n",
        "        model_output = model(input_ids)\n",
        "        predicted_index = torch.argmax(model_output[0]).item()\n",
        "        predicted_class = class_labels[predicted_index]\n",
        "\n",
        "        # Initialize a dictionary to store attribution scores for each target class in the current sentence\n",
        "        attribution_scores_by_target = {}\n",
        "\n",
        "        for target_class in class_labels:\n",
        "            target_index = class_labels.index(target_class)\n",
        "            attributions, delta = lig.attribute(inputs=input_ids, baselines=baseline_input_ids, target=target_index, return_convergence_delta=True)\n",
        "\n",
        "            # Summarize the attributions across tokens (modify this part based on your summarize_attributions function)\n",
        "           # attributions_sum = attributions.sum(dim=-1).squeeze().tolist()\n",
        "            attributions_sum = summarize_attributions(attributions).tolist()\n",
        "\n",
        "            # Calculate attribution score for the current target class\n",
        "            target_score = sum(attributions_sum)\n",
        "\n",
        "            # Calculate bigram scores\n",
        "            bigram_scores = [attributions_sum[i] + attributions_sum[i+1] for i in range(len(attributions_sum) - 1)]\n",
        "\n",
        "            # Calculate trigram scores\n",
        "            trigram_scores = [attributions_sum[i] + attributions_sum[i+1] + attributions_sum[i+2] for i in range(len(attributions_sum) - 2)]\n",
        "\n",
        "            # Store the attribution scores in the dictionary for the current target class\n",
        "            attribution_scores_by_target[target_class] = {\n",
        "                \"word_attributions\": attributions_sum,\n",
        "                \"bigram_scores\": bigram_scores,\n",
        "                \"trigram_scores\": trigram_scores,\n",
        "                \"pred_prob\": torch.max(model_output[0]).item(),\n",
        "                \"pred_class\": predicted_class,\n",
        "                \"true_class\": class_labels[predicted_index],\n",
        "                \"attr_class\": text,\n",
        "                \"attr_score\": target_score,\n",
        "                \"raw_input_ids\": all_tokens,\n",
        "                \"convergence_score\": delta\n",
        "            }\n",
        "\n",
        "        # Store the attribution scores for the current sentence in the main dictionary\n",
        "        attribution_scores_by_sentence[text] = attribution_scores_by_target\n",
        "\n",
        "    return attribution_scores_by_sentence\n",
        "\n",
        "def display_attribution_scores(scores):\n",
        "    for sentence, target_scores in scores.items():\n",
        "        print(\"Sentence:\", sentence)\n",
        "        for target_class, scores_dict in target_scores.items():\n",
        "            print(\"Target Class:\", target_class)\n",
        "\n",
        "            # Display token scores\n",
        "            print(\"Token\\t\\tToken Score\")\n",
        "            print(\"--------------------------\")\n",
        "            word_attributions = scores_dict[\"word_attributions\"]\n",
        "            for token, score in zip(scores_dict[\"raw_input_ids\"], word_attributions):\n",
        "                print(f\"{token}\\t\\t{score:.4f}\")\n",
        "\n",
        "            # Display bigram scores\n",
        "            print(\"\\nBigram\\t\\tBigram Score\")\n",
        "            print(\"--------------------------\")\n",
        "            bigram_attributions = scores_dict[\"bigram_scores\"]\n",
        "            bigram_tokens = [f\"{scores_dict['raw_input_ids'][i]} {scores_dict['raw_input_ids'][i+1]}\" for i in range(len(scores_dict[\"raw_input_ids\"]) - 1)]\n",
        "            for token, score in zip(bigram_tokens, bigram_attributions):\n",
        "                print(f\"{token}\\t\\t{score:.4f}\")\n",
        "\n",
        "            # Display trigram scores\n",
        "            print(\"\\nTrigram\\t\\tTrigram Score\")\n",
        "            print(\"--------------------------\")\n",
        "            trigram_attributions = scores_dict[\"trigram_scores\"]\n",
        "            trigram_tokens = [f\"{scores_dict['raw_input_ids'][i]} {scores_dict['raw_input_ids'][i+1]} {scores_dict['raw_input_ids'][i+2]}\" for i in range(len(scores_dict[\"raw_input_ids\"]) - 2)]\n",
        "            for token, score in zip(trigram_tokens, trigram_attributions):\n",
        "                print(f\"{token}\\t\\t{score:.4f}\")\n",
        "\n",
        "            print(\"\\nPredicted Class:\", scores_dict[\"pred_class\"])\n",
        "            print(\"True Class:\", scores_dict[\"true_class\"])\n",
        "            print(\"Predicted Probability:\", scores_dict[\"pred_prob\"])\n",
        "            print(\"Target Attribution Score:\", scores_dict[\"attr_score\"])\n",
        "            print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "# Example sentences and true class\n",
        "sentences = [\"croissance production de viande\", \"l'avion pollue beaucoup\", \"l'énergie nucléaire\"]\n",
        "true_class = 0\n",
        "\n",
        "# Get attribution scores\n",
        "attribution_scores = get_attribution_scores_for_all_targets(sentences)\n",
        "\n",
        "# Display attribution scores\n",
        "display_attribution_scores(attribution_scores)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqOG4G-04zUv",
        "outputId": "7213807a-cf77-4562-e58f-483942818f8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved target clusters to 'target_clusters.json'\n"
          ]
        }
      ],
      "source": [
        "#La fonction crée des clusters qui contient les unigram, bigram et trigram avec le plus grand score d'attribution\n",
        "def create_target_clusters(scores):\n",
        "    class_labels = ['avion', 'décroissance', 'nucléaire', 'viande']\n",
        "\n",
        "    target_clusters = {target: {\"tokens\": [], \"bigrams\": [], \"trigrams\": []} for target in class_labels}\n",
        "\n",
        "    for sentence, target_scores in scores.items():\n",
        "        for target_class, scores_dict in target_scores.items():\n",
        "            word_attributions = scores_dict[\"word_attributions\"]\n",
        "            bigram_attributions = scores_dict[\"bigram_scores\"]\n",
        "            trigram_attributions = scores_dict[\"trigram_scores\"]\n",
        "\n",
        "            for i, (token, token_score) in enumerate(zip(scores_dict[\"raw_input_ids\"], word_attributions)):\n",
        "                if token_score > 0:\n",
        "                    # Determine the corresponding target class with the highest score for this token\n",
        "                    best_target = max(target_scores.keys(), key=lambda target: target_scores[target][\"word_attributions\"][i])\n",
        "                    if best_target == target_class:\n",
        "                        target_clusters[target_class][\"tokens\"].append((token, token_score))\n",
        "\n",
        "            for i in range(len(scores_dict[\"raw_input_ids\"]) - 1):\n",
        "                bigram_token = f\"{scores_dict['raw_input_ids'][i]} {scores_dict['raw_input_ids'][i+1]}\"\n",
        "                bigram_score = bigram_attributions[i]\n",
        "                if bigram_score > 0:\n",
        "                    best_target = max(target_scores.keys(), key=lambda target: target_scores[target][\"bigram_scores\"][i])\n",
        "                    if best_target == target_class:\n",
        "                        target_clusters[target_class][\"bigrams\"].append((bigram_token, bigram_score))\n",
        "\n",
        "            for i in range(len(scores_dict[\"raw_input_ids\"]) - 2):\n",
        "                trigram_token = f\"{scores_dict['raw_input_ids'][i]} {scores_dict['raw_input_ids'][i+1]} {scores_dict['raw_input_ids'][i+2]}\"\n",
        "                trigram_score = trigram_attributions[i]\n",
        "                if trigram_score > 0:\n",
        "                    best_target = max(target_scores.keys(), key=lambda target: target_scores[target][\"trigram_scores\"][i])\n",
        "                    if best_target == target_class:\n",
        "                        target_clusters[target_class][\"trigrams\"].append((trigram_token, trigram_score))\n",
        "\n",
        "    return target_clusters\n",
        "\n",
        "# Example sentences and true class\n",
        "#sentences = [\"augmentation production de viande\", \"l'avion pollue beaucoup\", \"l'énergie nucléaire\"]\n",
        "sentences = df_test['Text'].tolist()\n",
        "true_class = 0\n",
        "\n",
        "# Get attribution scores\n",
        "attribution_scores = get_attribution_scores_for_all_targets(sentences)\n",
        "\n",
        "# Create target clusters\n",
        "target_clusters = create_target_clusters(attribution_scores)\n",
        "\n",
        "# Save clusters to a JSON file\n",
        "result_dict = {}\n",
        "for target, data in target_clusters.items():\n",
        "    result_dict[target] = {\n",
        "        \"tokens\": [{\"token\": token, \"score\": score} for token, score in sorted(data[\"tokens\"], key=lambda x: x[1], reverse=True)],\n",
        "        \"bigrams\": [{\"bigram\": bigram, \"score\": score} for bigram, score in sorted(data[\"bigrams\"], key=lambda x: x[1], reverse=True)],\n",
        "        \"trigrams\": [{\"trigram\": trigram, \"score\": score} for trigram, score in sorted(data[\"trigrams\"], key=lambda x: x[1], reverse=True)]\n",
        "    }\n",
        "\n",
        "# Save the result to a JSON file\n",
        "import json\n",
        "with open(\"target_clusters.json\", \"w\") as json_file:\n",
        "    json.dump(result_dict, json_file, indent=4)\n",
        "\n",
        "print(\"Saved target clusters to 'target_clusters.json'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-KF3vIZzd1i",
        "outputId": "e464ac39-8512-402c-c4e2-8eebbd340474"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved negative score clusters to 'negative_score_clusters.json'\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# Function to create clusters containing unigrams, bigrams, and trigrams with the most negative attribution score\n",
        "def create_negative_score_clusters(scores):\n",
        "    class_labels = ['avion', 'décroissance', 'nucléaire', 'viande']\n",
        "\n",
        "    negative_score_clusters = {target: {\"tokens\": [], \"bigrams\": [], \"trigrams\": []} for target in class_labels}\n",
        "\n",
        "    for sentence, target_scores in scores.items():\n",
        "        for target_class, scores_dict in target_scores.items():\n",
        "            word_attributions = scores_dict[\"word_attributions\"]\n",
        "            bigram_attributions = scores_dict[\"bigram_scores\"]\n",
        "            trigram_attributions = scores_dict[\"trigram_scores\"]\n",
        "\n",
        "            for i, (token, token_score) in enumerate(zip(scores_dict[\"raw_input_ids\"], word_attributions)):\n",
        "                token = token.lstrip('\\u2581')  # Remove the character from the beginning\n",
        "                if token_score < 0:\n",
        "                    # Determine the corresponding target class with the most negative score for this token\n",
        "                    worst_target = min(target_scores.keys(), key=lambda target: target_scores[target][\"word_attributions\"][i])\n",
        "                    if worst_target == target_class:\n",
        "                        negative_score_clusters[target_class][\"tokens\"].append((token, token_score))\n",
        "\n",
        "            for i in range(len(scores_dict[\"raw_input_ids\"]) - 1):\n",
        "                bigram_token = f\"{scores_dict['raw_input_ids'][i]} {scores_dict['raw_input_ids'][i+1]}\"\n",
        "                bigram_token = bigram_token.lstrip('\\u2581')  # Remove the character from the beginning\n",
        "                bigram_score = bigram_attributions[i]\n",
        "                if bigram_score < 0:\n",
        "                    worst_target = min(target_scores.keys(), key=lambda target: target_scores[target][\"bigram_scores\"][i])\n",
        "                    if worst_target == target_class:\n",
        "                        negative_score_clusters[target_class][\"bigrams\"].append((bigram_token, bigram_score))\n",
        "\n",
        "            for i in range(len(scores_dict[\"raw_input_ids\"]) - 2):\n",
        "                trigram_token = f\"{scores_dict['raw_input_ids'][i]} {scores_dict['raw_input_ids'][i+1]} {scores_dict['raw_input_ids'][i+2]}\"\n",
        "                trigram_token = trigram_token.lstrip('\\u2581')  # Remove the character from the beginning\n",
        "                trigram_score = trigram_attributions[i]\n",
        "                if trigram_score < 0:\n",
        "                    worst_target = min(target_scores.keys(), key=lambda target: target_scores[target][\"trigram_scores\"][i])\n",
        "                    if worst_target == target_class:\n",
        "                        negative_score_clusters[target_class][\"trigrams\"].append((trigram_token, trigram_score))\n",
        "\n",
        "    return negative_score_clusters\n",
        "\n",
        "# Example sentences and true class\n",
        "# sentences = [\"augmentation production de viande\", \"l'avion pollue beaucoup\", \"l'énergie nucléaire\"]\n",
        "sentences = df_test['Text'].tolist()\n",
        "true_class = 0\n",
        "\n",
        "# Get attribution scores (you should define this function)\n",
        "attribution_scores = get_attribution_scores_for_all_targets(sentences)\n",
        "\n",
        "# Create negative score clusters\n",
        "negative_score_clusters = create_negative_score_clusters(attribution_scores)\n",
        "\n",
        "# Save clusters with negative scores to a JSON file\n",
        "result_dict = {}\n",
        "for target, data in negative_score_clusters.items():\n",
        "    result_dict[target] = {\n",
        "        \"tokens\": [{\"token\": token, \"score\": score} for token, score in sorted(data[\"tokens\"], key=lambda x: x[1])],\n",
        "        \"bigrams\": [{\"bigram\": bigram, \"score\": score} for bigram, score in sorted(data[\"bigrams\"], key=lambda x: x[1])],\n",
        "        \"trigrams\": [{\"trigram\": trigram, \"score\": score} for trigram, score in sorted(data[\"trigrams\"], key=lambda x: x[1])]\n",
        "    }\n",
        "\n",
        "# Save the result to a JSON file\n",
        "with open(\"negative_score_clusters.json\", \"w\") as json_file:\n",
        "    json.dump(result_dict, json_file, indent=4)\n",
        "\n",
        "print(\"Saved negative score clusters to 'negative_score_clusters.json'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FveT_0a3y0wl",
        "outputId": "f2778f41-21ed-4a48-b36f-e53e0a4f5608"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved negative score clusters to 'negative_score_clusters.json'\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# Function to create clusters containing unigrams, bigrams, and trigrams with the most negative attribution score\n",
        "def create_negative_score_clusters(scores):\n",
        "    class_labels = ['avion', 'décroissance', 'nucléaire', 'viande']\n",
        "\n",
        "    negative_score_clusters = {target: {\"tokens\": [], \"bigrams\": [], \"trigrams\": []} for target in class_labels}\n",
        "\n",
        "    for sentence, target_scores in scores.items():\n",
        "        for target_class, scores_dict in target_scores.items():\n",
        "            word_attributions = scores_dict[\"word_attributions\"]\n",
        "            bigram_attributions = scores_dict[\"bigram_scores\"]\n",
        "            trigram_attributions = scores_dict[\"trigram_scores\"]\n",
        "\n",
        "            for i, (token, token_score) in enumerate(zip(scores_dict[\"raw_input_ids\"], word_attributions)):\n",
        "                token = token.lstrip('\\u2581')  # Remove the character from the beginning\n",
        "                if token_score < 0:\n",
        "                    # Determine the corresponding target class with the most negative score for this token\n",
        "                    worst_target = min(target_scores.keys(), key=lambda target: target_scores[target][\"word_attributions\"][i])\n",
        "                    if worst_target == target_class:\n",
        "                        negative_score_clusters[target_class][\"tokens\"].append((token, token_score))\n",
        "\n",
        "            for i in range(len(scores_dict[\"raw_input_ids\"]) - 1):\n",
        "                bigram_token = f\"{scores_dict['raw_input_ids'][i]} {scores_dict['raw_input_ids'][i+1]}\"\n",
        "                bigram_token = bigram_token.lstrip('\\u2581')  # Remove the character from the beginning\n",
        "                bigram_score = bigram_attributions[i]\n",
        "                if bigram_score < 0:\n",
        "                    worst_target = min(target_scores.keys(), key=lambda target: target_scores[target][\"bigram_scores\"][i])\n",
        "                    if worst_target == target_class:\n",
        "                        negative_score_clusters[target_class][\"bigrams\"].append((bigram_token, bigram_score))\n",
        "\n",
        "            for i in range(len(scores_dict[\"raw_input_ids\"]) - 2):\n",
        "                trigram_token = \" \".join([scores_dict['raw_input_ids'][i], scores_dict['raw_input_ids'][i+1], scores_dict['raw_input_ids'][i+2]])\n",
        "                trigram_token = trigram_token.lstrip('\\u2581')  # Remove the character from the beginning\n",
        "                trigram_score = trigram_attributions[i]\n",
        "                if trigram_score < 0:\n",
        "                    worst_target = min(target_scores.keys(), key=lambda target: target_scores[target][\"trigram_scores\"][i])\n",
        "                    if worst_target == target_class:\n",
        "                        negative_score_clusters[target_class][\"trigrams\"].append((trigram_token, trigram_score))\n",
        "\n",
        "    return negative_score_clusters\n",
        "\n",
        "# Example sentences and true class\n",
        "# sentences = [\"augmentation production de viande\", \"l'avion pollue beaucoup\", \"l'énergie nucléaire\"]\n",
        "sentences = df_test['Text'].tolist()\n",
        "true_class = 0\n",
        "\n",
        "# Get attribution scores (you should define this function)\n",
        "attribution_scores = get_attribution_scores_for_all_targets(sentences)\n",
        "\n",
        "# Create negative score clusters\n",
        "negative_score_clusters = create_negative_score_clusters(attribution_scores)\n",
        "\n",
        "# Save clusters with negative scores to a JSON file\n",
        "result_dict = {}\n",
        "for target, data in negative_score_clusters.items():\n",
        "    result_dict[target] = {\n",
        "        \"tokens\": [{\"token\": token, \"score\": score} for token, score in sorted(data[\"tokens\"], key=lambda x: x[1])],\n",
        "        \"bigrams\": [{\"bigram\": bigram, \"score\": score} for bigram, score in sorted(data[\"bigrams\"], key=lambda x: x[1])],\n",
        "        \"trigrams\": [{\"trigram\": trigram, \"score\": score} for trigram, score in sorted(data[\"trigrams\"], key=lambda x: x[1])]\n",
        "    }\n",
        "\n",
        "# Save the result to a JSON file\n",
        "with open(\"negative_score_clusters.json\", \"w\") as json_file:\n",
        "    json.dump(result_dict, json_file, indent=4)\n",
        "\n",
        "print(\"Saved negative score clusters to 'negative_score_clusters.json'\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0c08707df1dc4a3e9f453dd77f892cb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3904831de1cf4812abe4e4e68f8041d1",
            "placeholder": "​",
            "style": "IPY_MODEL_f3e2cfe95656420f858341b041e8c8c4",
            "value": "Downloading (…)tencepiece.bpe.model: 100%"
          }
        },
        "13ac6963e60b4ba0a11287a4a04b30b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "251c0d15e8934c81a8bcc81db922aa3c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f1169c946fa49f58df1148e59e0673a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3904831de1cf4812abe4e4e68f8041d1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41e650a7f166453aad7a59a59133607c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4eaed1dbc18e4c3c9ffcd332e9cc1398": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b98016ec6e21448c94f190eda67bf9ca",
            "placeholder": "​",
            "style": "IPY_MODEL_efe7647200d740969a99cb244c303290",
            "value": " 445M/445M [00:08&lt;00:00, 66.4MB/s]"
          }
        },
        "50a8b3a628e7446e85c743a2ef0147c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53fd5cc5fdb942b7922da6f6beae9c1d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54808a869491405883544a70e3b39634": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53fd5cc5fdb942b7922da6f6beae9c1d",
            "placeholder": "​",
            "style": "IPY_MODEL_2f1169c946fa49f58df1148e59e0673a",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "55e07f86caa446bc92f59079e1fd3e1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_251c0d15e8934c81a8bcc81db922aa3c",
            "max": 810912,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fb013b809bd649a5a446c629668224b5",
            "value": 810912
          }
        },
        "5be2e706625b476bb92b8773b08d6f93": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41e650a7f166453aad7a59a59133607c",
            "placeholder": "​",
            "style": "IPY_MODEL_e69f1da37d394ae9ba54dedc16b09764",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "627a6e86df9143229e0473528dd0189e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6316e29a817e4f3aa5ebba496bb07b53": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8f1fd79c4184ec39ad21f9369d0c475",
            "max": 445008750,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9fc2d14b00a741b6a74a08b4cc557b39",
            "value": 445008750
          }
        },
        "7591052b83184646b6ce6ed75693d7a7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ff8534ab40846efa8136cd50144b7e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fdb2990ef9a14c749e6093afe5f17b81",
            "placeholder": "​",
            "style": "IPY_MODEL_13ac6963e60b4ba0a11287a4a04b30b1",
            "value": " 508/508 [00:00&lt;00:00, 28.5kB/s]"
          }
        },
        "9203bab8523b4baea7c2128ff5cf6cc8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9fc2d14b00a741b6a74a08b4cc557b39": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b98016ec6e21448c94f190eda67bf9ca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9bd4edfccd340d5aad58f3746fcb75f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ba26d44f04b94b87b5fcb91aa26b885b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0c08707df1dc4a3e9f453dd77f892cb9",
              "IPY_MODEL_55e07f86caa446bc92f59079e1fd3e1a",
              "IPY_MODEL_f9fbea7ba1054fd9a95f11a3f9d32cfc"
            ],
            "layout": "IPY_MODEL_627a6e86df9143229e0473528dd0189e"
          }
        },
        "becf1165f932483ead634174f352cd38": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9203bab8523b4baea7c2128ff5cf6cc8",
            "max": 508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b9bd4edfccd340d5aad58f3746fcb75f",
            "value": 508
          }
        },
        "c8f1fd79c4184ec39ad21f9369d0c475": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d711aae23db840a8b1b9345278746fc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_54808a869491405883544a70e3b39634",
              "IPY_MODEL_becf1165f932483ead634174f352cd38",
              "IPY_MODEL_7ff8534ab40846efa8136cd50144b7e5"
            ],
            "layout": "IPY_MODEL_ddbb65d3f2904ccfbde80b8621e4002b"
          }
        },
        "ddbb65d3f2904ccfbde80b8621e4002b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0f21bea6d7a4af49c24428fcf0327ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5be2e706625b476bb92b8773b08d6f93",
              "IPY_MODEL_6316e29a817e4f3aa5ebba496bb07b53",
              "IPY_MODEL_4eaed1dbc18e4c3c9ffcd332e9cc1398"
            ],
            "layout": "IPY_MODEL_7591052b83184646b6ce6ed75693d7a7"
          }
        },
        "e69f1da37d394ae9ba54dedc16b09764": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef4e012b7384490c9d92ac2caaf0de42": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efe7647200d740969a99cb244c303290": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3e2cfe95656420f858341b041e8c8c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f9fbea7ba1054fd9a95f11a3f9d32cfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef4e012b7384490c9d92ac2caaf0de42",
            "placeholder": "​",
            "style": "IPY_MODEL_50a8b3a628e7446e85c743a2ef0147c5",
            "value": " 811k/811k [00:00&lt;00:00, 1.36MB/s]"
          }
        },
        "fb013b809bd649a5a446c629668224b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fdb2990ef9a14c749e6093afe5f17b81": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
